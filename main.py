# main.py - ë²ˆí˜¸ì´ë™ì •ì‚° AI ë¶„ì„ ì‹œìŠ¤í…œ ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜ (Azure SQL Database ì—°ë™)
import streamlit as st
import os
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import re
from datetime import datetime, timedelta
import logging
import re
import traceback
import time

from azure_config import get_azure_config
from sample_data import SampleDataManager
from database_manager import DatabaseManagerFactory
from openai import AzureOpenAI
import json

# í”„ë¡œì íŠ¸ ëª¨ë“ˆë“¤
from database_manager import DatabaseManagerFactory
from azure_config import get_azure_config

from dotenv import load_dotenv

# ìƒ˜í”Œ ë°ì´í„° ì„í¬íŠ¸
from sample_data import create_sample_database

from sql_generator import SQLGenerator

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ

load_dotenv()

OPENAI_AVAILABLE = True

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ë²ˆí˜¸ì´ë™ì •ì‚° AI ë¶„ì„ ì‹œìŠ¤í…œ",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded",
)

# CSS ìŠ¤íƒ€ì¼
st.markdown(
    """
<style>
    /* í”„ë¡œê·¸ë ˆìŠ¤ ì™„ë£Œ í›„ ì •ë¦¬ë¥¼ ìœ„í•œ CSS */
    .progress-cleanup {
        animation: fadeOut 0.5s ease-out forwards;
    }
    
    @keyframes fadeOut {
        0% { opacity: 1; }
        100% { opacity: 0; display: none; }
    }
    
    /* ìŠ¤í”¼ë„ˆ ê´€ë ¨ ëª¨ë“  ìš”ì†Œ ìˆ¨ê¸°ê¸° */
    .stSpinner,
    div[data-testid="stSpinner"],
    .stProgress.stProgress-complete {
        display: none !important;
    }
    
    /* ìƒíƒœ ë©”ì‹œì§€ ì»¨í…Œì´ë„ˆ */
    .status-message-container {
        transition: all 0.3s ease-out;
    }
    
    .status-message-container.hidden {
        opacity: 0;
        height: 0;
        overflow: hidden;
        margin: 0;
        padding: 0;
    }
    .main-header {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 2rem;
        border-radius: 15px;
        color: white;
        text-align: center;
        margin-bottom: 2rem;
        box-shadow: 0 8px 32px rgba(31, 38, 135, 0.37);
    }
    
    .metric-card {
        background: rgba(255, 255, 255, 0.95);
        padding: 1.5rem;
        border-radius: 12px;
        box-shadow: 0 4px 20px rgba(0,0,0,0.1);
        border-left: 5px solid #667eea;
        transition: transform 0.2s ease;
    }
    
    .chat-container {
        background: linear-gradient(145deg, #f8f9fa, #e9ecef);
        border-radius: 15px;
        padding: 1.5rem;
        margin: 1rem 0;
        border: 1px solid #dee2e6;
    }
    
    .query-example {
        background: rgba(102, 126, 234, 0.1);
        border-left: 4px solid #667eea;
        padding: 1rem;
        margin: 0.5rem 0;
        border-radius: 0 8px 8px 0;
        cursor: pointer;
    }
       
    .success-alert {
        background: linear-gradient(135deg, #4facfe 0%, #00f2fe 100%);
        color: white;
        padding: 1rem;
        border-radius: 8px;
        margin: 1rem 0;
    }
    
    .error-alert {
        background: linear-gradient(135deg, #ff6b6b 0%, #ee5a52 100%);
        color: white;
        padding: 1rem;
        border-radius: 8px;
        margin: 1rem 0;
    }

    .azure-status {
        background: linear-gradient(135deg, #0078d4 0%, #106ebe 100%);
        color: white;
        padding: 0.8rem;
        border-radius: 8px;
        margin: 0.5rem 0;
        text-align: center;
        font-weight: 500;
    }
    
    .local-status {
        background: linear-gradient(135deg, #ffa500 0%, #ff8c00 100%);
        color: white;
        padding: 0.8rem;
        border-radius: 8px;
        margin: 0.5rem 0;
        text-align: center;
        font-weight: 500;
    
        /* main.pyì˜ CSS ì„¹ì…˜ì— ì¶”ê°€í•  ìŠ¤íƒ€ì¼ */

    .stProgress > div > div > div > div {
        background: linear-gradient(90deg, #667eea 0%, #764ba2 50%, #4facfe 100%);
        animation: progressFlow 2s ease-in-out infinite;
    }

    @keyframes progressFlow {
        0% { background-position: 0% 50%; }
        50% { background-position: 100% 50%; }
        100% { background-position: 0% 50%; }
    }

    .progress-container {
        background: rgba(255, 255, 255, 0.95);
        padding: 2rem;
        border-radius: 15px;
        box-shadow: 0 8px 32px rgba(31, 38, 135, 0.37);
        backdrop-filter: blur(4px);
        border: 1px solid rgba(255, 255, 255, 0.18);
        margin: 2rem 0;
    }

    .progress-text {
        font-weight: 600;
        font-size: 1.1em;
        color: #667eea;
        text-align: center;
        margin: 1rem 0;
    }

    .status-message {
        background: linear-gradient(135deg, #f8f9fa, #e9ecef);
        border-left: 4px solid #667eea;
        padding: 1rem;
        border-radius: 0 8px 8px 0;
        margin: 1rem 0;
    }

    .detail-message {
        color: #6c757d;
        font-style: italic;
        font-size: 0.9em;
        margin-top: 0.5rem;
    }
    </style>
    """,
    unsafe_allow_html=True,
)

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


# ğŸ”¥ ì„ì‹œ ë””ë²„ê¹… ì½”ë“œ ì¶”ê°€
# def debug_environment():
#     st.write("ğŸ” í™˜ê²½ë³€ìˆ˜ ë””ë²„ê¹…:")
#     env_vars = [
#         "AZURE_SQL_SERVER",
#         "AZURE_SQL_DATABASE",
#         "AZURE_SQL_USERNAME",
#         "AZURE_SQL_PASSWORD",
#     ]
#     for var in env_vars:
#         value = os.getenv(var, "âŒ ì—†ìŒ")
#         if "PASSWORD" in var and value != "âŒ ì—†ìŒ":
#             value = "âœ… ì„¤ì •ë¨"
#         st.write(f"- {var}: {value}")


# ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”
@st.cache_resource(show_spinner=False)
def init_database_manager():
    """ì•ˆì „í•œ ë°ì´í„°ë² ì´ìŠ¤ ë§¤ë‹ˆì € ì´ˆê¸°í™” - ë™ì  í”„ë¡œê·¸ë ˆìŠ¤ë°”"""

    # ì§„í–‰ ìƒí™© í‘œì‹œ ì»¨í…Œì´ë„ˆ
    progress_container = st.container()

    with progress_container:
        # í”„ë¡œê·¸ë ˆìŠ¤ë°”ì™€ ìƒíƒœ ë©”ì‹œì§€
        progress_bar = st.progress(0)
        status_text = st.empty()
        progress_text = st.empty()
        detail_text = st.empty()  # ğŸ”¥ ì¶”ê°€: ì„¸ë¶€ ë©”ì‹œì§€ìš©

    def update_progress(value, message, detail=""):
        """í”„ë¡œê·¸ë ˆìŠ¤ë°” ì—…ë°ì´íŠ¸ í•¨ìˆ˜"""
        progress_bar.progress(value)
        progress_text.write(f"**ì§„í–‰ë¥ : {int(value * 100)}%**")
        status_text.info(f"{message}")
        if detail:
            detail_text.caption(detail)  # ğŸ”¥ ìˆ˜ì •: st.caption â†’ detail_text.caption
        time.sleep(0.3)  # ì‹œê°ì  íš¨ê³¼ë¥¼ ìœ„í•œ ì§€ì—°

    def clean_progress_ui():
        """ğŸ”¥ ì¶”ê°€: í”„ë¡œê·¸ë ˆìŠ¤ UI ì™„ì „ ì •ë¦¬ í•¨ìˆ˜"""
        progress_bar.empty()
        status_text.empty()
        progress_text.empty()
        detail_text.empty()
        progress_container.empty()

    try:
        import time  # ì• ë‹ˆë©”ì´ì…˜ íš¨ê³¼ìš©

        # ğŸ¯ 1ë‹¨ê³„: Azure ì„¤ì • ë¡œë“œ (0-20%)
        update_progress(0.05, "ğŸ”§ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...", "í™˜ê²½ ì„¤ì •ì„ í™•ì¸í•˜ê³  ìˆìŠµë‹ˆë‹¤")

        update_progress(
            0.10, "ğŸ”§ Azure ì„¤ì •ì„ ë¡œë“œí•˜ê³  ìˆìŠµë‹ˆë‹¤...", "Azure ì—°ê²° ì •ë³´ë¥¼ ì½ëŠ” ì¤‘"
        )
        azure_config = get_azure_config()

        update_progress(0.20, "âœ… Azure ì„¤ì • ë¡œë“œ ì™„ë£Œ", "ì—°ê²° ì •ë³´ ê²€ì¦ ì¤‘")

        # ğŸ¯ 2ë‹¨ê³„: í™˜ê²½ë³€ìˆ˜ í™•ì¸ (20-30%)
        update_progress(
            0.25, "ğŸ” í™˜ê²½ë³€ìˆ˜ í™•ì¸ ì¤‘...", "FORCE_SAMPLE_MODE ë“± ì„¤ì • í™•ì¸"
        )
        force_sample = os.getenv("FORCE_SAMPLE_MODE", "false").lower() == "true"

        update_progress(
            0.30,
            "âœ… í™˜ê²½ë³€ìˆ˜ í™•ì¸ ì™„ë£Œ",
            f"ê°•ì œ ìƒ˜í”Œ ëª¨ë“œ: {'í™œì„±í™”' if force_sample else 'ë¹„í™œì„±í™”'}",
        )

        # ğŸ¯ 3ë‹¨ê³„: ê°•ì œ ìƒ˜í”Œ ëª¨ë“œ ì²˜ë¦¬ (30-100%)
        if force_sample:
            update_progress(
                0.40, "ğŸ”§ ê°•ì œ ìƒ˜í”Œ ëª¨ë“œë¡œ ì„¤ì •ë¨", "ë¡œì»¬ SQLite ë°ì´í„°ë² ì´ìŠ¤ ì¤€ë¹„ ì¤‘"
            )

            update_progress(
                0.60,
                "ğŸ“Š ìƒ˜í”Œ ë°ì´í„°ë² ì´ìŠ¤ ìƒì„± ì¤‘...",
                "í…Œì´ë¸” êµ¬ì¡° ìƒì„± ë° ë°ì´í„° ì‚½ì…",
            )
            db_manager = DatabaseManagerFactory.create_sample_manager(azure_config)

            update_progress(0.80, "ğŸ” ì—°ê²° í…ŒìŠ¤íŠ¸ ì¤‘...", "ë°ì´í„°ë² ì´ìŠ¤ ì ‘ê·¼ ê¶Œí•œ í™•ì¸")

            update_progress(0.95, "âœ… ìƒ˜í”Œ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì„±ê³µ!", "ì‹œìŠ¤í…œ ì¤€ë¹„ ì™„ë£Œ")

            update_progress(1.0, "ğŸš€ ì‹œìŠ¤í…œ ì‹œì‘ ì™„ë£Œ!", "ìƒ˜í”Œ ëª¨ë“œì—ì„œ ì‹¤í–‰ë©ë‹ˆë‹¤")

            # ğŸ”¥ ìˆ˜ì •: ì„±ê³µ ì‹œ UI ì™„ì „ ì •ë¦¬
            time.sleep(1.5)  # ì™„ë£Œ ë©”ì‹œì§€ë¥¼ ì ì‹œ ë³´ì—¬ì¤€ í›„
            clean_progress_ui()  # ëª¨ë“  ì§„í–‰ ìƒí™© ë©”ì‹œì§€ ì œê±°

            return db_manager

        # ğŸ¯ 4ë‹¨ê³„: Azure ìš°ì„  ì‹œë„ (30-70%)
        update_progress(
            0.35, "â˜ï¸ Azure í´ë¼ìš°ë“œ ì„œë¹„ìŠ¤ ì—°ê²° ì¤‘...", "Azure SQL Database ì ‘ê·¼ ì‹œë„"
        )

        try:
            # Azure ì—°ê²° ê°€ëŠ¥ ì—¬ë¶€ ë¨¼ì € í™•ì¸
            update_progress(
                0.40, "ğŸ” Azure ì—°ê²° ë¬¸ìì—´ í™•ì¸...", "ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì • ê²€ì¦"
            )
            if not azure_config.get_database_connection_string():
                raise Exception("Azure SQL Database ì—°ê²° ë¬¸ìì—´ì´ ì„¤ì •ë˜ì§€ ì•ŠìŒ")

            update_progress(
                0.50, "ğŸ—ï¸ Azure ë°ì´í„°ë² ì´ìŠ¤ ë§¤ë‹ˆì € ìƒì„±...", "SQLAlchemy ì—”ì§„ ì´ˆê¸°í™”"
            )
            db_manager = DatabaseManagerFactory.create_manager(
                azure_config, force_sample=False
            )

            update_progress(
                0.65, "ğŸ” Azure ì—°ê²° í…ŒìŠ¤íŠ¸ ì¤‘...", "ë°ì´í„°ë² ì´ìŠ¤ ê¶Œí•œ ë° í…Œì´ë¸” í™•ì¸"
            )

            if db_manager and db_manager.test_connection():
                update_progress(
                    0.85,
                    "ğŸ‰ Azure ì—°ê²° í…ŒìŠ¤íŠ¸ ì„±ê³µ!",
                    "í´ë¼ìš°ë“œ ë°ì´í„°ë² ì´ìŠ¤ ì¤€ë¹„ ì™„ë£Œ",
                )

                connection_type = (
                    "Azure SQL Database"
                    if not db_manager.use_sample_data
                    else "ìƒ˜í”Œ SQLite"
                )
                update_progress(
                    0.95, f"âœ… {connection_type} ì—°ê²° ì„±ê³µ!", "ìµœì¢… ì‹œìŠ¤í…œ ê²€ì¦ ì¤‘"
                )

                update_progress(
                    1.0, "ğŸš€ Azure í´ë¼ìš°ë“œ ëª¨ë“œ ì‹œì‘!", "ì‹¤ì‹œê°„ ë°ì´í„° ë¶„ì„ ì¤€ë¹„ ì™„ë£Œ"
                )

                # ğŸ”¥ ìˆ˜ì •: ì„±ê³µ ì‹œ UI ì™„ì „ ì •ë¦¬
                time.sleep(1.5)  # ì™„ë£Œ ë©”ì‹œì§€ë¥¼ ì ì‹œ ë³´ì—¬ì¤€ í›„
                clean_progress_ui()  # ëª¨ë“  ì§„í–‰ ìƒí™© ë©”ì‹œì§€ ì œê±°

                return db_manager
            else:
                raise Exception("ì—°ê²° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")

        except Exception as azure_e:
            update_progress(0.60, f"âš ï¸ Azure ì—°ê²° ì‹¤íŒ¨", f"ì˜¤ë¥˜: {str(azure_e)[:50]}...")

            # ğŸ¯ 5ë‹¨ê³„: ë°©í™”ë²½ ì˜¤ë¥˜ íŠ¹ë³„ ì²˜ë¦¬
            if "40615" in str(azure_e):
                clean_progress_ui()  # ğŸ”¥ ì¶”ê°€: ì˜¤ë¥˜ ì‹œì—ë„ í”„ë¡œê·¸ë ˆìŠ¤ ì •ë¦¬

                st.error("ğŸš¨ Azure SQL Database ë°©í™”ë²½ ì°¨ë‹¨!")

                # IP ì •ë³´ ì¶”ì¶œ ë° í•´ê²° ê°€ì´ë“œ í‘œì‹œ
                ip_match = re.search(r"IP address '([\d.]+)'", str(azure_e))
                server_match = re.search(r"server '([^']+)'", str(azure_e))

                if ip_match and server_match:
                    current_ip = ip_match.group(1)
                    server_name = server_match.group(1)

                    col1, col2 = st.columns(2)
                    with col1:
                        st.info(f"ğŸŒ í˜„ì¬ IP: `{current_ip}`")
                    with col2:
                        st.info(f"ğŸ—„ï¸ ì„œë²„: `{server_name}`")

                    st.markdown("### ğŸ”§ í•´ê²° ë°©ë²•")
                    st.markdown(
                        f"""
                    1. **Azure Portal** ì ‘ì†: https://portal.azure.com
                    2. **SQL Server ê²€ìƒ‰**: `{server_name.split('.')[0]}`
                    3. **ë°©í™”ë²½ ì„¤ì •**: "ë°©í™”ë²½ ë° ê°€ìƒ ë„¤íŠ¸ì›Œí¬" ë©”ë‰´
                    4. **IP ì¶”ê°€**: "í´ë¼ì´ì–¸íŠ¸ IP ì¶”ê°€" ë²„íŠ¼ í´ë¦­
                    5. **ì €ì¥ í›„ ìƒˆë¡œê³ ì¹¨**: 5ë¶„ í›„ í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨
                    """
                    )

                return None

            # ğŸ¯ 6ë‹¨ê³„: ìƒ˜í”Œ ëª¨ë“œë¡œ ë°±ì—… (70-100%)
            update_progress(
                0.70, "ğŸ”„ ìƒ˜í”Œ ë°ì´í„° ëª¨ë“œë¡œ ì „í™˜...", "ë¡œì»¬ ë°±ì—… ë°ì´í„°ë² ì´ìŠ¤ ì¤€ë¹„"
            )

            try:
                update_progress(
                    0.80, "ğŸ“Š ìƒ˜í”Œ ë°ì´í„°ë² ì´ìŠ¤ ìƒì„± ì¤‘...", "SQLite ë©”ëª¨ë¦¬ DB ì´ˆê¸°í™”"
                )
                sample_manager = DatabaseManagerFactory.create_sample_manager(
                    azure_config
                )

                update_progress(
                    0.90, "ğŸ” ìƒ˜í”Œ DB ì—°ê²° í…ŒìŠ¤íŠ¸...", "í…Œì´ë¸” êµ¬ì¡° ë° ë°ì´í„° í™•ì¸"
                )

                if sample_manager.test_connection():
                    update_progress(
                        0.95, "âœ… ìƒ˜í”Œ ë°ì´í„°ë² ì´ìŠ¤ ì¤€ë¹„ ì™„ë£Œ!", "ë°±ì—… ëª¨ë“œ ì‹œìŠ¤í…œ ê²€ì¦"
                    )

                    update_progress(
                        1.0, "ğŸš€ ìƒ˜í”Œ ëª¨ë“œë¡œ ì‹œì‘!", "ê°œë°œ/í…ŒìŠ¤íŠ¸ í™˜ê²½ì—ì„œ ì‹¤í–‰ë©ë‹ˆë‹¤"
                    )

                    # ğŸ”¥ ìˆ˜ì •: ì„±ê³µ ì‹œ UI ì™„ì „ ì •ë¦¬
                    time.sleep(1.5)
                    clean_progress_ui()

                    return sample_manager
                else:
                    raise Exception("ìƒ˜í”Œ ì—°ê²° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")

            except Exception as sample_e:
                clean_progress_ui()  # ğŸ”¥ ì¶”ê°€: ì˜¤ë¥˜ ì‹œì—ë„ í”„ë¡œê·¸ë ˆìŠ¤ ì •ë¦¬

                st.error("âŒ ìƒ˜í”Œ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°ë„ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")

                # ìƒì„¸ ì˜¤ë¥˜ ì •ë³´
                with st.expander("ğŸ› ì˜¤ë¥˜ ìƒì„¸ ì •ë³´"):
                    st.code(f"Azure ì˜¤ë¥˜: {azure_e}")
                    st.code(f"ìƒ˜í”Œ ì˜¤ë¥˜: {sample_e}")
                    st.code(f"íŠ¸ë ˆì´ìŠ¤ë°±:\n{traceback.format_exc()}")

                return None

    except Exception as e:
        clean_progress_ui()  # ğŸ”¥ ì¶”ê°€: ì˜ˆì™¸ ë°œìƒ ì‹œì—ë„ í”„ë¡œê·¸ë ˆìŠ¤ ì •ë¦¬

        st.error(f"âŒ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

        with st.expander("ğŸ› ì‹œìŠ¤í…œ ì˜¤ë¥˜ ì •ë³´"):
            st.code(f"ì˜¤ë¥˜: {e}")
            st.code(f"íŠ¸ë ˆì´ìŠ¤ë°±:\n{traceback.format_exc()}")

        # ğŸ¯ 7ë‹¨ê³„: ìµœì¢… ë³µêµ¬ ì‹œë„ (ê¸´ê¸‰ ëª¨ë“œ)
        st.info("ğŸ› ï¸ ìµœì†Œí•œì˜ ì‹œìŠ¤í…œìœ¼ë¡œ ì‹¤í–‰ì„ ì‹œë„í•©ë‹ˆë‹¤...")

        emergency_progress = st.progress(0)
        emergency_status = st.empty()

        try:
            for i in range(1, 6):
                emergency_progress.progress(i * 0.2)
                emergency_status.info(f"ğŸ”§ ê¸´ê¸‰ ë³µêµ¬ ëª¨ë“œ {i}/5 ë‹¨ê³„...")
                time.sleep(0.5)

            # ìµœì†Œí•œì˜ Azure Config ìƒì„±
            from azure_config import AzureConfig

            minimal_config = AzureConfig()

            # ì§ì ‘ SQLite ì—°ê²° ìƒì„±
            import sqlite3

            class MinimalManager:
                def __init__(self):
                    self.use_sample_data = True
                    self.connection_type = "Minimal SQLite"
                    self.connection = sqlite3.connect(
                        ":memory:", check_same_thread=False
                    )
                    self._create_minimal_tables()

                def _create_minimal_tables(self):
                    cursor = self.connection.cursor()
                    cursor.execute(
                        "CREATE TABLE test (id INTEGER PRIMARY KEY, name TEXT)"
                    )
                    cursor.execute("INSERT INTO test (name) VALUES ('Emergency Mode')")
                    self.connection.commit()

                def test_connection(self):
                    try:
                        cursor = self.connection.cursor()
                        cursor.execute("SELECT COUNT(*) FROM test")
                        return True
                    except:
                        return False

                def execute_query(self, query):
                    return pd.DataFrame(
                        [{"message": "ê¸´ê¸‰ ëª¨ë“œì—ì„œëŠ” ì œí•œëœ ê¸°ëŠ¥ë§Œ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤."}]
                    ), {"success": True}

            minimal_manager = MinimalManager()

            if minimal_manager.test_connection():
                emergency_progress.progress(1.0)
                emergency_status.success("âœ… ê¸´ê¸‰ ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤. (ê¸°ëŠ¥ ì œí•œ)")
                time.sleep(1)
                # ğŸ”¥ ì¶”ê°€: ê¸´ê¸‰ ëª¨ë“œë„ UI ì •ë¦¬
                emergency_progress.empty()
                emergency_status.empty()
                return minimal_manager

        except Exception as minimal_e:
            # ğŸ”¥ ì¶”ê°€: ìµœì¢… ì‹¤íŒ¨ì‹œì—ë„ UI ì •ë¦¬
            emergency_progress.empty()
            emergency_status.empty()
            st.error(f"âŒ ê¸´ê¸‰ ëª¨ë“œ ì‹¤í–‰ë„ ì‹¤íŒ¨: {minimal_e}")

        return None


# ëŒ€ì‹œë³´ë“œ ë°ì´í„° ì¡°íšŒ (ìˆ˜ì •ëœ ë²„ì „)
@st.cache_data(ttl=300)  # 5ë¶„ ìºì‹œ
def get_dashboard_data(_db_manager):
    """ëŒ€ì‹œë³´ë“œìš© ë°ì´í„° ì¡°íšŒ - ì•ˆì „í•œ ì²˜ë¦¬"""

    if not _db_manager:
        return pd.DataFrame(), pd.DataFrame()

    try:
        port_in_query = """
        SELECT 
            FORMAT(TRT_DATE, 'yyyy-MM') as month,
            COUNT(*) as count,
            SUM(SETL_AMT) as amount,
            BCHNG_COMM_CMPN_ID as operator
        FROM PY_NP_SBSC_RMNY_TXN 
        WHERE TRT_DATE >= DATEADD(month, -3, GETDATE())
            AND NP_STTUS_CD IN ('OK', 'WD')
        GROUP BY FORMAT(TRT_DATE, 'yyyy-MM'), BCHNG_COMM_CMPN_ID
        ORDER BY month DESC
        """

        port_out_query = """
        SELECT 
            FORMAT(NP_TRMN_DATE, 'yyyy-MM') as month,
            COUNT(*) as count,
            SUM(PAY_AMT) as amount,
            ACHNG_COMM_CMPN_ID as operator
        FROM PY_NP_TRMN_RMNY_TXN 
        WHERE NP_TRMN_DATE >= DATEADD(month, -3, GETDATE())
            AND NP_TRMN_DTL_STTUS_VAL IN ('1', '3')
        GROUP BY FORMAT(NP_TRMN_DATE, 'yyyy-MM'), ACHNG_COMM_CMPN_ID
        ORDER BY month DESC
            """

        # ë°ì´í„°ë² ì´ìŠ¤ íƒ€ì…ì— ë”°ë¥¸ ì¿¼ë¦¬ ì„ íƒ
        # if _db_manager.use_sample_data:
        #     # SQLite ìƒ˜í”Œ ë°ì´í„°ìš© ì¿¼ë¦¬
        #     port_in_query = """
        #     SELECT
        #         strftime('%Y-%m', TRT_DATE) as month,
        #         COUNT(*) as count,
        #         SUM(SETL_AMT) as amount,
        #         BCHNG_COMM_CMPN_ID as operator
        #     FROM PY_NP_SBSC_RMNY_TXN
        #     WHERE TRT_DATE >= date('now', '-4 months')
        #         AND NP_STTUS_CD IN ('OK', 'WD')
        #     GROUP BY strftime('%Y-%m', TRT_DATE), BCHNG_COMM_CMPN_ID
        #     ORDER BY month DESC
        #     """

        #     port_out_query = """
        #     SELECT
        #         strftime('%Y-%m', NP_TRMN_DATE) as month,
        #         COUNT(*) as count,
        #         SUM(PAY_AMT) as amount,
        #         BCHNG_COMM_CMPN_ID as operator
        #     FROM PY_NP_TRMN_RMNY_TXN
        #     WHERE NP_TRMN_DATE >= date('now', '-4 months')
        #         AND NP_TRMN_DTL_STTUS_VAL IN ('1', '3')
        #     GROUP BY strftime('%Y-%m', NP_TRMN_DATE), BCHNG_COMM_CMPN_ID
        #     ORDER BY month DESC
        #     """
        # else:
        #     # Azure SQL Databaseìš© ì¿¼ë¦¬
        #     port_in_query = """
        #     SELECT
        #         FORMAT(TRT_DATE, 'yyyy-MM') as month,
        #         COUNT(*) as count,
        #         SUM(SETL_AMT) as amount,
        #         COMM_CMPN_NM as operator
        #     FROM PY_NP_SBSC_RMNY_TXN
        #     WHERE TRT_DATE >= DATEADD(month, -4, GETDATE())
        #         AND TRT_STUS_CD IN ('OK', 'WD')
        #     GROUP BY FORMAT(TRT_DATE, 'yyyy-MM'), COMM_CMPN_NM
        #     ORDER BY month DESC
        #     """

        #     port_out_query = """
        #     SELECT
        #         FORMAT(SETL_TRT_DATE, 'yyyy-MM') as month,
        #         COUNT(*) as count,
        #         SUM(PAY_AMT) as amount,
        #         COMM_CMPN_NM as operator
        #     FROM PY_NP_TRMN_RMNY_TXN
        #     WHERE SETL_TRT_DATE >= DATEADD(month, -4, GETDATE())
        #         AND NP_TRMN_DTL_STTUS_VAL IN ('1', '3')
        #     GROUP BY FORMAT(SETL_TRT_DATE, 'yyyy-MM'), COMM_CMPN_NM
        #     ORDER BY month DESC
        #     """

        # ì¿¼ë¦¬ ì‹¤í–‰
        port_in_df, _ = _db_manager.execute_query(port_in_query)
        port_out_df, _ = _db_manager.execute_query(port_out_query)

        return port_in_df, port_out_df

    except Exception as e:
        st.error(f"ğŸ“Š ëŒ€ì‹œë³´ë“œ ë°ì´í„° ì¡°íšŒ ì˜¤ë¥˜: {e}")
        return pd.DataFrame(), pd.DataFrame()


def generate_sql_with_openai(user_input, azure_config, is_azure=True):
    """OpenAIë¥¼ ì‚¬ìš©í•˜ì—¬ SQL ì¿¼ë¦¬ ìƒì„±"""

    try:
        # Azure OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        client = AzureOpenAI(
            api_key=azure_config.openai_api_key,
            api_version=azure_config.openai_api_version,
            azure_endpoint=azure_config.openai_endpoint,
        )

        # ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ì •ë³´
        schema_info = get_database_schema_info(azure_config, is_azure)

        # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        system_prompt = f"""
        ë‹¹ì‹ ì€ ë²ˆí˜¸ì´ë™ì •ì‚° ì‹œìŠ¤í…œì˜ SQL ì¿¼ë¦¬ ìƒì„± ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
        ì‚¬ìš©ìì˜ ìì—°ì–´ ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ì ì ˆí•œ SQL ì¿¼ë¦¬ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.

        ë°ì´í„°ë² ì´ìŠ¤ ì •ë³´:
        - íƒ€ì…: {'Azure SQL Database' if is_azure else 'SQLite'}
        - ìŠ¤í‚¤ë§ˆ: {schema_info}

        ê·œì¹™:
        1. ì „í™”ë²ˆí˜¸ëŠ” í•­ìƒ ë§ˆìŠ¤í‚¹ ì²˜ë¦¬ (ì• 3ìë¦¬ + **** + ë’¤ 4ìë¦¬)
        2. ë‚ ì§œ í•¨ìˆ˜ëŠ” ë°ì´í„°ë² ì´ìŠ¤ íƒ€ì…ì— ë§ê²Œ ì‚¬ìš©
        3. ê°œì¸ì •ë³´ ë³´í˜¸ë¥¼ ìœ„í•´ ë¯¼ê°í•œ ì •ë³´ëŠ” ì œí•œì ìœ¼ë¡œ ë…¸ì¶œ
        4. ê²°ê³¼ëŠ” ê°€ë…ì„± ìˆê²Œ í•œê¸€ ì»¬ëŸ¼ëª… ì‚¬ìš©
        5. ì„±ëŠ¥ì„ ìœ„í•´ ì ì ˆí•œ WHERE ì¡°ê±´ ì¶”ê°€

        ì‘ë‹µ í˜•ì‹: JSON
        {{
            "sql_query": "ìƒì„±ëœ SQL ì¿¼ë¦¬",
            "explanation": "ì¿¼ë¦¬ ì„¤ëª…",
            "confidence": 0.9 (0-1 ì‚¬ì´ì˜ ì‹ ë¢°ë„)
        }}
        """

        user_prompt = f"ë‹¤ìŒ ì§ˆë¬¸ì— ëŒ€í•œ SQL ì¿¼ë¦¬ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”: {user_input}"

        # OpenAI API í˜¸ì¶œ
        response = client.chat.completions.create(
            model=azure_config.openai_model_name,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt},
            ],
            temperature=0.1,
            max_tokens=1000,
        )

        # ì‘ë‹µ íŒŒì‹±
        response_content = response.choices[0].message.content

        try:
            # JSON ì‘ë‹µ íŒŒì‹± ì‹œë„
            result = json.loads(response_content)
            return {
                "sql_query": result.get("sql_query", ""),
                "explanation": result.get("explanation", ""),
                "confidence": result.get("confidence", 0.0),
                "source": "OpenAI",
            }
        except json.JSONDecodeError:
            # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ í…ìŠ¤íŠ¸ì—ì„œ SQL ì¶”ì¶œ ì‹œë„
            sql_match = re.search(r"```sql\n(.*?)\n```", response_content, re.DOTALL)
            if sql_match:
                return {
                    "sql_query": sql_match.group(1).strip(),
                    "explanation": "OpenAIì—ì„œ ìƒì„±ëœ ì¿¼ë¦¬",
                    "confidence": 0.8,
                    "source": "OpenAI",
                }
            else:
                raise Exception("OpenAI ì‘ë‹µì—ì„œ SQLì„ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

    except Exception as e:
        logger.warning(f"OpenAI SQL ìƒì„± ì‹¤íŒ¨: {e}")
        raise e


def get_database_schema_info(azure_config, is_azure=True):
    """ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ì •ë³´ ë°˜í™˜"""

    # schema = {
    #     "tables": {
    #         "PY_NP_SBSC_RMNY_TXN": {
    #             "description": "ë²ˆí˜¸ì´ë™ ê°€ì… ì •ì‚° ê±°ë˜",
    #             "columns": {
    #                 "TEL_NO": "ì „í™”ë²ˆí˜¸",
    #                 "TRT_DATE": "ê±°ë˜ì¼ì",
    #                 "SETL_AMT": "ì •ì‚°ê¸ˆì•¡",
    #                 "BCHNG_COMM_CMPN_ID": "ì „ì‚¬ì—…ìID",
    #                 "ACHNG_COMM_CMPN_ID": "í›„ì‚¬ì—…ìID",
    #                 "NP_STTUS_CD": "ë²ˆí˜¸ì´ë™ìƒíƒœì½”ë“œ",
    #                 "SVC_CONT_ID": "ì„œë¹„ìŠ¤ê³„ì•½ID",
    #             },
    #         },
    #         "PY_NP_TRMN_RMNY_TXN": {
    #             "description": "ë²ˆí˜¸ì´ë™ í•´ì§€ ì •ì‚° ê±°ë˜",
    #             "columns": {
    #                 "TEL_NO": "ì „í™”ë²ˆí˜¸",
    #                 "NP_TRMN_DATE": "ë²ˆí˜¸ì´ë™í•´ì§€ì¼ì",
    #                 "PAY_AMT": "ì§€ê¸‰ê¸ˆì•¡",
    #                 "BCHNG_COMM_CMPN_ID": "ì „ì‚¬ì—…ìID",
    #                 "ACHNG_COMM_CMPN_ID": "í›„ì‚¬ì—…ìID",
    #                 "NP_TRMN_DTL_STTUS_VAL": "í•´ì§€ìƒì„¸ìƒíƒœê°’",
    #                 "SVC_CONT_ID": "ì„œë¹„ìŠ¤ê³„ì•½ID",
    #             },
    #         },
    #         "PY_DEPAZ_BAS": {
    #             "description": "ì˜ˆì¹˜ê¸ˆ ê¸°ë³¸",
    #             "columns": {
    #                 "RMNY_DATE": "ìˆ˜ë‚©ì¼ì",
    #                 "DEPAZ_AMT": "ì˜ˆì¹˜ê¸ˆì•¡",
    #                 "DEPAZ_DIV_CD": "ì˜ˆì¹˜ê¸ˆêµ¬ë¶„ì½”ë“œ",
    #                 "RMNY_METH_CD": "ìˆ˜ë‚©ë°©ë²•ì½”ë“œ",
    #             },
    #         },
    #     },
    #     "common_filters": {
    #         "port_in_status": "NP_STTUS_CD IN ('OK', 'WD')",
    #         "port_out_status": "NP_TRMN_DTL_STTUS_VAL IN ('1', '3')",
    #         "deposit_status": "DEPAZ_DIV_CD = '10' AND RMNY_METH_CD = 'NA'",
    #     },
    # }

    # ìˆ˜ì •: sql_generator.pyì˜ SQLGeneratorë¥¼ ì‚¬ìš©í•˜ì—¬ ìŠ¤í‚¤ë§ˆ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
    # SQLGenerator ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
    sql_generator = SQLGenerator(azure_config)
    schema = sql_generator._load_schema()

    return json.dumps(schema, ensure_ascii=False, indent=2)


def generate_sql_query(user_input, is_azure=True, azure_config=None):
    """ì‚¬ìš©ì ì…ë ¥ì„ SQL ì¿¼ë¦¬ë¡œ ë³€í™˜ (OpenAI ìš°ì„ , ê·œì¹™ ê¸°ë°˜ í´ë°±)"""

    # 1. OpenAI ì‚¬ìš© ì‹œë„ (ìš°ì„ ìˆœìœ„)
    if (
        azure_config
        and hasattr(azure_config, "openai_api_key")
        and azure_config.openai_api_key
    ):
        try:
            logger.info("OpenAIë¥¼ ì‚¬ìš©í•˜ì—¬ SQL ì¿¼ë¦¬ ìƒì„± ì‹œë„")
            openai_result = generate_sql_with_openai(user_input, azure_config, is_azure)

            # ì‹ ë¢°ë„ê°€ ë†’ìœ¼ë©´ OpenAI ê²°ê³¼ ì‚¬ìš©
            if openai_result.get("confidence", 0) > 0.7:
                logger.info(
                    f"OpenAI ì¿¼ë¦¬ ìƒì„± ì„±ê³µ (ì‹ ë¢°ë„: {openai_result.get('confidence')})"
                )
                return openai_result["sql_query"]
            else:
                logger.warning("OpenAI ì‹ ë¢°ë„ê°€ ë‚®ì•„ ê·œì¹™ ê¸°ë°˜ìœ¼ë¡œ í´ë°±")

        except Exception as e:
            logger.warning(f"OpenAI ì¿¼ë¦¬ ìƒì„± ì‹¤íŒ¨, ê·œì¹™ ê¸°ë°˜ìœ¼ë¡œ í´ë°±: {e}")

    # 2. ê·œì¹™ ê¸°ë°˜ ì¿¼ë¦¬ ìƒì„± (í´ë°±)
    logger.info("ê·œì¹™ ê¸°ë°˜ SQL ì¿¼ë¦¬ ìƒì„± ì‚¬ìš©")
    return generate_rule_based_sql_query(user_input, is_azure)


# SQL ì¿¼ë¦¬ ìƒì„± í•¨ìˆ˜ (ìˆ˜ì •ëœ ë²„ì „)
def generate_rule_based_sql_query(user_input, is_azure=True):
    """ì‚¬ìš©ì ì…ë ¥ì„ SQL ì¿¼ë¦¬ë¡œ ë³€í™˜ (Azure SQL/SQLite í˜¸í™˜)"""

    user_input_lower = user_input.lower()

    # ë‚ ì§œ í•¨ìˆ˜ ë§¤í•‘
    date_func = {
        "now_minus_months": lambda months: (
            f"DATEADD(month, -{months}, GETDATE())"
            #if is_azure
            #else f"date('now', '-{months} months')"
        ),
        "format_month": lambda col: (
            f"FORMAT({col}, 'yyyy-MM')" #if is_azure else f"strftime('%Y-%m', {col})"
        ),
        "substr_phone": lambda col: (
            f"LEFT({col}, 3) + '****' + RIGHT({col}, 4)"
            #if is_azure
            #else f"SUBSTR({col}, 1, 3) || '****' || SUBSTR({col}, -4)"
        ),
    }

    # 1. ì›”ë³„ ì§‘ê³„ ì¿¼ë¦¬
    # if "ì›”ë³„" in user_input_lower or "ì¶”ì´" in user_input_lower:
    #     if "í¬íŠ¸ì¸" in user_input_lower:
    #         return f"""
    #         SELECT 
    #             {date_func['format_month']('TRT_DATE')} as ë²ˆí˜¸ì´ë™ì›”,
    #             BCHNG_COMM_CMPN_ID as ì „ì‚¬ì—…ì,
    #             COUNT(*) as ì´ê±´ìˆ˜,
    #             SUM(SETL_AMT) as ì´ê¸ˆì•¡,
    #             {'ROUND(AVG(SETL_AMT), 0)' if not is_azure else 'CAST(AVG(SETL_AMT) AS INT)'} as ì •ì‚°ê¸ˆì•¡í‰ê· 
    #         FROM PY_NP_SBSC_RMNY_TXN 
    #         WHERE TRT_DATE >= {date_func['now_minus_months'](6)}
    #             AND NP_STTUS_CD IN ('OK', 'WD')
    #         GROUP BY {date_func['format_month']('TRT_DATE')}, BCHNG_COMM_CMPN_ID
    #         ORDER BY ë²ˆí˜¸ì´ë™ì›” DESC, ì´ê¸ˆì•¡ DESC
    #         """
    #     elif "í¬íŠ¸ì•„ì›ƒ" in user_input_lower:
    #         return f"""
    #         SELECT 
    #             {date_func['format_month']('NP_TRMN_DATE')} as ë²ˆí˜¸ì´ë™ì›”,
    #             BCHNG_COMM_CMPN_ID as ì „ì‚¬ì—…ì,
    #             COUNT(*) as ì´ê±´ìˆ˜,
    #             SUM(PAY_AMT) as ì´ê¸ˆì•¡,
    #             {'ROUND(AVG(PAY_AMT), 0)' if not is_azure else 'CAST(AVG(PAY_AMT) AS INT)'} as ì •ì‚°ê¸ˆì•¡í‰ê· 
    #         FROM PY_NP_TRMN_RMNY_TXN 
    #         WHERE NP_TRMN_DATE IS NOT NULL 
    #             AND NP_TRMN_DATE >= {date_func['now_minus_months'](4)}
    #             AND NP_TRMN_DTL_STTUS_VAL IN ('1', '3')
    #         GROUP BY {date_func['format_month']('NP_TRMN_DATE')}, BCHNG_COMM_CMPN_ID
    #         ORDER BY ë²ˆí˜¸ì´ë™ì›” DESC, ì´ê¸ˆì•¡ DESC
    #         """

    # 1. ì›”ë³„ ì§‘ê³„ ì¿¼ë¦¬
    if "ì›”ë³„" in user_input_lower or "ì¶”ì´" in user_input_lower:
        if "í¬íŠ¸ì¸" in user_input_lower:
            return f"""
            SELECT 
                {date_func['format_month']('TRT_DATE')} as ë²ˆí˜¸ì´ë™ì›”,
                BCHNG_COMM_CMPN_ID as ì „ì‚¬ì—…ì,
                COUNT(*) as ì´ê±´ìˆ˜,
                SUM(SETL_AMT) as ì´ê¸ˆì•¡,
                CAST(AVG(SETL_AMT) AS INT) as ì •ì‚°ê¸ˆì•¡í‰ê· 
            FROM PY_NP_SBSC_RMNY_TXN 
            WHERE TRT_DATE >= {date_func['now_minus_months'](6)}
                AND NP_STTUS_CD IN ('OK', 'WD')
            GROUP BY {date_func['format_month']('TRT_DATE')}, BCHNG_COMM_CMPN_ID
            ORDER BY ë²ˆí˜¸ì´ë™ì›” DESC, ì´ê¸ˆì•¡ DESC
            """
        elif "í¬íŠ¸ì•„ì›ƒ" in user_input_lower:
            return f"""
            SELECT 
                {date_func['format_month']('NP_TRMN_DATE')} as ë²ˆí˜¸ì´ë™ì›”,
                BCHNG_COMM_CMPN_ID as ì „ì‚¬ì—…ì,
                COUNT(*) as ì´ê±´ìˆ˜,
                SUM(PAY_AMT) as ì´ê¸ˆì•¡,
                CAST(AVG(PAY_AMT) AS INT) as ì •ì‚°ê¸ˆì•¡í‰ê· 
            FROM PY_NP_TRMN_RMNY_TXN 
            WHERE NP_TRMN_DATE IS NOT NULL 
                AND NP_TRMN_DATE >= {date_func['now_minus_months'](4)}
                AND NP_TRMN_DTL_STTUS_VAL IN ('1', '3')
            GROUP BY {date_func['format_month']('NP_TRMN_DATE')}, BCHNG_COMM_CMPN_ID
            ORDER BY ë²ˆí˜¸ì´ë™ì›” DESC, ì´ê¸ˆì•¡ DESC
            """

    # 2. ì „í™”ë²ˆí˜¸ ê²€ìƒ‰ (ë§ˆìŠ¤í‚¹ ì ìš©)
    phone_match = re.search(r"010[- ]?\d{4}[- ]?\d{4}", user_input)
    if phone_match:
        phone = phone_match.group().replace("-", "").replace(" ", "")
        return f"""
        SELECT 
            'PORT_IN' as ë²ˆí˜¸ì´ë™íƒ€ì…,
            TRT_DATE as ë²ˆí˜¸ì´ë™ì¼,
            {date_func['substr_phone']('TEL_NO')} as ì „í™”ë²ˆí˜¸,
            SVC_CONT_ID,
            SETL_AMT as ì •ì‚°ê¸ˆì•¡,
            BCHNG_COMM_CMPN_ID as ì „ì‚¬ì—…ì,
            ACHNG_COMM_CMPN_ID as í›„ì‚¬ì—…ì,
            NP_STTUS_CD as ìƒíƒœ
        FROM PY_NP_SBSC_RMNY_TXN 
        WHERE TEL_NO = '{phone}' AND NP_STTUS_CD IN ('OK', 'WD')
        UNION ALL
        SELECT 
            'PORT_OUT' as ë²ˆí˜¸ì´ë™íƒ€ì…,
            NP_TRMN_DATE as ë²ˆí˜¸ì´ë™ì¼,
            {date_func['substr_phone']('TEL_NO')} as ì „í™”ë²ˆí˜¸,
            SVC_CONT_ID,
            PAY_AMT as ì •ì‚°ê¸ˆì•¡,
            BCHNG_COMM_CMPN_ID as ì „ì‚¬ì—…ì,
            ACHNG_COMM_CMPN_ID as í›„ì‚¬ì—…ì,
            NP_TRMN_DTL_STTUS_VAL as ìƒíƒœ
        FROM PY_NP_TRMN_RMNY_TXN 
        WHERE TEL_NO = '{phone}' AND NP_TRMN_DTL_STTUS_VAL IN ('1', '3')
        ORDER BY ë²ˆí˜¸ì´ë™ì¼ DESC
        """

    # 3. ì‚¬ì—…ìë³„ í˜„í™©
    if any(
        keyword in user_input_lower
        for keyword in ["ì‚¬ì—…ì", "íšŒì‚¬", "í†µì‹ ì‚¬", "skt", "kt", "lg"]
    ):
        operator_filter = ""
        if "skt" in user_input_lower or "sk" in user_input_lower:
            operator_filter = (
                "AND (BCHNG_COMM_CMPN_ID = 'SKT' OR ACHNG_COMM_CMPN_ID = 'SKT')"
            )
        elif "kt" in user_input_lower:
            operator_filter = (
                "AND (BCHNG_COMM_CMPN_ID = 'KT' OR ACHNG_COMM_CMPN_ID = 'KT')"
            )
        elif "lg" in user_input_lower:
            operator_filter = (
                "AND (BCHNG_COMM_CMPN_ID = 'LGU+' OR ACHNG_COMM_CMPN_ID = 'LGU+')"
            )

        # return f"""
        # SELECT 
        #     BCHNG_COMM_CMPN_ID as ì‚¬ì—…ì,
        #     'PORT_IN' as ë²ˆí˜¸ì´ë™íƒ€ì…,
        #     COUNT(*) as ë²ˆí˜¸ì´ë™ê±´ìˆ˜,
        #     SUM(SETL_AMT) as ì´ì •ì‚°ê¸ˆì•¡,
        #     {'ROUND(AVG(SETL_AMT), 0)' if not is_azure else 'CAST(AVG(SETL_AMT) AS INT)'} as ì •ì‚°ê¸ˆì•¡í‰ê· ,
        #     {'MIN(TRT_DATE)' if not is_azure else 'MIN(CAST(TRT_DATE AS DATE))'} as ìµœì´ˆì¼ì,
        #     {'MAX(TRT_DATE)' if not is_azure else 'MAX(CAST(TRT_DATE AS DATE))'} as ìµœì‹ ì¼ì
        # FROM PY_NP_SBSC_RMNY_TXN
        # WHERE TRT_DATE >= {date_func['now_minus_months'](3)}
        #     AND NP_STTUS_CD IN ('OK', 'WD')
        #     {operator_filter}
        # GROUP BY BCHNG_COMM_CMPN_ID
        # UNION ALL
        # SELECT 
        #     BCHNG_COMM_CMPN_ID as ì‚¬ì—…ì,
        #     'PORT_OUT' as ë²ˆí˜¸ì´ë™íƒ€ì…,
        #     COUNT(*) as ë²ˆí˜¸ì´ë™ê±´ìˆ˜,
        #     SUM(PAY_AMT) as ì´ì •ì‚°ê¸ˆì•¡,
        #     {'ROUND(AVG(PAY_AMT), 0)' if not is_azure else 'CAST(AVG(PAY_AMT) AS INT)'} as ì •ì‚°ê¸ˆì•¡í‰ê· ,
        #     {'MIN(NP_TRMN_DATE)' if not is_azure else 'MIN(CAST(NP_TRMN_DATE AS DATE))'} as ìµœì´ˆì¼ì,
        #     {'MAX(NP_TRMN_DATE)' if not is_azure else 'MAX(CAST(NP_TRMN_DATE AS DATE))'} as ìµœì‹ ì¼ì
        # FROM PY_NP_TRMN_RMNY_TXN
        # WHERE NP_TRMN_DATE IS NOT NULL 
        #     AND NP_TRMN_DATE >= {date_func['now_minus_months'](3)}
        #     AND NP_TRMN_DTL_STTUS_VAL IN ('1', '3')
        #     {operator_filter}
        # GROUP BY BCHNG_COMM_CMPN_ID
        # ORDER BY ì‚¬ì—…ì, ë²ˆí˜¸ì´ë™íƒ€ì…
        # """
        return f"""
        SELECT 
            BCHNG_COMM_CMPN_ID as ì‚¬ì—…ì,
            'PORT_IN' as ë²ˆí˜¸ì´ë™íƒ€ì…,
            COUNT(*) as ë²ˆí˜¸ì´ë™ê±´ìˆ˜,
            SUM(SETL_AMT) as ì´ì •ì‚°ê¸ˆì•¡,
            {'ROUND(AVG(SETL_AMT), 0)' if not is_azure else 'CAST(AVG(SETL_AMT) AS INT)'} as ì •ì‚°ê¸ˆì•¡í‰ê· ,
            MIN(CAST(TRT_DATE AS DATE)) as ìµœì´ˆì¼ì,
            MAX(CAST(TRT_DATE AS DATE)) as ìµœì‹ ì¼ì
        FROM PY_NP_SBSC_RMNY_TXN
        WHERE TRT_DATE >= {date_func['now_minus_months'](3)}
            AND NP_STTUS_CD IN ('OK', 'WD')
            {operator_filter}
        GROUP BY BCHNG_COMM_CMPN_ID
        UNION ALL
        SELECT 
            BCHNG_COMM_CMPN_ID as ì‚¬ì—…ì,
            'PORT_OUT' as ë²ˆí˜¸ì´ë™íƒ€ì…,
            COUNT(*) as ë²ˆí˜¸ì´ë™ê±´ìˆ˜,
            SUM(PAY_AMT) as ì´ì •ì‚°ê¸ˆì•¡,
            CAST(AVG(PAY_AMT) AS INT)' as ì •ì‚°ê¸ˆì•¡í‰ê· ,
            MIN(CAST(NP_TRMN_DATE AS DATE))' as ìµœì´ˆì¼ì,
            MAX(CAST(NP_TRMN_DATE AS DATE))' as ìµœì‹ ì¼ì
        FROM PY_NP_TRMN_RMNY_TXN
        WHERE NP_TRMN_DATE IS NOT NULL 
            AND NP_TRMN_DATE >= {date_func['now_minus_months'](3)}
            AND NP_TRMN_DTL_STTUS_VAL IN ('1', '3')
            {operator_filter}
        GROUP BY BCHNG_COMM_CMPN_ID
        ORDER BY ì‚¬ì—…ì, ë²ˆí˜¸ì´ë™íƒ€ì…
        """

    # # 4. ì˜ˆì¹˜ê¸ˆ ì¡°íšŒ
    # if "ì˜ˆì¹˜ê¸ˆ" in user_input_lower:
    #     return f"""
    #     SELECT 
    #         {date_func['format_month']('RMNY_DATE')} as ìˆ˜ë‚©ì›”,
    #         COUNT(*) as ì´ê±´ìˆ˜,
    #         SUM(DEPAZ_AMT) as ì´ê¸ˆì•¡,
    #         {'ROUND(AVG(DEPAZ_AMT), 0)' if not is_azure else 'CAST(AVG(DEPAZ_AMT) AS INT)'} as í‰ê· ê¸ˆì•¡,
    #         MIN(DEPAZ_AMT) as ìµœì†Œê¸ˆì•¡,
    #         MAX(DEPAZ_AMT) as ìµœëŒ€ê¸ˆì•¡,
    #         DEPAZ_DIV_CD as ì˜ˆì¹˜ê¸ˆêµ¬ë¶„,
    #         RMNY_METH_CD as ìˆ˜ë‚©ë°©ë²•
    #     FROM PY_DEPAZ_BAS
    #     WHERE RMNY_DATE >= {date_func['now_minus_months'](3)}
    #         AND DEPAZ_DIV_CD = '10'
    #         AND RMNY_METH_CD = 'NA'
    #     GROUP BY {date_func['format_month']('RMNY_DATE')}, DEPAZ_DIV_CD, RMNY_METH_CD
    #     ORDER BY ìˆ˜ë‚©ì›” DESC
    #     """
        # 4. ì˜ˆì¹˜ê¸ˆ ì¡°íšŒ
    if "ì˜ˆì¹˜ê¸ˆ" in user_input_lower:
        return f"""
        SELECT 
            {date_func['format_month']('RMNY_DATE')} as ìˆ˜ë‚©ì›”,
            COUNT(*) as ì´ê±´ìˆ˜,
            SUM(DEPAZ_AMT) as ì´ê¸ˆì•¡,
            CAST(AVG(DEPAZ_AMT) AS INT) as í‰ê· ê¸ˆì•¡,
            MIN(DEPAZ_AMT) as ìµœì†Œê¸ˆì•¡,
            MAX(DEPAZ_AMT) as ìµœëŒ€ê¸ˆì•¡,
            DEPAZ_DIV_CD as ì˜ˆì¹˜ê¸ˆêµ¬ë¶„,
            RMNY_METH_CD as ìˆ˜ë‚©ë°©ë²•
        FROM PY_DEPAZ_BAS
        WHERE RMNY_DATE >= {date_func['now_minus_months'](3)}
            AND DEPAZ_DIV_CD = '10'
            AND RMNY_METH_CD = 'NA'
        GROUP BY {date_func['format_month']('RMNY_DATE')}, DEPAZ_DIV_CD, RMNY_METH_CD
        ORDER BY ìˆ˜ë‚©ì›” DESC
        """

    # ê¸°ë³¸ ì¿¼ë¦¬
    return """
    SELECT 
        'OpenAI ë° ê·œì¹™ ê¸°ë°˜ ì¿¼ë¦¬ ìƒì„±ì„ ì‹œë„í–ˆìœ¼ë‚˜ ì ì ˆí•œ ì¿¼ë¦¬ë¥¼ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤' as ë©”ì‹œì§€,
        'ë” êµ¬ì²´ì ìœ¼ë¡œ ì§ˆë¬¸í•´ì£¼ì‹œê±°ë‚˜ ì˜ˆì‹œ ì¿¼ë¦¬ë¥¼ ì‚¬ìš©í•´ë³´ì„¸ìš”' as ì•ˆë‚´
    """


# ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜
def main():
    # ë°ì´í„°ë² ì´ìŠ¤ ë§¤ë‹ˆì € ì´ˆê¸°í™” (Azure ìš°ì„ )
    db_manager = init_database_manager()

    if not db_manager:
        st.error("ğŸ”¥ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì‹œìŠ¤í…œ ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”.")
        st.stop()

    # í—¤ë”
    st.markdown(
        """
    <div class="main-header">
        <h1>ğŸ“Š ë²ˆí˜¸ì´ë™ì •ì‚° AI ë¶„ì„ ì‹œìŠ¤í…œ</h1>
        <p>ğŸ¤– Azure í´ë¼ìš°ë“œ ê¸°ë°˜ ì‹¤ì‹œê°„ ë°ì´í„° ë¶„ì„ í”Œë«í¼</p>
        <p><small>âœ¨ Azure SQL Database + OpenAI GPT-4 ì—°ë™</small></p>
    </div>
    """,
        unsafe_allow_html=True,
    )

    # ì‹¤ì‹œê°„ ëŒ€ì‹œë³´ë“œ
    st.header("ğŸ“ˆ ë²ˆí˜¸ì´ë™ ì¶”ì´ ë¶„ì„ ëŒ€ì‹œë³´ë“œ")

    with st.spinner("ğŸ“Š Azure ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ìµœì‹  ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
        port_in_df, port_out_df = get_dashboard_data(db_manager)

    # ë©”íŠ¸ë¦­ ì¹´ë“œ í‘œì‹œ
    display_metrics(port_in_df, port_out_df)

    # ì¶”ì´ ì°¨íŠ¸ í‘œì‹œ
    display_charts(port_in_df, port_out_df)

    # êµ¬ë¶„ì„ 
    st.markdown("---")

    # AI ì±—ë´‡ ì„¹ì…˜ (DatabaseManager ì „ë‹¬)
    display_chatbot(db_manager)

    # ì‚¬ì´ë“œë°” (DatabaseManager ì „ë‹¬)
    display_sidebar(db_manager)


def display_connection_status(connection_info, is_fallback=False):
    """ì—°ê²° ìƒíƒœ í‘œì‹œ"""

    if is_fallback:
        st.markdown(
            """
        <div class="error-alert">
            âš ï¸ Azure ì—°ê²° ì‹¤íŒ¨ë¡œ ë¡œì»¬ ëª¨ë“œë¡œ ì „í™˜ë˜ì—ˆìŠµë‹ˆë‹¤
        </div>
        """,
            unsafe_allow_html=True,
        )

    connection_type = connection_info["type"]

    if connection_type == "Azure SQL Database":
        st.markdown(
            """
        <div class="azure-status">
            â˜ï¸ Azure SQL Database ì—°ê²°ë¨ | ì‹¤ì‹œê°„ ë°ì´í„° ì‚¬ìš©
        </div>
        """,
            unsafe_allow_html=True,
        )
    else:
        st.markdown(
            """
        <div class="local-status">
            ğŸ’» ë¡œì»¬ SQLite ëª¨ë“œ | ìƒ˜í”Œ ë°ì´í„° ì‚¬ìš©
        </div>
        """,
            unsafe_allow_html=True,
        )


def display_metrics(port_in_df, port_out_df):
    """ì£¼ìš” ë©”íŠ¸ë¦­ í‘œì‹œ"""

    col1, col2, col3, col4 = st.columns(4)

    # ì´ ê±´ìˆ˜ ë° ê¸ˆì•¡ ê³„ì‚°
    total_port_in = port_in_df["count"].sum() if not port_in_df.empty else 0
    total_port_out = port_out_df["count"].sum() if not port_out_df.empty else 0
    total_in_amount = port_in_df["amount"].sum() if not port_in_df.empty else 0
    total_out_amount = port_out_df["amount"].sum() if not port_out_df.empty else 0

    with col1:
        st.metric(
            label="ğŸ“¥ ì´ í¬íŠ¸ì¸",
            value=f"{total_port_in:,}ê±´",
            delta=(
                f"+{total_port_in - total_port_out}ê±´"
                if total_port_in > total_port_out
                else None
            ),
        )

    with col2:
        st.metric(
            label="ğŸ“¤ ì´ í¬íŠ¸ì•„ì›ƒ",
            value=f"{total_port_out:,}ê±´",
            delta=(
                f"{total_port_out - total_port_in:+,}ê±´"
                if total_port_out != total_port_in
                else None
            ),
        )

    with col3:
        st.metric(
            label="ğŸ’° í¬íŠ¸ì¸ ì •ì‚°ì•¡",
            value=f"{total_in_amount:,.0f}ì›",
            delta=f"í‰ê·  {total_in_amount/max(total_port_in,1):,.0f}ì›/ê±´",
        )

    with col4:
        st.metric(
            label="ğŸ’¸ í¬íŠ¸ì•„ì›ƒ ì •ì‚°ì•¡",
            value=f"{total_out_amount:,.0f}ì›",
            delta=f"í‰ê·  {total_out_amount/max(total_port_out,1):,.0f}ì›/ê±´",
        )


def display_charts(port_in_df, port_out_df):
    """ì¶”ì´ ì°¨íŠ¸ í‘œì‹œ"""

    if not port_in_df.empty or not port_out_df.empty:
        # ì›”ë³„ ì´ ê±´ìˆ˜ ì§‘ê³„
        port_in_monthly = (
            port_in_df.groupby("month")
            .agg({"count": "sum", "amount": "sum"})
            .reset_index()
            if not port_in_df.empty
            else pd.DataFrame()
        )
        port_out_monthly = (
            port_out_df.groupby("month")
            .agg({"count": "sum", "amount": "sum"})
            .reset_index()
            if not port_out_df.empty
            else pd.DataFrame()
        )

        # 2x2 ì„œë¸Œí”Œë¡¯ ìƒì„±
        fig = make_subplots(
            rows=2,
            cols=2,
            subplot_titles=(
                "ğŸ“Š ì›”ë³„ ê±´ìˆ˜ ì¶”ì´",
                "ğŸ’° ì›”ë³„ ì •ì‚°ì•¡ ì¶”ì´",
                "ğŸ¢ ì‚¬ì—…ìë³„ í¬íŠ¸ì¸ í˜„í™©",
                "ğŸ“ˆ ì‚¬ì—…ìë³„ í¬íŠ¸ì•„ì›ƒ í˜„í™©",
            ),
            specs=[
                [{"secondary_y": False}, {"secondary_y": False}],
                [{"secondary_y": False}, {"secondary_y": False}],
            ],
        )

        # 1. ì›”ë³„ ê±´ìˆ˜ ì¶”ì´
        if not port_in_monthly.empty:
            fig.add_trace(
                go.Scatter(
                    x=port_in_monthly["month"],
                    y=port_in_monthly["count"],
                    mode="lines+markers",
                    name="í¬íŠ¸ì¸",
                    line=dict(color="#1f77b4"),
                ),
                row=1,
                col=1,
            )

        if not port_out_monthly.empty:
            fig.add_trace(
                go.Scatter(
                    x=port_out_monthly["month"],
                    y=port_out_monthly["count"],
                    mode="lines+markers",
                    name="í¬íŠ¸ì•„ì›ƒ",
                    line=dict(color="#ff7f0e"),
                ),
                row=1,
                col=1,
            )

        # 2. ì›”ë³„ ì •ì‚°ì•¡ ì¶”ì´
        if not port_in_monthly.empty:
            fig.add_trace(
                go.Scatter(
                    x=port_in_monthly["month"],
                    y=port_in_monthly["amount"],
                    mode="lines+markers",
                    name="í¬íŠ¸ì¸ ê¸ˆì•¡",
                    line=dict(color="#2ca02c"),
                ),
                row=1,
                col=2,
            )

        if not port_out_monthly.empty:
            fig.add_trace(
                go.Scatter(
                    x=port_out_monthly["month"],
                    y=port_out_monthly["amount"],
                    mode="lines+markers",
                    name="í¬íŠ¸ì•„ì›ƒ ê¸ˆì•¡",
                    line=dict(color="#d62728"),
                ),
                row=1,
                col=2,
            )

        # 3. ì‚¬ì—…ìë³„ í¬íŠ¸ì¸ í˜„í™©
        if not port_in_df.empty:
            port_in_by_operator = (
                port_in_df.groupby("operator")["count"].sum().reset_index()
            )
            fig.add_trace(
                go.Bar(
                    x=port_in_by_operator["operator"],
                    y=port_in_by_operator["count"],
                    name="í¬íŠ¸ì¸ ì‚¬ì—…ìë³„",
                    marker_color="#1f77b4",
                ),
                row=2,
                col=1,
            )

        # 4. ì‚¬ì—…ìë³„ í¬íŠ¸ì•„ì›ƒ í˜„í™©
        if not port_out_df.empty:
            port_out_by_operator = (
                port_out_df.groupby("operator")["count"].sum().reset_index()
            )
            fig.add_trace(
                go.Bar(
                    x=port_out_by_operator["operator"],
                    y=port_out_by_operator["count"],
                    name="í¬íŠ¸ì•„ì›ƒ ì‚¬ì—…ìë³„",
                    marker_color="#ff7f0e",
                ),
                row=2,
                col=2,
            )

        fig.update_layout(
            height=800, showlegend=True, title_text="ğŸ“Š ë²ˆí˜¸ì´ë™ ì¢…í•© ë¶„ì„ ëŒ€ì‹œë³´ë“œ"
        )
        st.plotly_chart(fig, use_container_width=True)
    else:
        st.info("ğŸ“Š í‘œì‹œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ìƒ˜í”Œ ë°ì´í„°ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.")


def display_chatbot(db_manager):
    """AI ì±—ë´‡ ì¸í„°í˜ì´ìŠ¤ - ëŒ€í™”í˜• êµ¬ì¡°"""

    st.header("ğŸ¤– Azure OpenAI ê¸°ë°˜ ìì—°ì–´ SQL ì¿¼ë¦¬ ìƒì„±")

    # ğŸ”¥ ìˆ˜ì •: SQL ìƒì„±ê¸° ì´ˆê¸°í™” ê°œì„ 
    def initialize_sql_generator():
        """ì•ˆì „í•œ SQL ìƒì„±ê¸° ì´ˆê¸°í™”"""
        try:
            azure_config = get_azure_config()
            
            # Azure OpenAI ì„¤ì • í™•ì¸
            if not azure_config.openai_api_key or not azure_config.openai_endpoint:
                st.warning("âš ï¸ Azure OpenAI ì„¤ì •ì´ ì™„ì „í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ê·œì¹™ ê¸°ë°˜ ì¿¼ë¦¬ë§Œ ì‚¬ìš©ë©ë‹ˆë‹¤.")
                return None
            
            # SQLGenerator ìƒì„± ì‹œë„
            sql_generator = SQLGenerator(azure_config)
            st.success("âœ… Azure OpenAI SQL ìƒì„±ê¸°ê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤!")
            return sql_generator
            
        except Exception as e:
            st.error(f"âŒ SQL ìƒì„±ê¸° ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            st.info("ğŸ’¡ ê·œì¹™ ê¸°ë°˜ ì¿¼ë¦¬ ìƒì„±ê¸°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            return None

    # SQL ìƒì„±ê¸° ì´ˆê¸°í™” (ì„¸ì…˜ë³„ 1íšŒë§Œ)
    if "sql_generator" not in st.session_state:
        with st.spinner("ğŸ”§ AI ì¿¼ë¦¬ ìƒì„±ê¸°ë¥¼ ì´ˆê¸°í™”í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
            st.session_state.sql_generator = initialize_sql_generator()
    
    # SQL ìƒì„±ê¸° ìƒíƒœ í‘œì‹œ
    if st.session_state.sql_generator is None:
        st.info("ğŸ”§ í˜„ì¬ ê·œì¹™ ê¸°ë°˜ ì¿¼ë¦¬ ìƒì„±ê¸°ë¥¼ ì‚¬ìš© ì¤‘ì…ë‹ˆë‹¤.")
    else:
        st.success("ğŸ¤– Azure OpenAI ê¸°ë°˜ AI ì¿¼ë¦¬ ìƒì„±ê¸°ê°€ í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤!")

    # ëŒ€í™” íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”
    if "conversation_history" not in st.session_state:
        st.session_state.conversation_history = []

    # í˜„ì¬ ì…ë ¥ ì´ˆê¸°í™”
    if "current_input" not in st.session_state:
        st.session_state.current_input = ""

    # ì˜ˆì‹œ ì¿¼ë¦¬ ë²„íŠ¼ë“¤ - ì„¸ë¡œ ë°°ì¹˜
    st.subheader("ğŸ’¡ ë¹ ë¥¸ ì¿¼ë¦¬ ì˜ˆì‹œ")
    quick_examples = [
        ("ğŸ“Š ì›”ë³„ í¬íŠ¸ì¸ í˜„í™©", "ì›”ë³„ í¬íŠ¸ì¸ í˜„í™©ì„ ì•Œë ¤ì¤˜"),
        ("ğŸ” íŠ¹ì • ë²ˆí˜¸ ì¡°íšŒ", "TEL_NOê°€ 01012345678ì¸ ë²ˆí˜¸ì˜ ì •ì‚° ë‚´ì—­ í™•ì¸í•´ì¤˜"),
        ("ğŸ“ˆ ì‚¬ì—…ìë³„ ì§‘ê³„", "ì‚¬ì—…ìë³„ ë²ˆí˜¸ì´ë™ ì •ì‚° í˜„í™© ë³´ì—¬ì¤˜"),
    ]
    for idx, (label, value) in enumerate(quick_examples):
        if st.button(label, key=f"quick_{idx}"):
            st.session_state.current_input = value

    # ì¶”ê°€ ì˜ˆì‹œë“¤
    with st.expander("ğŸ¯ ë” ë§ì€ ì˜ˆì‹œ"):
        examples = [
            "ìµœê·¼ 3ê°œì›” í¬íŠ¸ì•„ì›ƒ í˜„í™© ì•Œë ¤ì¤˜",
            "01012345678 ë°ì´í„°ì˜ ì˜ˆì¹˜ê¸ˆ ë°ì´í„° ì˜ ìŒ“ì˜€ëŠ”ì§€ ê²€ì¦í•´ì¤˜",
            "í¬íŠ¸ì¸ ë°ì´í„° ì›”ë³„ ì¶”ì´ ë¶„ì„í•´ì¤˜",
            "í¬íŠ¸ì•„ì›ƒ í…Œì´ë¸”ì—ì„œ ìµœê·¼ 1ê°œì›” ë°œìƒí•œ ë°ì´í„° ìš”ì•½í•´ì¤˜",
            "í¬íŠ¸ì•„ì›ƒ ë°ì´í„° ìƒ˜í”Œ í•˜ë‚˜ ë½‘ì•„ì„œ ì˜ˆì¹˜ê¸ˆ ë°ì´í„° ì¡°íšŒí•´ì¤˜",
        ]
        for i, example in enumerate(examples):
            if st.button(f"ğŸ’¬ {example}", key=f"example_{i}"):
                st.session_state.current_input = example

    # ì§ˆë¬¸ ì…ë ¥ ë¶€ë¶„
    st.subheader("âœ¨ ìƒˆë¡œìš´ ì§ˆë¬¸í•˜ê¸°")

    user_input = st.text_input(
        "ğŸ’¬ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:",
        key="user_input",
        value=st.session_state.current_input,
        placeholder="ì˜ˆ: 'ìµœê·¼ 3ê°œì›” ì‚¬ì—…ìë³„ SETL_AMT í•©ê³„ ì•Œë ¤ì¤˜'",
    )

    # ë²„íŠ¼ë“¤ ì™¼ìª½ ë°°ì¹˜
    col_btn, col_empty = st.columns([2, 6])
    with col_btn:
        submit_button = st.button(
            "ğŸš€ ì¿¼ë¦¬ ìƒì„± ë° ì‹¤í–‰", key="submit_query", type="primary"
        )
        clear_button = st.button("ğŸ—‘ï¸ ëŒ€í™” ì´ˆê¸°í™”", key="clear_chat")

    # ëŒ€í™” ì´ˆê¸°í™” ì²˜ë¦¬
    if clear_button:
        st.session_state.conversation_history = []
        st.session_state.current_input = ""
        st.success("âœ… ëŒ€í™” íˆìŠ¤í† ë¦¬ê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
        st.rerun()

    # ğŸ”¥ ìˆ˜ì •: ì¿¼ë¦¬ ì‹¤í–‰ ì²˜ë¦¬ - ì•ˆì „í•œ SQL ìƒì„± ë° ì–¸íŒ¨í‚¹ ì˜¤ë¥˜ í•´ê²°
    if submit_button and user_input.strip():
        with st.spinner("ğŸ¤– AIê°€ SQL ì¿¼ë¦¬ë¥¼ ìƒì„±í•˜ê³  ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤..."):
            time.sleep(1)
            try:
                # ğŸ”¥ ìˆ˜ì •: SQL ìƒì„± ë°©ì‹ ê°œì„  - ì•ˆì „í•œ ì–¸íŒ¨í‚¹
                sql_query = None
                is_ai_generated = False
                
                # 1. AI ìƒì„±ê¸°ê°€ ìˆìœ¼ë©´ AIë¡œ ì‹œë„
                if st.session_state.sql_generator is not None:
                    try:
                        # ğŸ”¥ ìˆ˜ì •: ì•ˆì „í•œ ì–¸íŒ¨í‚¹ ì²˜ë¦¬
                        ai_result = st.session_state.sql_generator.generate_sql(user_input)
                        
                        if ai_result is not None:
                            is_ai_generated = True
                            # íŠœí”Œì¸ì§€ í™•ì¸
                            if isinstance(ai_result, tuple) and len(ai_result) == 2:
                                sql_query, is_ai_generated = ai_result
                                st.info("ğŸ¤– Azure OpenAIë¡œ ì¿¼ë¦¬ë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤.")
                            else:
                                # ë¬¸ìì—´ë§Œ ë°˜í™˜ëœ ê²½ìš°
                                if isinstance(ai_result, str):
                                    sql_query = ai_result
                                    st.info("ğŸ¤– Azure OpenAIë¡œ ì¿¼ë¦¬ë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤.")
                                else:
                                    raise ValueError(f"ì˜ˆìƒì¹˜ ëª»í•œ ë°˜í™˜ íƒ€ì…: {type(ai_result)}")
                        else:
                            raise ValueError("AI ìƒì„±ê¸°ê°€ Noneì„ ë°˜í™˜í–ˆìŠµë‹ˆë‹¤.")
                            
                    except Exception as ai_error:
                        st.warning(f"âš ï¸ AI ì¿¼ë¦¬ ìƒì„± ì‹¤íŒ¨: {ai_error}")
                        sql_query = None
                
                # 2. AI ì‹¤íŒ¨ ì‹œ ë˜ëŠ” AIê°€ ì—†ìœ¼ë©´ ê·œì¹™ ê¸°ë°˜ìœ¼ë¡œ í´ë°±
                if sql_query is None:
                    st.info("ğŸ”§ ê·œì¹™ ê¸°ë°˜ ì¿¼ë¦¬ ìƒì„±ê¸°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                    sql_query = generate_rule_based_sql_query(
                        user_input, 
                        is_azure=(not db_manager.use_sample_data if db_manager else True)
                    )
                    is_ai_generated = False

                # 3. ì¿¼ë¦¬ ì‹¤í–‰
                if sql_query and sql_query.strip():
                    result_df, metadata = db_manager.execute_query(sql_query)

                    # ì„¤ëª… ìƒì„± (AI ìƒì„±ê¸°ê°€ ìˆì„ ë•Œë§Œ)
                    explanation = ""
                    if st.session_state.sql_generator and hasattr(st.session_state.sql_generator, "get_query_explanation"):
                        try:
                            explanation = st.session_state.sql_generator.get_query_explanation(sql_query)
                        except Exception as exp_error:
                            explanation = f"ì¿¼ë¦¬ ì„¤ëª… ìƒì„± ì‹¤íŒ¨: {exp_error}"

                    # ëŒ€í™” íˆìŠ¤í† ë¦¬ì— ì €ì¥
                    conversation_item = {
                        "user_input": user_input,
                        "sql_query": sql_query,
                        "result_df": (
                            result_df.copy() if not result_df.empty else pd.DataFrame()
                        ),
                        "result_count": len(result_df) if not result_df.empty else 0,
                        "execution_time": metadata["execution_time"],
                        "is_ai_generated": is_ai_generated,
                        "explanation": explanation,
                        "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                        "success": metadata["success"],
                    }

                    st.session_state.conversation_history.append(conversation_item)

                    # ê²°ê³¼ í‘œì‹œ
                    st.markdown("---")
                    st.markdown("### ğŸ¯ ì‹¤í–‰ ê²°ê³¼")

                    if metadata["success"]:
                        if is_ai_generated:
                            st.success("âœ… Azure OpenAI GPT-4ê°€ ì¿¼ë¦¬ë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤!")
                        else:
                            st.info("â„¹ï¸ ê·œì¹™ ê¸°ë°˜ìœ¼ë¡œ ì¿¼ë¦¬ë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤.")

                        st.subheader("ğŸ” ìƒì„±ëœ SQL ì¿¼ë¦¬")
                        st.code(sql_query, language="sql")

                        if explanation:
                            st.info(f"ğŸ“ ì¿¼ë¦¬ ì„¤ëª…: {explanation}")

                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.metric("ì‹¤í–‰ ì‹œê°„", f"{metadata['execution_time']:.3f}ì´ˆ")
                        with col2:
                            st.metric("ê²°ê³¼ í–‰ìˆ˜", f"{metadata['row_count']:,}í–‰")
                        with col3:
                            st.metric("AI ìƒì„±", "âœ…" if is_ai_generated else "âŒ")

                        if not result_df.empty:
                            st.subheader("ğŸ“‹ ì¿¼ë¦¬ ì‹¤í–‰ ê²°ê³¼")
                            st.dataframe(result_df, use_container_width=True)

                            try:
                                create_result_visualization(result_df)
                            except Exception as viz_error:
                                st.warning(f"ì‹œê°í™” ìƒì„± ì¤‘ ì˜¤ë¥˜: {viz_error}")

                            csv = result_df.to_csv(index=False, encoding="utf-8-sig")
                            st.download_button(
                                label="ğŸ“¥ ê²°ê³¼ ë°ì´í„° ë‹¤ìš´ë¡œë“œ (CSV)",
                                data=csv,
                                file_name=f"query_result_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                                mime="text/csv",
                                key=f"download_{len(st.session_state.conversation_history)}",
                            )
                        else:
                            st.warning("âš ï¸ ì¿¼ë¦¬ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")

                    else:
                        st.error(
                            f"âŒ ì¿¼ë¦¬ ì‹¤í–‰ ì‹¤íŒ¨: {metadata.get('error_message', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}"
                        )

                    st.success(
                        f"âœ… ì§ˆë¬¸ì´ ëŒ€í™” íˆìŠ¤í† ë¦¬ì— ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤! (ì´ {len(st.session_state.conversation_history)}ê°œ)"
                    )

                    st.session_state.current_input = ""
                else:
                    st.error("âŒ SQL ì¿¼ë¦¬ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

            except Exception as e:
                st.error(f"âŒ ì¿¼ë¦¬ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
                st.info("ğŸ’¡ ë‹¤ë¥¸ ë°©ì‹ìœ¼ë¡œ ì§ˆë¬¸í•´ë³´ì‹œê±°ë‚˜ ì˜ˆì‹œ ì¿¼ë¦¬ë¥¼ ì‚¬ìš©í•´ë³´ì„¸ìš”.")
                
                # ğŸ”¥ ì¶”ê°€: ë””ë²„ê¹… ì •ë³´
                with st.expander("ğŸ› ë””ë²„ê¹… ì •ë³´"):
                    st.code(f"ì˜¤ë¥˜ íƒ€ì…: {type(e).__name__}")
                    st.code(f"ì˜¤ë¥˜ ë©”ì‹œì§€: {str(e)}")
                    st.code(f"SQL ìƒì„±ê¸° ìƒíƒœ: {st.session_state.sql_generator is not None}")
                    if st.session_state.sql_generator:
                        st.code(f"SQL ìƒì„±ê¸° íƒ€ì…: {type(st.session_state.sql_generator)}")

    # ëŒ€í™” íˆìŠ¤í† ë¦¬ í‘œì‹œ (ê¸°ì¡´ ì½”ë“œ ê·¸ëŒ€ë¡œ ìœ ì§€)
    if st.session_state.conversation_history:
        st.markdown("---")
        st.subheader("ğŸ’¬ ëŒ€í™” íˆìŠ¤í† ë¦¬")

        recent_conversations = st.session_state.conversation_history[-5:]

        for i, conversation in enumerate(reversed(recent_conversations)):
            actual_index = len(st.session_state.conversation_history) - i

            with st.chat_message("user"):
                st.write(f"**ì§ˆë¬¸ {actual_index}:** {conversation['user_input']}")

            with st.chat_message("assistant"):
                col1, col2, col3 = st.columns([2, 1, 1])

                with col1:
                    st.write(f"**ì‹¤í–‰ ê²°ê³¼:** {conversation['result_count']}ê±´")
                with col2:
                    st.write(f"**ì‹¤í–‰ì‹œê°„:** {conversation['execution_time']:.3f}ì´ˆ")
                with col3:
                    ai_badge = (
                        "ğŸ¤– AI"
                        if conversation.get("is_ai_generated", False)
                        else "ğŸ“ ê·œì¹™"
                    )
                    st.write(f"**ìƒì„±:** {ai_badge}")

                with st.expander(f"ğŸ” ìƒì„±ëœ SQL ì¿¼ë¦¬ (ì§ˆë¬¸ {actual_index})"):
                    st.code(conversation["sql_query"], language="sql")

                    if conversation.get("explanation"):
                        st.info(f"ğŸ“ ì¿¼ë¦¬ ì„¤ëª…: {conversation['explanation']}")

                if not conversation["result_df"].empty:
                    with st.expander(f"ğŸ“‹ ì‹¤í–‰ ê²°ê³¼ ë°ì´í„° (ì§ˆë¬¸ {actual_index})"):
                        st.dataframe(
                            conversation["result_df"], use_container_width=True
                        )

                        csv = conversation["result_df"].to_csv(
                            index=False, encoding="utf-8-sig"
                        )
                        st.download_button(
                            label=f"ğŸ“¥ ì§ˆë¬¸ {actual_index} ê²°ê³¼ ë‹¤ìš´ë¡œë“œ",
                            data=csv,
                            file_name=f"history_result_{actual_index}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                            mime="text/csv",
                            key=f"download_history_{actual_index}",
                        )

        if len(st.session_state.conversation_history) > 5:
            st.info(
                f"ìµœê·¼ 5ê°œ ëŒ€í™”ë§Œ í‘œì‹œë©ë‹ˆë‹¤. ì „ì²´ {len(st.session_state.conversation_history)}ê°œ ëŒ€í™”ê°€ ìˆìŠµë‹ˆë‹¤."
            )

        st.markdown("---")
        st.subheader("ğŸ“Š ëŒ€í™” ì„¸ì…˜ í†µê³„")

        total_questions = len(st.session_state.conversation_history)
        successful_queries = sum(
            1 for conv in st.session_state.conversation_history if conv["success"]
        )
        ai_generated = sum(
            1
            for conv in st.session_state.conversation_history
            if conv["is_ai_generated"]
        )
        total_results = sum(
            conv["result_count"] for conv in st.session_state.conversation_history
        )

        col1, col2, col3, col4 = st.columns(4)

        with col1:
            st.metric("ì´ ì§ˆë¬¸ ìˆ˜", f"{total_questions}ê°œ")
        with col2:
            st.metric("ì„±ê³µë¥ ", f"{(successful_queries/total_questions*100):.1f}%")
        with col3:
            st.metric("AI ìƒì„±ë¥ ", f"{(ai_generated/total_questions*100):.1f}%")
        with col4:
            st.metric("ì´ ê²°ê³¼ í–‰ìˆ˜", f"{total_results:,}í–‰")


def create_result_visualization(df):
    """ê²°ê³¼ ë°ì´í„° ì‹œê°í™”"""

    if len(df.columns) < 2:
        return

    # ì»¬ëŸ¼ëª…ì„ ê¸°ë°˜ìœ¼ë¡œ ì ì ˆí•œ ì°¨íŠ¸ ìƒì„±
    columns = df.columns.tolist()

    # ì´ê¸ˆì•¡ê³¼ ì‚¬ì—…ìê°€ ìˆëŠ” ê²½ìš°
    if "ì´ê¸ˆì•¡" in columns and (
        "ì‚¬ì—…ì" in columns or "ì „ì‚¬ì—…ì" in columns or "í›„ì‚¬ì—…ì" in columns
    ):
        operator_col = next(
            (col for col in ["ì‚¬ì—…ì", "ì „ì‚¬ì—…ì", "í›„ì‚¬ì—…ì"] if col in columns), None
        )
        if operator_col:
            fig = px.bar(
                df,
                x=operator_col,
                y="ì´ê¸ˆì•¡",
                color="ë²ˆí˜¸ì´ë™íƒ€ì…" if "ë²ˆí˜¸ì´ë™íƒ€ì…" in columns else None,
                title="ğŸ’° ì‚¬ì—…ìë³„ ì •ì‚° ê¸ˆì•¡ ë¹„êµ",
            )
            st.plotly_chart(fig, use_container_width=True)

    # ì›”ë³„ ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš°
    elif "ë²ˆí˜¸ì´ë™ì›”" in columns and "ì´ê¸ˆì•¡" in columns:
        operator_col = next(
            (col for col in ["ì „ì‚¬ì—…ì", "í›„ì‚¬ì—…ì"] if col in columns), None
        )
        fig = px.line(
            df,
            x="ë²ˆí˜¸ì´ë™ì›”",
            y="ì´ê¸ˆì•¡",
            color=operator_col if operator_col else None,
            title="ğŸ“ˆ ì›”ë³„ ì •ì‚° ê¸ˆì•¡ ì¶”ì´",
        )
        st.plotly_chart(fig, use_container_width=True)

    # ë²ˆí˜¸ì´ë™íƒ€ì…ë³„ ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš°
    elif "ë²ˆí˜¸ì´ë™íƒ€ì…" in columns and "ë²ˆí˜¸ì´ë™ê±´ìˆ˜" in columns:
        fig = px.pie(
            df,
            values="ë²ˆí˜¸ì´ë™ê±´ìˆ˜",
            names="ë²ˆí˜¸ì´ë™íƒ€ì…",
            title="ğŸ“Š í¬íŠ¸ì¸/í¬íŠ¸ì•„ì›ƒ ë¹„ìœ¨",
        )
        st.plotly_chart(fig, use_container_width=True)


def display_sidebar(db_manager):
    """ì‚¬ì´ë“œë°” í‘œì‹œ - DatabaseManager ì‚¬ìš©"""

    with st.sidebar:
        st.header("ğŸ”§ Azure í´ë¼ìš°ë“œ ì‹œìŠ¤í…œ ì •ë³´")

        # Azure ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
        from azure_config import get_azure_config

        azure_config = get_azure_config()
        connection_status = azure_config.test_connection()

        # Azure ì„œë¹„ìŠ¤ ìƒíƒœ í‘œì‹œ
        st.subheader("â˜ï¸ Azure ì„œë¹„ìŠ¤ ìƒíƒœ")
        st.metric(
            "ğŸ¤– OpenAI", "âœ… ì—°ê²°ë¨" if connection_status["openai"] else "âŒ ì—°ê²° ì‹¤íŒ¨"
        )
        st.metric(
            "ğŸ—„ï¸ SQL Database",
            "âœ… ì—°ê²°ë¨" if connection_status["database"] else "âŒ ì—°ê²° ì‹¤íŒ¨",
        )

        # ë°ì´í„°ë² ì´ìŠ¤ í˜„í™©
        if db_manager:
            st.subheader("ğŸ“Š ë°ì´í„°ë² ì´ìŠ¤ í˜„í™©")

            try:
                # ì„±ëŠ¥ í†µê³„ ê°€ì ¸ì˜¤ê¸°
                perf_stats = db_manager.get_performance_stats()

                st.info(f"ğŸ”— ì—°ê²° íƒ€ì…: {perf_stats['connection_type']}")
                st.success(perf_stats["connection_status"])

                # í…Œì´ë¸” ì •ë³´ í‘œì‹œ
                if "tables" in perf_stats:
                    st.subheader("ğŸ“‹ í…Œì´ë¸” í˜„í™©")
                    for table_name, table_info in perf_stats["tables"].items():
                        with st.expander(f"ğŸ“Š {table_name}"):
                            st.metric(
                                "ì´ í–‰ ìˆ˜", f"{table_info.get('row_count', 0):,}ê±´"
                            )

                            # ğŸ”¥ ìˆ˜ì •: latest_dateë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
                            latest_date = table_info.get("latest_date")
                            if latest_date is not None:
                                # datetime.date ê°ì²´ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
                                if hasattr(latest_date, "strftime"):
                                    latest_date_str = latest_date.strftime("%Y-%m-%d")
                                else:
                                    latest_date_str = str(latest_date)
                            else:
                                latest_date_str = "N/A"

                            st.metric("ìµœì‹  ë°ì´í„°", latest_date_str)
                            st.write(f"ìƒíƒœ: {table_info.get('status', 'N/A')}")

            except Exception as e:
                st.error(f"ë°ì´í„°ë² ì´ìŠ¤ ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {e}")

        st.markdown("---")

        # ì‹œìŠ¤í…œ ìƒíƒœ
        st.subheader("âš™ï¸ ì‹œìŠ¤í…œ ìƒíƒœ")

        # ìš´ì˜ í™˜ê²½ ì¤€ë¹„ ìƒíƒœ
        production_ready = azure_config.is_production_ready()
        if production_ready:
            st.success("ğŸŸ¢ Azure í´ë¼ìš°ë“œ ì—°ê²°ë¨")
            st.success("ğŸŸ¢ ìš´ì˜ ëª¨ë“œ í™œì„±í™”")
        else:
            st.warning("ğŸŸ¡ ì¼ë¶€ Azure ì„œë¹„ìŠ¤ ì—°ê²° ì‹¤íŒ¨")
            st.info("ğŸ”µ ê°œë°œ ëª¨ë“œë¡œ ì‹¤í–‰")

        st.success("ğŸŸ¢ Streamlit ì„œë²„ ì‹¤í–‰ì¤‘")

        # ì—ëŸ¬ ì •ë³´ í‘œì‹œ
        if connection_status.get("errors"):
            st.subheader("âš ï¸ ì—°ê²° ì˜¤ë¥˜")
            for error in connection_status["errors"][:3]:  # ìµœëŒ€ 3ê°œë§Œ í‘œì‹œ
                st.error(f"â€¢ {error}")

        # ì‚¬ìš©ë²• ì•ˆë‚´
        st.markdown("---")
        st.subheader("ğŸ’¡ Azure AI ì‚¬ìš©ë²•")
        st.markdown(
            """
        **ìì—°ì–´ ì¿¼ë¦¬ ì˜ˆì‹œ:**
        - "ìµœê·¼ 3ê°œì›” í¬íŠ¸ì¸ í˜„í™©"
        - "ì‚¬ì—…ìë³„ ì •ì‚° ë‚´ì—­"
        - "TEL_NO ì¡°íšŒ"
        - "ì›”ë³„ ì •ìƒê¸ˆì•¡ ì¶”ì´"
        - "ì˜ˆì¹˜ê¸ˆ í•©ê³„ í˜„í™©"
        
        **ğŸ’¡ íŒ:**
        - ì‹¤ì œ ì»¬ëŸ¼ëª…ì„ ì‚¬ìš©í•˜ë©´ ë” ì •í™•í•©ë‹ˆë‹¤
        - ë‚ ì§œ ë²”ìœ„ë¥¼ ëª…ì‹œí•˜ë©´ ì„±ëŠ¥ì´ í–¥ìƒë©ë‹ˆë‹¤
        - Azure OpenAIê°€ ìë™ìœ¼ë¡œ ìµœì í™”ëœ ì¿¼ë¦¬ë¥¼ ìƒì„±í•©ë‹ˆë‹¤
        """
        )

        # ìƒˆë¡œê³ ì¹¨ ë° ìºì‹œ ê´€ë¦¬
        st.markdown("---")
        st.subheader("ğŸ”„ ì‹œìŠ¤í…œ ê´€ë¦¬")

        col1, col2 = st.columns(2)

        with col1:
            if st.button("ğŸ”„ ë°ì´í„° ìƒˆë¡œê³ ì¹¨"):
                st.cache_data.clear()
                st.rerun()

        with col2:
            if st.button("ğŸ—„ï¸ ì—°ê²° í…ŒìŠ¤íŠ¸"):
                with st.spinner("ì—°ê²° í…ŒìŠ¤íŠ¸ ì¤‘..."):
                    if db_manager and db_manager.test_connection():
                        st.success("âœ… ì—°ê²° ì„±ê³µ!")
                    else:
                        st.error("âŒ ì—°ê²° ì‹¤íŒ¨!")

        # ì‹œìŠ¤í…œ ë²„ì „ ì •ë³´
        st.markdown("---")
        st.caption("ğŸ“± Version 2.0 - Azure Cloud Edition")
        st.caption("ğŸ¢ Enterprise Grade Security")
        st.caption("âš¡ Powered by GPT-4")


# ë©”ì¸ ì‹¤í–‰
if __name__ == "__main__":
    try:
        # debug_environment()
        main()
    except Exception as e:
        st.error(f"ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘ ì‹¤íŒ¨: {e}")
        st.info("ë¡œì»¬ ëª¨ë“œë¡œ ì „í™˜í•˜ì—¬ ë‹¤ì‹œ ì‹œë„í•´ë³´ì„¸ìš”.")

        # ê¸´ê¸‰ í´ë°± - ê¸°ë³¸ ë¡œì»¬ ëª¨ë“œ
        try:
            st.header("ğŸ”§ ë¡œì»¬ ëª¨ë“œ")
            st.warning("ì‹œìŠ¤í…œ ì˜¤ë¥˜ë¡œ ì¸í•´ ê¸°ë³¸ ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.")

            # ê¸°ë³¸ ìƒ˜í”Œ ë°ì´í„°ë² ì´ìŠ¤ ìƒì„±
            conn = create_sample_database()

            st.success("âœ… ê¸°ë³¸ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì„±ê³µ")

            # ê¸°ë³¸ í˜„í™© í‘œì‹œ
            try:
                basic_query = """
                SELECT 
                    'PORT_IN' as type,
                    COUNT(*) as count,
                    SUM(SETL_AMT) as amount
                FROM PY_NP_SBSC_RMNY_TXN
                UNION ALL
                SELECT 
                    'PORT_OUT' as type,
                    COUNT(*) as count,
                    SUM(PAY_AMT) as amount
                FROM PY_NP_TRMN_RMNY_TXN
                """

                basic_df = pd.read_sql_query(basic_query, conn)
                st.dataframe(basic_df)

            except Exception as basic_error:
                st.error(f"ê¸°ë³¸ ì¿¼ë¦¬ ì‹¤í–‰ ì‹¤íŒ¨: {basic_error}")

        except Exception as fallback_error:
            st.error(f"ê¸´ê¸‰ ë³µêµ¬ ëª¨ë“œ ì‹¤íŒ¨: {fallback_error}")
            st.info("ì‹œìŠ¤í…œ ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”.")
