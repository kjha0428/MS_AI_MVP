# main.py - ë²ˆí˜¸ì´ë™ì •ì‚° AI ë¶„ì„ ì‹œìŠ¤í…œ ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜ (Azure SQL Database ì—°ë™)
import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import re
from datetime import datetime, timedelta
import logging

from azure_config import get_azure_config
from sample_data import SampleDataManager
from database_manager import DatabaseManagerFactory
import openai
from openai import AzureOpenAI
import json

# ìƒ˜í”Œ ë°ì´í„° ì„í¬íŠ¸
from sample_data import create_sample_database

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
try:
    from dotenv import load_dotenv

    load_dotenv()
except ImportError:
    pass  # python-dotenvê°€ ì—†ì–´ë„ ë™ì‘

OPENAI_AVAILABLE = True

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ë²ˆí˜¸ì´ë™ì •ì‚° AI ë¶„ì„ ì‹œìŠ¤í…œ",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded",
)

# CSS ìŠ¤íƒ€ì¼
st.markdown(
    """
<style>
    .main-header {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 2rem;
        border-radius: 15px;
        color: white;
        text-align: center;
        margin-bottom: 2rem;
        box-shadow: 0 8px 32px rgba(31, 38, 135, 0.37);
    }
    
    .metric-card {
        background: rgba(255, 255, 255, 0.95);
        padding: 1.5rem;
        border-radius: 12px;
        box-shadow: 0 4px 20px rgba(0,0,0,0.1);
        border-left: 5px solid #667eea;
        transition: transform 0.2s ease;
    }
    
    .chat-container {
        background: linear-gradient(145deg, #f8f9fa, #e9ecef);
        border-radius: 15px;
        padding: 1.5rem;
        margin: 1rem 0;
        border: 1px solid #dee2e6;
    }
    
    .query-example {
        background: rgba(102, 126, 234, 0.1);
        border-left: 4px solid #667eea;
        padding: 1rem;
        margin: 0.5rem 0;
        border-radius: 0 8px 8px 0;
        cursor: pointer;
    }
    
    .stButton > button {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        border: none;
        border-radius: 8px;
        padding: 0.6rem 1.2rem;
        font-weight: 500;
        transition: all 0.3s ease;
    }
    
    .success-alert {
        background: linear-gradient(135deg, #4facfe 0%, #00f2fe 100%);
        color: white;
        padding: 1rem;
        border-radius: 8px;
        margin: 1rem 0;
    }
    
    .error-alert {
        background: linear-gradient(135deg, #ff6b6b 0%, #ee5a52 100%);
        color: white;
        padding: 1rem;
        border-radius: 8px;
        margin: 1rem 0;
    }

    .azure-status {
        background: linear-gradient(135deg, #0078d4 0%, #106ebe 100%);
        color: white;
        padding: 0.8rem;
        border-radius: 8px;
        margin: 0.5rem 0;
        text-align: center;
        font-weight: 500;
    }
    
    .local-status {
        background: linear-gradient(135deg, #ffa500 0%, #ff8c00 100%);
        color: white;
        padding: 0.8rem;
        border-radius: 8px;
        margin: 0.5rem 0;
        text-align: center;
        font-weight: 500;
</style>
""",
    unsafe_allow_html=True,
)

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


# ì‹œìŠ¤í…œ ì´ˆê¸°í™”
@st.cache_resource
def init_system():
    """ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
    try:
        # Azure ì„¤ì • ë¡œë“œ
        azure_config = get_azure_config()

        # ë°ì´í„°ë² ì´ìŠ¤ ë§¤ë‹ˆì € ìƒì„±
        db_manager = DatabaseManagerFactory.create_manager(azure_config)

        # ìƒ˜í”Œ ë°ì´í„° ë§¤ë‹ˆì € ìƒì„±
        sample_manager = SampleDataManager(azure_config)

        # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ìƒì„±
        conn = sample_manager.create_sample_database()

        return {
            "azure_config": azure_config,
            "db_manager": db_manager,
            "sample_manager": sample_manager,
            "connection": conn,
            "is_azure": sample_manager.is_using_azure(),
            "connection_info": sample_manager.get_connection_info(),
            "success": True,
        }

    except Exception as e:
        # í´ë°±: ê¸°ë³¸ ë¡œì»¬ ëª¨ë“œ
        conn = create_sample_database(force_local=True)


# ëŒ€ì‹œë³´ë“œ ë°ì´í„° ì¡°íšŒ (ìˆ˜ì •ëœ ë²„ì „)
@st.cache_data(ttl=300)
def get_dashboard_data(_conn, is_azure=False):
    """ëŒ€ì‹œë³´ë“œìš© ë°ì´í„° ì¡°íšŒ"""

    # í¬íŠ¸ì¸ ì›”ë³„ ì§‘ê³„ - ì˜¬ë°”ë¥¸ ì»¬ëŸ¼ëª… ì‚¬ìš©
    port_in_query = """
    SELECT 
        {} as month,
        COUNT(*) as count,
        SUM(SETL_AMT) as amount,
        BCHNG_COMM_CMPN_ID as operator
    FROM PY_NP_SBSC_RMNY_TXN 
    WHERE TRT_DATE >= {} 
        AND NP_STTUS_CD IN ('OK', 'WD')
    GROUP BY {}, BCHNG_COMM_CMPN_ID
    ORDER BY month
    """.format(
        "FORMAT(TRT_DATE, 'yyyy-MM')" if is_azure else "strftime('%Y-%m', TRT_DATE)",
        "DATEADD(month, -4, GETDATE())" if is_azure else "date('now', '-4 months')",
        "FORMAT(TRT_DATE, 'yyyy-MM')" if is_azure else "strftime('%Y-%m', TRT_DATE)",
    )

    # í¬íŠ¸ì•„ì›ƒ ì›”ë³„ ì§‘ê³„ - ì˜¬ë°”ë¥¸ ì»¬ëŸ¼ëª… ì‚¬ìš©
    port_out_query = """
    SELECT 
        {} as month,
        COUNT(*) as count,
        SUM(PAY_AMT) as amount,
        BCHNG_COMM_CMPN_ID as operator
    FROM PY_NP_TRMN_RMNY_TXN 
    WHERE NP_TRMN_DATE IS NOT NULL 
        AND NP_TRMN_DATE >= {}
        AND NP_TRMN_DTL_STTUS_VAL IN ('1', '3')
    GROUP BY {}, BCHNG_COMM_CMPN_ID
    ORDER BY month
    """.format(
        (
            "FORMAT(NP_TRMN_DATE, 'yyyy-MM')"
            if is_azure
            else "strftime('%Y-%m', NP_TRMN_DATE)"
        ),
        "DATEADD(month, -4, GETDATE())" if is_azure else "date('now', '-4 months')",
        (
            "FORMAT(NP_TRMN_DATE, 'yyyy-MM')"
            if is_azure
            else "strftime('%Y-%m', NP_TRMN_DATE)"
        ),
    )

    try:
        port_in_df = pd.read_sql_query(port_in_query, _conn)
        port_out_df = pd.read_sql_query(port_out_query, _conn)
    except Exception as e:
        st.error(f"ë°ì´í„° ì¡°íšŒ ì˜¤ë¥˜: {e}")
        port_in_df = pd.DataFrame()
        port_out_df = pd.DataFrame()

    return port_in_df, port_out_df


def generate_sql_with_openai(user_input, azure_config, is_azure=False):
    """OpenAIë¥¼ ì‚¬ìš©í•˜ì—¬ SQL ì¿¼ë¦¬ ìƒì„±"""

    try:
        # Azure OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        client = AzureOpenAI(
            api_key=azure_config.openai_api_key,
            api_version=azure_config.openai_api_version,
            azure_endpoint=azure_config.openai_endpoint,
        )

        # ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ì •ë³´
        schema_info = get_database_schema_info(is_azure)

        # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        system_prompt = f"""
        ë‹¹ì‹ ì€ ë²ˆí˜¸ì´ë™ì •ì‚° ì‹œìŠ¤í…œì˜ SQL ì¿¼ë¦¬ ìƒì„± ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
        ì‚¬ìš©ìì˜ ìì—°ì–´ ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ì ì ˆí•œ SQL ì¿¼ë¦¬ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.

        ë°ì´í„°ë² ì´ìŠ¤ ì •ë³´:
        - íƒ€ì…: {'Azure SQL Database' if is_azure else 'SQLite'}
        - ìŠ¤í‚¤ë§ˆ: {schema_info}

        ê·œì¹™:
        1. ì „í™”ë²ˆí˜¸ëŠ” í•­ìƒ ë§ˆìŠ¤í‚¹ ì²˜ë¦¬ (ì• 3ìë¦¬ + **** + ë’¤ 4ìë¦¬)
        2. ë‚ ì§œ í•¨ìˆ˜ëŠ” ë°ì´í„°ë² ì´ìŠ¤ íƒ€ì…ì— ë§ê²Œ ì‚¬ìš©
        3. ê°œì¸ì •ë³´ ë³´í˜¸ë¥¼ ìœ„í•´ ë¯¼ê°í•œ ì •ë³´ëŠ” ì œí•œì ìœ¼ë¡œ ë…¸ì¶œ
        4. ê²°ê³¼ëŠ” ê°€ë…ì„± ìˆê²Œ í•œê¸€ ì»¬ëŸ¼ëª… ì‚¬ìš©
        5. ì„±ëŠ¥ì„ ìœ„í•´ ì ì ˆí•œ WHERE ì¡°ê±´ ì¶”ê°€

        ì‘ë‹µ í˜•ì‹: JSON
        {{
            "sql_query": "ìƒì„±ëœ SQL ì¿¼ë¦¬",
            "explanation": "ì¿¼ë¦¬ ì„¤ëª…",
            "confidence": 0.9 (0-1 ì‚¬ì´ì˜ ì‹ ë¢°ë„)
        }}
        """

        user_prompt = f"ë‹¤ìŒ ì§ˆë¬¸ì— ëŒ€í•œ SQL ì¿¼ë¦¬ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”: {user_input}"

        # OpenAI API í˜¸ì¶œ
        response = client.chat.completions.create(
            model=azure_config.openai_model_name,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt},
            ],
            temperature=0.1,
            max_tokens=1000,
        )

        # ì‘ë‹µ íŒŒì‹±
        response_content = response.choices[0].message.content

        try:
            # JSON ì‘ë‹µ íŒŒì‹± ì‹œë„
            result = json.loads(response_content)
            return {
                "sql_query": result.get("sql_query", ""),
                "explanation": result.get("explanation", ""),
                "confidence": result.get("confidence", 0.0),
                "source": "OpenAI",
            }
        except json.JSONDecodeError:
            # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ í…ìŠ¤íŠ¸ì—ì„œ SQL ì¶”ì¶œ ì‹œë„
            sql_match = re.search(r"```sql\n(.*?)\n```", response_content, re.DOTALL)
            if sql_match:
                return {
                    "sql_query": sql_match.group(1).strip(),
                    "explanation": "OpenAIì—ì„œ ìƒì„±ëœ ì¿¼ë¦¬",
                    "confidence": 0.8,
                    "source": "OpenAI",
                }
            else:
                raise Exception("OpenAI ì‘ë‹µì—ì„œ SQLì„ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

    except Exception as e:
        logger.warning(f"OpenAI SQL ìƒì„± ì‹¤íŒ¨: {e}")
        raise e


def get_database_schema_info(is_azure=False):
    """ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ì •ë³´ ë°˜í™˜"""

    schema = {
        "tables": {
            "PY_NP_SBSC_RMNY_TXN": {
                "description": "ë²ˆí˜¸ì´ë™ ê°€ì… ì •ì‚° ê±°ë˜",
                "columns": {
                    "TEL_NO": "ì „í™”ë²ˆí˜¸",
                    "TRT_DATE": "ê±°ë˜ì¼ì",
                    "SETL_AMT": "ì •ì‚°ê¸ˆì•¡",
                    "BCHNG_COMM_CMPN_ID": "ì „ì‚¬ì—…ìID",
                    "ACHNG_COMM_CMPN_ID": "í›„ì‚¬ì—…ìID",
                    "NP_STTUS_CD": "ë²ˆí˜¸ì´ë™ìƒíƒœì½”ë“œ",
                    "SVC_CONT_ID": "ì„œë¹„ìŠ¤ê³„ì•½ID",
                },
            },
            "PY_NP_TRMN_RMNY_TXN": {
                "description": "ë²ˆí˜¸ì´ë™ í•´ì§€ ì •ì‚° ê±°ë˜",
                "columns": {
                    "TEL_NO": "ì „í™”ë²ˆí˜¸",
                    "NP_TRMN_DATE": "ë²ˆí˜¸ì´ë™í•´ì§€ì¼ì",
                    "PAY_AMT": "ì§€ê¸‰ê¸ˆì•¡",
                    "BCHNG_COMM_CMPN_ID": "ì „ì‚¬ì—…ìID",
                    "ACHNG_COMM_CMPN_ID": "í›„ì‚¬ì—…ìID",
                    "NP_TRMN_DTL_STTUS_VAL": "í•´ì§€ìƒì„¸ìƒíƒœê°’",
                    "SVC_CONT_ID": "ì„œë¹„ìŠ¤ê³„ì•½ID",
                },
            },
            "PY_DEPAZ_BAS": {
                "description": "ì˜ˆì¹˜ê¸ˆ ê¸°ë³¸",
                "columns": {
                    "RMNY_DATE": "ìˆ˜ë‚©ì¼ì",
                    "DEPAZ_AMT": "ì˜ˆì¹˜ê¸ˆì•¡",
                    "DEPAZ_DIV_CD": "ì˜ˆì¹˜ê¸ˆêµ¬ë¶„ì½”ë“œ",
                    "RMNY_METH_CD": "ìˆ˜ë‚©ë°©ë²•ì½”ë“œ",
                },
            },
        },
        "common_filters": {
            "port_in_status": "NP_STTUS_CD IN ('OK', 'WD')",
            "port_out_status": "NP_TRMN_DTL_STTUS_VAL IN ('1', '3')",
            "deposit_status": "DEPAZ_DIV_CD = '10' AND RMNY_METH_CD = 'NA'",
        },
    }

    return json.dumps(schema, ensure_ascii=False, indent=2)


def generate_sql_query(user_input, is_azure=False, azure_config=None):
    """ì‚¬ìš©ì ì…ë ¥ì„ SQL ì¿¼ë¦¬ë¡œ ë³€í™˜ (OpenAI ìš°ì„ , ê·œì¹™ ê¸°ë°˜ í´ë°±)"""

    # 1. OpenAI ì‚¬ìš© ì‹œë„ (ìš°ì„ ìˆœìœ„)
    if (
        azure_config
        and hasattr(azure_config, "openai_api_key")
        and azure_config.openai_api_key
    ):
        try:
            logger.info("OpenAIë¥¼ ì‚¬ìš©í•˜ì—¬ SQL ì¿¼ë¦¬ ìƒì„± ì‹œë„")
            openai_result = generate_sql_with_openai(user_input, azure_config, is_azure)

            # ì‹ ë¢°ë„ê°€ ë†’ìœ¼ë©´ OpenAI ê²°ê³¼ ì‚¬ìš©
            if openai_result.get("confidence", 0) > 0.7:
                logger.info(
                    f"OpenAI ì¿¼ë¦¬ ìƒì„± ì„±ê³µ (ì‹ ë¢°ë„: {openai_result.get('confidence')})"
                )
                return openai_result["sql_query"]
            else:
                logger.warning("OpenAI ì‹ ë¢°ë„ê°€ ë‚®ì•„ ê·œì¹™ ê¸°ë°˜ìœ¼ë¡œ í´ë°±")

        except Exception as e:
            logger.warning(f"OpenAI ì¿¼ë¦¬ ìƒì„± ì‹¤íŒ¨, ê·œì¹™ ê¸°ë°˜ìœ¼ë¡œ í´ë°±: {e}")

    # 2. ê·œì¹™ ê¸°ë°˜ ì¿¼ë¦¬ ìƒì„± (í´ë°±)
    logger.info("ê·œì¹™ ê¸°ë°˜ SQL ì¿¼ë¦¬ ìƒì„± ì‚¬ìš©")
    return generate_rule_based_sql_query(user_input, is_azure)


# SQL ì¿¼ë¦¬ ìƒì„± í•¨ìˆ˜ (ìˆ˜ì •ëœ ë²„ì „)
def generate_rule_based_sql_query(user_input, is_azure=False):
    """ì‚¬ìš©ì ì…ë ¥ì„ SQL ì¿¼ë¦¬ë¡œ ë³€í™˜ (Azure SQL/SQLite í˜¸í™˜)"""

    user_input_lower = user_input.lower()

    # ë‚ ì§œ í•¨ìˆ˜ ë§¤í•‘
    date_func = {
        "now_minus_months": lambda months: (
            f"DATEADD(month, -{months}, GETDATE())"
            if is_azure
            else f"date('now', '-{months} months')"
        ),
        "format_month": lambda col: (
            f"FORMAT({col}, 'yyyy-MM')" if is_azure else f"strftime('%Y-%m', {col})"
        ),
        "substr_phone": lambda col: (
            f"LEFT({col}, 3) + '****' + RIGHT({col}, 4)"
            if is_azure
            else f"SUBSTR({col}, 1, 3) || '****' || SUBSTR({col}, -4)"
        ),
    }

    # 1. ì›”ë³„ ì§‘ê³„ ì¿¼ë¦¬
    if "ì›”ë³„" in user_input_lower or "ì¶”ì´" in user_input_lower:
        if "í¬íŠ¸ì¸" in user_input_lower:
            return f"""
            SELECT 
                {date_func['format_month']('TRT_DATE')} as ë²ˆí˜¸ì´ë™ì›”,
                BCHNG_COMM_CMPN_ID as ì „ì‚¬ì—…ì,
                COUNT(*) as ì´ê±´ìˆ˜,
                SUM(SETL_AMT) as ì´ê¸ˆì•¡,
                {'ROUND(AVG(SETL_AMT), 0)' if not is_azure else 'CAST(AVG(SETL_AMT) AS INT)'} as ì •ì‚°ê¸ˆì•¡í‰ê· 
            FROM PY_NP_SBSC_RMNY_TXN 
            WHERE TRT_DATE >= {date_func['now_minus_months'](6)}
                AND NP_STTUS_CD IN ('OK', 'WD')
            GROUP BY {date_func['format_month']('TRT_DATE')}, BCHNG_COMM_CMPN_ID
            ORDER BY ë²ˆí˜¸ì´ë™ì›” DESC, ì´ê¸ˆì•¡ DESC
            """
        elif "í¬íŠ¸ì•„ì›ƒ" in user_input_lower:
            return f"""
            SELECT 
                {date_func['format_month']('NP_TRMN_DATE')} as ë²ˆí˜¸ì´ë™ì›”,
                BCHNG_COMM_CMPN_ID as ì „ì‚¬ì—…ì,
                COUNT(*) as ì´ê±´ìˆ˜,
                SUM(PAY_AMT) as ì´ê¸ˆì•¡,
                {'ROUND(AVG(PAY_AMT), 0)' if not is_azure else 'CAST(AVG(PAY_AMT) AS INT)'} as ì •ì‚°ê¸ˆì•¡í‰ê· 
            FROM PY_NP_TRMN_RMNY_TXN 
            WHERE NP_TRMN_DATE IS NOT NULL 
                AND NP_TRMN_DATE >= {date_func['now_minus_months'](4)}
                AND NP_TRMN_DTL_STTUS_VAL IN ('1', '3')
            GROUP BY {date_func['format_month']('NP_TRMN_DATE')}, BCHNG_COMM_CMPN_ID
            ORDER BY ë²ˆí˜¸ì´ë™ì›” DESC, ì´ê¸ˆì•¡ DESC
            """

    # 2. ì „í™”ë²ˆí˜¸ ê²€ìƒ‰ (ë§ˆìŠ¤í‚¹ ì ìš©)
    phone_match = re.search(r"010[- ]?\d{4}[- ]?\d{4}", user_input)
    if phone_match:
        phone = phone_match.group().replace("-", "").replace(" ", "")
        return f"""
        SELECT 
            'PORT_IN' as ë²ˆí˜¸ì´ë™íƒ€ì…,
            TRT_DATE as ë²ˆí˜¸ì´ë™ì¼,
            {date_func['substr_phone']('TEL_NO')} as ì „í™”ë²ˆí˜¸,
            SVC_CONT_ID,
            SETL_AMT as ì •ì‚°ê¸ˆì•¡,
            BCHNG_COMM_CMPN_ID as ì „ì‚¬ì—…ì,
            ACHNG_COMM_CMPN_ID as í›„ì‚¬ì—…ì,
            NP_STTUS_CD as ìƒíƒœ
        FROM PY_NP_SBSC_RMNY_TXN 
        WHERE TEL_NO = '{phone}' AND NP_STTUS_CD IN ('OK', 'WD')
        UNION ALL
        SELECT 
            'PORT_OUT' as ë²ˆí˜¸ì´ë™íƒ€ì…,
            NP_TRMN_DATE as ë²ˆí˜¸ì´ë™ì¼,
            {date_func['substr_phone']('TEL_NO')} as ì „í™”ë²ˆí˜¸,
            SVC_CONT_ID,
            PAY_AMT as ì •ì‚°ê¸ˆì•¡,
            BCHNG_COMM_CMPN_ID as ì „ì‚¬ì—…ì,
            ACHNG_COMM_CMPN_ID as í›„ì‚¬ì—…ì,
            NP_TRMN_DTL_STTUS_VAL as ìƒíƒœ
        FROM PY_NP_TRMN_RMNY_TXN 
        WHERE TEL_NO = '{phone}' AND NP_TRMN_DTL_STTUS_VAL IN ('1', '3')
        ORDER BY ë²ˆí˜¸ì´ë™ì¼ DESC
        """

    # 3. ì‚¬ì—…ìë³„ í˜„í™©
    if any(
        keyword in user_input_lower
        for keyword in ["ì‚¬ì—…ì", "íšŒì‚¬", "í†µì‹ ì‚¬", "skt", "kt", "lgu+"]
    ):
        operator_filter = ""
        if "skt" in user_input_lower or "sk" in user_input_lower:
            operator_filter = (
                "AND (BCHNG_COMM_CMPN_ID = 'SKT' OR ACHNG_COMM_CMPN_ID = 'SKT')"
            )
        elif "kt" in user_input_lower:
            operator_filter = (
                "AND (BCHNG_COMM_CMPN_ID = 'KT' OR ACHNG_COMM_CMPN_ID = 'KT')"
            )
        elif "lgu" in user_input_lower:
            operator_filter = (
                "AND (BCHNG_COMM_CMPN_ID = 'LGU+' OR ACHNG_COMM_CMPN_ID = 'LGU+')"
            )

        return f"""
        SELECT 
            BCHNG_COMM_CMPN_ID as ì‚¬ì—…ì,
            'PORT_IN' as ë²ˆí˜¸ì´ë™íƒ€ì…,
            COUNT(*) as ë²ˆí˜¸ì´ë™ê±´ìˆ˜,
            SUM(SETL_AMT) as ì´ì •ì‚°ê¸ˆì•¡,
            {'ROUND(AVG(SETL_AMT), 0)' if not is_azure else 'CAST(AVG(SETL_AMT) AS INT)'} as ì •ì‚°ê¸ˆì•¡í‰ê· ,
            {'MIN(TRT_DATE)' if not is_azure else 'MIN(CAST(TRT_DATE AS DATE))'} as ìµœì´ˆì¼ì,
            {'MAX(TRT_DATE)' if not is_azure else 'MAX(CAST(TRT_DATE AS DATE))'} as ìµœì‹ ì¼ì
        FROM PY_NP_SBSC_RMNY_TXN
        WHERE TRT_DATE >= {date_func['now_minus_months'](3)}
            AND NP_STTUS_CD IN ('OK', 'WD')
            {operator_filter}
        GROUP BY BCHNG_COMM_CMPN_ID
        UNION ALL
        SELECT 
            BCHNG_COMM_CMPN_ID as ì‚¬ì—…ì,
            'PORT_OUT' as ë²ˆí˜¸ì´ë™íƒ€ì…,
            COUNT(*) as ë²ˆí˜¸ì´ë™ê±´ìˆ˜,
            SUM(PAY_AMT) as ì´ì •ì‚°ê¸ˆì•¡,
            {'ROUND(AVG(PAY_AMT), 0)' if not is_azure else 'CAST(AVG(PAY_AMT) AS INT)'} as ì •ì‚°ê¸ˆì•¡í‰ê· ,
            {'MIN(NP_TRMN_DATE)' if not is_azure else 'MIN(CAST(NP_TRMN_DATE AS DATE))'} as ìµœì´ˆì¼ì,
            {'MAX(NP_TRMN_DATE)' if not is_azure else 'MAX(CAST(NP_TRMN_DATE AS DATE))'} as ìµœì‹ ì¼ì
        FROM PY_NP_TRMN_RMNY_TXN
        WHERE NP_TRMN_DATE IS NOT NULL 
            AND NP_TRMN_DATE >= {date_func['now_minus_months'](3)}
            AND NP_TRMN_DTL_STTUS_VAL IN ('1', '3')
            {operator_filter}
        GROUP BY BCHNG_COMM_CMPN_ID
        ORDER BY ì‚¬ì—…ì, ë²ˆí˜¸ì´ë™íƒ€ì…
        """

    # 4. ì˜ˆì¹˜ê¸ˆ ì¡°íšŒ
    if "ì˜ˆì¹˜ê¸ˆ" in user_input_lower:
        return f"""
        SELECT 
            {date_func['format_month']('RMNY_DATE')} as ìˆ˜ë‚©ì›”,
            COUNT(*) as ì´ê±´ìˆ˜,
            SUM(DEPAZ_AMT) as ì´ê¸ˆì•¡,
            {'ROUND(AVG(DEPAZ_AMT), 0)' if not is_azure else 'CAST(AVG(DEPAZ_AMT) AS INT)'} as í‰ê· ê¸ˆì•¡,
            MIN(DEPAZ_AMT) as ìµœì†Œê¸ˆì•¡,
            MAX(DEPAZ_AMT) as ìµœëŒ€ê¸ˆì•¡,
            DEPAZ_DIV_CD as ì˜ˆì¹˜ê¸ˆêµ¬ë¶„,
            RMNY_METH_CD as ìˆ˜ë‚©ë°©ë²•
        FROM PY_DEPAZ_BAS
        WHERE RMNY_DATE >= {date_func['now_minus_months'](3)}
            AND DEPAZ_DIV_CD = '10'
            AND RMNY_METH_CD = 'NA'
        GROUP BY {date_func['format_month']('RMNY_DATE')}, DEPAZ_DIV_CD, RMNY_METH_CD
        ORDER BY ìˆ˜ë‚©ì›” DESC
        """

    # ê¸°ë³¸ ì¿¼ë¦¬
    return """
    SELECT 
        'OpenAI ë° ê·œì¹™ ê¸°ë°˜ ì¿¼ë¦¬ ìƒì„±ì„ ì‹œë„í–ˆìœ¼ë‚˜ ì ì ˆí•œ ì¿¼ë¦¬ë¥¼ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤' as ë©”ì‹œì§€,
        'ë” êµ¬ì²´ì ìœ¼ë¡œ ì§ˆë¬¸í•´ì£¼ì‹œê±°ë‚˜ ì˜ˆì‹œ ì¿¼ë¦¬ë¥¼ ì‚¬ìš©í•´ë³´ì„¸ìš”' as ì•ˆë‚´
    """


# ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜
def main():
    # ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    system_info = init_system()

    azure_config = system_info["azure_config"]
    db_manager = system_info["db_manager"]
    sample_manager = system_info["sample_manager"]
    conn = system_info["connection"]
    is_azure = system_info["is_azure"]
    connection_info = system_info["connection_info"]

    # í—¤ë”
    st.markdown(
        """
    <div class="main-header">
        <h1>ğŸ“Š ë²ˆí˜¸ì´ë™ì •ì‚° AI ë¶„ì„ ì‹œìŠ¤í…œ</h1>
        <p>ğŸ¤– Azure OpenAI ê¸°ë°˜ ìì—°ì–´ ì¿¼ë¦¬ ìƒì„± ë° ì‹¤ì‹œê°„ ëŒ€ì‹œë³´ë“œ</p>
        <p><small>âœ¨ ë°ì´í„° ê¸°ë°˜ ì˜ì‚¬ê²°ì •ì„ ìœ„í•œ ìŠ¤ë§ˆíŠ¸ ë¶„ì„ í”Œë«í¼</small></p>
    </div>
    """,
        unsafe_allow_html=True,
    )

    # ì—°ê²° ìƒíƒœ í‘œì‹œ
    display_connection_status(connection_info, system_info.get("fallback", False))

    # ì‹¤ì‹œê°„ ëŒ€ì‹œë³´ë“œ
    st.header("ğŸ“ˆ ë²ˆí˜¸ì´ë™ ì¶”ì´ ë¶„ì„ ëŒ€ì‹œë³´ë“œ")

    with st.spinner("ğŸ“Š ìµœì‹  ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
        port_in_df, port_out_df = get_dashboard_data(conn, is_azure)

    # ë©”íŠ¸ë¦­ ì¹´ë“œ í‘œì‹œ
    display_metrics(port_in_df, port_out_df)

    # ì¶”ì´ ì°¨íŠ¸ í‘œì‹œ
    display_charts(port_in_df, port_out_df)

    # êµ¬ë¶„ì„ 
    st.markdown("---")

    # AI ì±—ë´‡ ì„¹ì…˜
    display_chatbot(conn, is_azure, system_info)

    # ì‚¬ì´ë“œë°”
    display_sidebar(conn, system_info)


def display_connection_status(connection_info, is_fallback=False):
    """ì—°ê²° ìƒíƒœ í‘œì‹œ"""

    if is_fallback:
        st.markdown(
            """
        <div class="error-alert">
            âš ï¸ Azure ì—°ê²° ì‹¤íŒ¨ë¡œ ë¡œì»¬ ëª¨ë“œë¡œ ì „í™˜ë˜ì—ˆìŠµë‹ˆë‹¤
        </div>
        """,
            unsafe_allow_html=True,
        )

    connection_type = connection_info["type"]

    if connection_type == "Azure SQL Database":
        st.markdown(
            """
        <div class="azure-status">
            â˜ï¸ Azure SQL Database ì—°ê²°ë¨ | ì‹¤ì‹œê°„ ë°ì´í„° ì‚¬ìš©
        </div>
        """,
            unsafe_allow_html=True,
        )
    else:
        st.markdown(
            """
        <div class="local-status">
            ğŸ’» ë¡œì»¬ SQLite ëª¨ë“œ | ìƒ˜í”Œ ë°ì´í„° ì‚¬ìš©
        </div>
        """,
            unsafe_allow_html=True,
        )


def display_metrics(port_in_df, port_out_df):
    """ì£¼ìš” ë©”íŠ¸ë¦­ í‘œì‹œ"""

    col1, col2, col3, col4 = st.columns(4)

    # ì´ ê±´ìˆ˜ ë° ê¸ˆì•¡ ê³„ì‚°
    total_port_in = port_in_df["count"].sum() if not port_in_df.empty else 0
    total_port_out = port_out_df["count"].sum() if not port_out_df.empty else 0
    total_in_amount = port_in_df["amount"].sum() if not port_in_df.empty else 0
    total_out_amount = port_out_df["amount"].sum() if not port_out_df.empty else 0

    with col1:
        st.metric(
            label="ğŸ“¥ ì´ í¬íŠ¸ì¸",
            value=f"{total_port_in:,}ê±´",
            delta=(
                f"+{total_port_in - total_port_out}ê±´"
                if total_port_in > total_port_out
                else None
            ),
        )

    with col2:
        st.metric(
            label="ğŸ“¤ ì´ í¬íŠ¸ì•„ì›ƒ",
            value=f"{total_port_out:,}ê±´",
            delta=(
                f"{total_port_out - total_port_in:+,}ê±´"
                if total_port_out != total_port_in
                else None
            ),
        )

    with col3:
        st.metric(
            label="ğŸ’° í¬íŠ¸ì¸ ì •ì‚°ì•¡",
            value=f"{total_in_amount:,.0f}ì›",
            delta=f"í‰ê·  {total_in_amount/max(total_port_in,1):,.0f}ì›/ê±´",
        )

    with col4:
        st.metric(
            label="ğŸ’¸ í¬íŠ¸ì•„ì›ƒ ì •ì‚°ì•¡",
            value=f"{total_out_amount:,.0f}ì›",
            delta=f"í‰ê·  {total_out_amount/max(total_port_out,1):,.0f}ì›/ê±´",
        )


def display_charts(port_in_df, port_out_df):
    """ì¶”ì´ ì°¨íŠ¸ í‘œì‹œ"""

    if not port_in_df.empty or not port_out_df.empty:
        # ì›”ë³„ ì´ ê±´ìˆ˜ ì§‘ê³„
        port_in_monthly = (
            port_in_df.groupby("month")
            .agg({"count": "sum", "amount": "sum"})
            .reset_index()
            if not port_in_df.empty
            else pd.DataFrame()
        )
        port_out_monthly = (
            port_out_df.groupby("month")
            .agg({"count": "sum", "amount": "sum"})
            .reset_index()
            if not port_out_df.empty
            else pd.DataFrame()
        )

        # 2x2 ì„œë¸Œí”Œë¡¯ ìƒì„±
        fig = make_subplots(
            rows=2,
            cols=2,
            subplot_titles=(
                "ğŸ“Š ì›”ë³„ ê±´ìˆ˜ ì¶”ì´",
                "ğŸ’° ì›”ë³„ ì •ì‚°ì•¡ ì¶”ì´",
                "ğŸ¢ ì‚¬ì—…ìë³„ í¬íŠ¸ì¸ í˜„í™©",
                "ğŸ“ˆ ì‚¬ì—…ìë³„ í¬íŠ¸ì•„ì›ƒ í˜„í™©",
            ),
            specs=[
                [{"secondary_y": False}, {"secondary_y": False}],
                [{"secondary_y": False}, {"secondary_y": False}],
            ],
        )

        # 1. ì›”ë³„ ê±´ìˆ˜ ì¶”ì´
        if not port_in_monthly.empty:
            fig.add_trace(
                go.Scatter(
                    x=port_in_monthly["month"],
                    y=port_in_monthly["count"],
                    mode="lines+markers",
                    name="í¬íŠ¸ì¸",
                    line=dict(color="#1f77b4"),
                ),
                row=1,
                col=1,
            )

        if not port_out_monthly.empty:
            fig.add_trace(
                go.Scatter(
                    x=port_out_monthly["month"],
                    y=port_out_monthly["count"],
                    mode="lines+markers",
                    name="í¬íŠ¸ì•„ì›ƒ",
                    line=dict(color="#ff7f0e"),
                ),
                row=1,
                col=1,
            )

        # 2. ì›”ë³„ ì •ì‚°ì•¡ ì¶”ì´
        if not port_in_monthly.empty:
            fig.add_trace(
                go.Scatter(
                    x=port_in_monthly["month"],
                    y=port_in_monthly["amount"],
                    mode="lines+markers",
                    name="í¬íŠ¸ì¸ ê¸ˆì•¡",
                    line=dict(color="#2ca02c"),
                ),
                row=1,
                col=2,
            )

        if not port_out_monthly.empty:
            fig.add_trace(
                go.Scatter(
                    x=port_out_monthly["month"],
                    y=port_out_monthly["amount"],
                    mode="lines+markers",
                    name="í¬íŠ¸ì•„ì›ƒ ê¸ˆì•¡",
                    line=dict(color="#d62728"),
                ),
                row=1,
                col=2,
            )

        # 3. ì‚¬ì—…ìë³„ í¬íŠ¸ì¸ í˜„í™©
        if not port_in_df.empty:
            port_in_by_operator = (
                port_in_df.groupby("operator")["count"].sum().reset_index()
            )
            fig.add_trace(
                go.Bar(
                    x=port_in_by_operator["operator"],
                    y=port_in_by_operator["count"],
                    name="í¬íŠ¸ì¸ ì‚¬ì—…ìë³„",
                    marker_color="#1f77b4",
                ),
                row=2,
                col=1,
            )

        # 4. ì‚¬ì—…ìë³„ í¬íŠ¸ì•„ì›ƒ í˜„í™©
        if not port_out_df.empty:
            port_out_by_operator = (
                port_out_df.groupby("operator")["count"].sum().reset_index()
            )
            fig.add_trace(
                go.Bar(
                    x=port_out_by_operator["operator"],
                    y=port_out_by_operator["count"],
                    name="í¬íŠ¸ì•„ì›ƒ ì‚¬ì—…ìë³„",
                    marker_color="#ff7f0e",
                ),
                row=2,
                col=2,
            )

        fig.update_layout(
            height=800, showlegend=True, title_text="ğŸ“Š ë²ˆí˜¸ì´ë™ ì¢…í•© ë¶„ì„ ëŒ€ì‹œë³´ë“œ"
        )
        st.plotly_chart(fig, use_container_width=True)
    else:
        st.info("ğŸ“Š í‘œì‹œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ìƒ˜í”Œ ë°ì´í„°ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.")


def display_chatbot(_conn, is_azure, system_info):
    """AI ì±—ë´‡ ì¸í„°í˜ì´ìŠ¤ (OpenAI ìš°ì„  ì‚¬ìš©)"""

    # Azure ì„¤ì • ê°€ì ¸ì˜¤ê¸°
    azure_config = None
    openai_available = False

    try:
        azure_config = system_info.get("azure_config")
        if not azure_config:
            from azure_config import get_azure_config

            azure_config = get_azure_config()

        # OpenAI ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
        if (
            azure_config
            and hasattr(azure_config, "openai_api_key")
            and azure_config.openai_api_key
            and hasattr(azure_config, "openai_endpoint")
            and azure_config.openai_endpoint
        ):
            openai_available = True

    except Exception as config_error:
        st.warning(f"Azure ì„¤ì • ë¡œë“œ ì‹¤íŒ¨: {config_error}")
        azure_config = None

    # AI ìƒíƒœ í‘œì‹œ (ë” ëª…í™•í•˜ê²Œ)
    if openai_available:
        st.success("ğŸ¤– Azure OpenAI ì‚¬ìš© ê°€ëŠ¥ - ìì—°ì–´ ì§ˆë¬¸ì„ SQLë¡œ ìë™ ë³€í™˜")
        st.info(
            "ğŸ’¡ ì˜ˆ: 'ì§€ë‚œ 3ê°œì›” ë™ì•ˆ SKí…”ë ˆì½¤ì—ì„œ LGìœ í”ŒëŸ¬ìŠ¤ë¡œ ì´ë™í•œ ê³ ê° ìˆ˜ì™€ ì •ì‚° ê¸ˆì•¡ì„ ì›”ë³„ë¡œ ë³´ì—¬ì¤˜'"
        )
    else:
        st.warning(
            "ğŸ“‹ ê·œì¹™ ê¸°ë°˜ ì¿¼ë¦¬ ìƒì„±ë§Œ ì‚¬ìš© ê°€ëŠ¥ - ë¯¸ë¦¬ ì •ì˜ëœ íŒ¨í„´ìœ¼ë¡œ ì¿¼ë¦¬ ìƒì„±"
        )
        st.info(
            "ğŸ’¡ ì˜ˆ: 'ì›”ë³„ í¬íŠ¸ì¸ í˜„í™©', 'SKí…”ë ˆì½¤ í¬íŠ¸ì•„ì›ƒ í˜„í™©', '010-1234-5678 ë²ˆí˜¸ ì¡°íšŒ'"
        )

    # DB íƒ€ì… í‘œì‹œ
    db_type_info = "â˜ï¸ Azure SQL Database" if is_azure else "ğŸ’» SQLite"
    st.info(f"í˜„ì¬ ì—°ê²°: {db_type_info}")

    # ì±„íŒ… íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”
    if "chat_history" not in st.session_state:
        st.session_state.chat_history = []

    # ì˜ˆì‹œ ì¿¼ë¦¬ ë²„íŠ¼ë“¤ (OpenAI ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ì— ë”°ë¼ ë‹¤ë¥¸ ì˜ˆì‹œ ì œê³µ)
    st.subheader("ğŸ’¡ ë¹ ë¥¸ ì¿¼ë¦¬ ì˜ˆì‹œ")

    if openai_available:
        # OpenAI ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš° - ë” ë³µì¡í•œ ìì—°ì–´ ì˜ˆì‹œ
        col1, col2, col3 = st.columns(3)

        with col1:
            if st.button("ğŸ¤– AI: ì›”ë³„ í¬íŠ¸ì¸ ë¶„ì„"):
                st.session_state.user_input = "ì§€ë‚œ 6ê°œì›” ë™ì•ˆ ì›”ë³„ í¬íŠ¸ì¸ í˜„í™©ì„ ì‚¬ì—…ìë³„ë¡œ ë¶„ì„í•´ì„œ ì´ ê±´ìˆ˜, ì´ ê¸ˆì•¡, í‰ê·  ì •ì‚°ì•¡ì„ ë³´ì—¬ì¤˜"

        with col2:
            if st.button("ğŸ¤– AI: ì‚¬ì—…ì ë¹„êµ ë¶„ì„"):
                st.session_state.user_input = (
                    "SKí…”ë ˆì½¤, KT, LGìœ í”ŒëŸ¬ìŠ¤ ê°„ì˜ í¬íŠ¸ì¸/í¬íŠ¸ì•„ì›ƒ í˜„í™©ì„ ë¹„êµ ë¶„ì„í•´ì¤˜"
                )

        with col3:
            if st.button("ğŸ¤– AI: ì •ì‚° íŒ¨í„´ ë¶„ì„"):
                st.session_state.user_input = "ìµœê·¼ 3ê°œì›” ì˜ˆì¹˜ê¸ˆ ìˆ˜ë‚© íŒ¨í„´ì„ ì›”ë³„ë¡œ ë¶„ì„í•˜ê³  í‰ê· , ìµœëŒ€, ìµœì†Œ ê¸ˆì•¡ì„ ì•Œë ¤ì¤˜"

        # ì¶”ê°€ AI ì˜ˆì‹œ
        st.markdown("### ğŸ§  ê³ ê¸‰ AI ì¿¼ë¦¬ ì˜ˆì‹œ")
        ai_examples = [
            "íŠ¹ì • ë²ˆí˜¸ 010-1234-5678ì˜ ì „ì²´ ë²ˆí˜¸ì´ë™ ì´ë ¥ê³¼ ì •ì‚° ë‚´ì—­ì„ ì‹œê°„ìˆœìœ¼ë¡œ ì •ë¦¬í•´ì¤˜",
            "ì§€ë‚œ ë‹¬ ëŒ€ë¹„ ì´ë²ˆ ë‹¬ í¬íŠ¸ì¸ ì¦ê°ë¥ ì„ ì‚¬ì—…ìë³„ë¡œ ê³„ì‚°í•´ì¤˜",
            "ì •ì‚° ê¸ˆì•¡ì´ í‰ê· ë³´ë‹¤ ë†’ì€ ê±°ë˜ë“¤ì˜ íŒ¨í„´ì„ ë¶„ì„í•´ì¤˜",
            "ì£¼ìš” ì‚¬ì—…ìë³„ ê³ ê° ìœ ì¹˜(í¬íŠ¸ì¸) ëŒ€ë¹„ ì´íƒˆ(í¬íŠ¸ì•„ì›ƒ) ë¹„ìœ¨ì„ ê³„ì‚°í•´ì¤˜",
        ]
    else:
        # OpenAI ì‚¬ìš© ë¶ˆê°€ëŠ¥í•œ ê²½ìš° - ê¸°ë³¸ ê·œì¹™ ê¸°ë°˜ ì˜ˆì‹œ
        col1, col2, col3 = st.columns(3)

        with col1:
            if st.button("ğŸ“Š ì›”ë³„ í¬íŠ¸ì¸ í˜„í™©"):
                st.session_state.user_input = "ì›”ë³„ í¬íŠ¸ì¸ í˜„í™©ì„ ì•Œë ¤ì¤˜"

        with col2:
            if st.button("ğŸ” íŠ¹ì • ë²ˆí˜¸ ì¡°íšŒ"):
                st.session_state.user_input = "010-1234-5678 ë²ˆí˜¸ì˜ ì •ì‚° ë‚´ì—­ í™•ì¸í•´ì¤˜"

        with col3:
            if st.button("ğŸ“ˆ ì‚¬ì—…ìë³„ ì§‘ê³„"):
                st.session_state.user_input = "ì‚¬ì—…ìë³„ ë²ˆí˜¸ì´ë™ ì •ì‚° í˜„í™© ë³´ì—¬ì¤˜"

        # ê¸°ë³¸ ì˜ˆì‹œ
        st.markdown("### ğŸ¯ ê·œì¹™ ê¸°ë°˜ ì¿¼ë¦¬ ì˜ˆì‹œ")
        ai_examples = [
            "SKí…”ë ˆì½¤ í¬íŠ¸ì•„ì›ƒ í˜„í™© ì•Œë ¤ì¤˜",
            "ìµœê·¼ 3ê°œì›” ì˜ˆì¹˜ê¸ˆ í˜„í™© ë³´ì—¬ì¤˜",
            "ì›”ë³„ ë²ˆí˜¸ì´ë™ ì¶”ì´ ë¶„ì„í•´ì¤˜",
            "LGìœ í”ŒëŸ¬ìŠ¤ ê´€ë ¨ ì •ì‚° ë‚´ì—­ í™•ì¸í•´ì¤˜",
        ]

    # ì˜ˆì‹œ ë²„íŠ¼ë“¤ í‘œì‹œ
    for i, example in enumerate(ai_examples):
        if st.button(f"ğŸ’¬ {example}", key=f"example_{i}"):
            st.session_state.user_input = example

    # ì‚¬ìš©ì ì…ë ¥
    placeholder_text = (
        "ì˜ˆ: 'ì§€ë‚œ 3ê°œì›” SKí…”ë ˆì½¤ í¬íŠ¸ì¸ ê³ ê°ì˜ í‰ê·  ì •ì‚°ì•¡ê³¼ ì›”ë³„ ì¶”ì´ë¥¼ ë¶„ì„í•´ì¤˜'"
        if openai_available
        else "ì˜ˆ: '2024ë…„ 1ì›” SKí…”ë ˆì½¤ í¬íŠ¸ì¸ ì •ì‚° ê¸ˆì•¡ ì•Œë ¤ì¤˜'"
    )

    user_input = st.text_input(
        "ğŸ’¬ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:", key="user_input", placeholder=placeholder_text
    )

    if st.button("ğŸš€ ì¿¼ë¦¬ ìƒì„± ë° ì‹¤í–‰") and user_input:
        query_method = "AI (OpenAI)" if openai_available else "ê·œì¹™ ê¸°ë°˜"

        with st.spinner(f"ğŸ¤– {query_method} ë°©ì‹ìœ¼ë¡œ ì¿¼ë¦¬ë¥¼ ìƒì„±í•˜ê³  ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤..."):
            try:
                # SQL ì¿¼ë¦¬ ìƒì„± (OpenAI ìš°ì„ , azure_config ì „ë‹¬)
                sql_query = generate_sql_query(user_input, is_azure, azure_config)

                # ì¿¼ë¦¬ ì‹¤í–‰
                result_df = pd.read_sql_query(sql_query, _conn)

                # ê²°ê³¼ í‘œì‹œ
                success_message = (
                    f"âœ… {query_method}ë¡œ ì¿¼ë¦¬ê°€ ì„±ê³µì ìœ¼ë¡œ ì‹¤í–‰ë˜ì—ˆìŠµë‹ˆë‹¤!"
                )
                st.markdown(
                    f'<div class="success-alert">{success_message}</div>',
                    unsafe_allow_html=True,
                )

                # ìƒì„±ëœ SQL í‘œì‹œ
                with st.expander("ğŸ” ìƒì„±ëœ SQL ì¿¼ë¦¬ ë³´ê¸°"):
                    st.code(sql_query, language="sql")
                    st.caption(f"ìƒì„± ë°©ì‹: {query_method}")

                # ê²°ê³¼ ë°ì´í„° í‘œì‹œ
                if not result_df.empty:
                    st.subheader("ğŸ“‹ ì¿¼ë¦¬ ì‹¤í–‰ ê²°ê³¼")
                    st.dataframe(result_df, use_container_width=True)

                    # ê²°ê³¼ ì‹œê°í™”
                    create_result_visualization(result_df)

                    # CSV ë‹¤ìš´ë¡œë“œ
                    csv = result_df.to_csv(index=False, encoding="utf-8-sig")
                    st.download_button(
                        label="ğŸ“¥ ê²°ê³¼ ë°ì´í„° ë‹¤ìš´ë¡œë“œ (CSV)",
                        data=csv,
                        file_name=f"query_result_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                        mime="text/csv",
                    )
                else:
                    st.warning("âš ï¸ ì¿¼ë¦¬ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")

                # ì±„íŒ… íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
                st.session_state.chat_history.append(
                    {
                        "user": user_input,
                        "sql": sql_query,
                        "result_count": len(result_df) if not result_df.empty else 0,
                        "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                        "db_type": "Azure SQL" if is_azure else "SQLite",
                        "query_method": query_method,
                    }
                )

            except Exception as e:
                error_message = f"âŒ ì¿¼ë¦¬ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
                st.markdown(
                    f'<div class="error-alert">{error_message}</div>',
                    unsafe_allow_html=True,
                )

                if openai_available:
                    st.info(
                        "ğŸ’¡ AI ì¿¼ë¦¬ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë” êµ¬ì²´ì ìœ¼ë¡œ ì§ˆë¬¸í•˜ê±°ë‚˜ ì˜ˆì‹œ ì¿¼ë¦¬ë¥¼ ì‚¬ìš©í•´ë³´ì„¸ìš”."
                    )
                else:
                    st.info(
                        "ğŸ’¡ ê·œì¹™ ê¸°ë°˜ ì¿¼ë¦¬ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë¯¸ë¦¬ ì •ì˜ëœ íŒ¨í„´ìœ¼ë¡œ ì§ˆë¬¸í•´ë³´ì‹œê±°ë‚˜ ì˜ˆì‹œ ì¿¼ë¦¬ë¥¼ ì‚¬ìš©í•´ë³´ì„¸ìš”."
                    )

    # ì±„íŒ… íˆìŠ¤í† ë¦¬ í‘œì‹œ (ì¿¼ë¦¬ ìƒì„± ë°©ì‹ ì •ë³´ í¬í•¨)
    if st.session_state.chat_history:
        st.subheader("ğŸ“ ìµœê·¼ ì¿¼ë¦¬ íˆìŠ¤í† ë¦¬")
        with st.expander("íˆìŠ¤í† ë¦¬ ë³´ê¸°"):
            for chat in reversed(st.session_state.chat_history[-5:]):
                query_method_info = chat.get("query_method", "ì•Œ ìˆ˜ ì—†ìŒ")
                st.markdown(
                    f"""
                <div class="chat-container">
                    <strong>ğŸ—£ï¸ ì§ˆë¬¸:</strong> {chat['user']}<br>
                    <strong>â° ì‹œê°„:</strong> {chat['timestamp']}<br>
                    <strong>ğŸ“Š ê²°ê³¼:</strong> {chat['result_count']}ê±´<br>
                    <strong>ğŸ—„ï¸ DB:</strong> {chat.get('db_type', 'Unknown')}<br>
                    <strong>ğŸ¤– ìƒì„±ë°©ì‹:</strong> {query_method_info}
                </div>
                """,
                    unsafe_allow_html=True,
                )


def create_result_visualization(df):
    """ê²°ê³¼ ë°ì´í„° ì‹œê°í™”"""

    if len(df.columns) < 2:
        return

    # ì»¬ëŸ¼ëª…ì„ ê¸°ë°˜ìœ¼ë¡œ ì ì ˆí•œ ì°¨íŠ¸ ìƒì„±
    columns = df.columns.tolist()

    # ì´ê¸ˆì•¡ê³¼ ì‚¬ì—…ìê°€ ìˆëŠ” ê²½ìš°
    if "ì´ê¸ˆì•¡" in columns and (
        "ì‚¬ì—…ì" in columns or "ì „ì‚¬ì—…ì" in columns or "í›„ì‚¬ì—…ì" in columns
    ):
        operator_col = next(
            (col for col in ["ì‚¬ì—…ì", "ì „ì‚¬ì—…ì", "í›„ì‚¬ì—…ì"] if col in columns), None
        )
        if operator_col:
            fig = px.bar(
                df,
                x=operator_col,
                y="ì´ê¸ˆì•¡",
                color="ë²ˆí˜¸ì´ë™íƒ€ì…" if "ë²ˆí˜¸ì´ë™íƒ€ì…" in columns else None,
                title="ğŸ’° ì‚¬ì—…ìë³„ ì •ì‚° ê¸ˆì•¡ ë¹„êµ",
            )
            st.plotly_chart(fig, use_container_width=True)

    # ì›”ë³„ ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš°
    elif "ë²ˆí˜¸ì´ë™ì›”" in columns and "ì´ê¸ˆì•¡" in columns:
        operator_col = next(
            (col for col in ["ì „ì‚¬ì—…ì", "í›„ì‚¬ì—…ì"] if col in columns), None
        )
        fig = px.line(
            df,
            x="ë²ˆí˜¸ì´ë™ì›”",
            y="ì´ê¸ˆì•¡",
            color=operator_col if operator_col else None,
            title="ğŸ“ˆ ì›”ë³„ ì •ì‚° ê¸ˆì•¡ ì¶”ì´",
        )
        st.plotly_chart(fig, use_container_width=True)

    # ë²ˆí˜¸ì´ë™íƒ€ì…ë³„ ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš°
    elif "ë²ˆí˜¸ì´ë™íƒ€ì…" in columns and "ë²ˆí˜¸ì´ë™ê±´ìˆ˜" in columns:
        fig = px.pie(
            df,
            values="ë²ˆí˜¸ì´ë™ê±´ìˆ˜",
            names="ë²ˆí˜¸ì´ë™íƒ€ì…",
            title="ğŸ“Š í¬íŠ¸ì¸/í¬íŠ¸ì•„ì›ƒ ë¹„ìœ¨",
        )
        st.plotly_chart(fig, use_container_width=True)


def display_sidebar(_conn, system_info):
    """ì‚¬ì´ë“œë°” í‘œì‹œ"""

    with st.sidebar:
        st.header("ğŸ”§ ì‹œìŠ¤í…œ ì •ë³´")

        # ì—°ê²° ì •ë³´ í‘œì‹œ
        connection_info = system_info["connection_info"]
        is_azure = system_info["is_azure"]

        st.subheader("ğŸ”— ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°")
        if is_azure:
            st.success("â˜ï¸ Azure SQL Database")
            st.info("ğŸ”µ ìš´ì˜ ëª¨ë“œ")
        else:
            st.warning("ğŸ’» ë¡œì»¬ SQLite")
            st.info("ğŸŸ¡ ê°œë°œ ëª¨ë“œ (ìƒ˜í”Œ ë°ì´í„°)")

        # ë°ì´í„°ë² ì´ìŠ¤ í˜„í™©
        st.subheader("ğŸ“Š ë°ì´í„° í˜„í™©")
        try:
            if is_azure:
                # Azure SQL Database ì¿¼ë¦¬
                port_in_count = pd.read_sql_query(
                    "SELECT COUNT(*) as count FROM PY_NP_SBSC_RMNY_TXN WHERE NP_STTUS_CD IN ('OK', 'WD')",
                    _conn,
                ).iloc[0]["count"]
                port_out_count = pd.read_sql_query(
                    "SELECT COUNT(*) as count FROM PY_NP_TRMN_RMNY_TXN WHERE NP_TRMN_DTL_STTUS_VAL IN ('1', '3')",
                    _conn,
                ).iloc[0]["count"]
                deposit_count = pd.read_sql_query(
                    "SELECT COUNT(*) as count FROM PY_DEPAZ_BAS WHERE DEPAZ_DIV_CD = '10'",
                    _conn,
                ).iloc[0]["count"]
            else:
                # SQLite ì¿¼ë¦¬
                port_in_count = pd.read_sql_query(
                    "SELECT COUNT(*) as count FROM PY_NP_SBSC_RMNY_TXN", _conn
                ).iloc[0]["count"]
                port_out_count = pd.read_sql_query(
                    "SELECT COUNT(*) as count FROM PY_NP_TRMN_RMNY_TXN", _conn
                ).iloc[0]["count"]
                deposit_count = pd.read_sql_query(
                    "SELECT COUNT(*) as count FROM PY_DEPAZ_BAS", _conn
                ).iloc[0]["count"]

            st.metric("ğŸ“¥ í¬íŠ¸ì¸ ë°ì´í„°", f"{port_in_count:,}ê±´")
            st.metric("ğŸ“¤ í¬íŠ¸ì•„ì›ƒ ë°ì´í„°", f"{port_out_count:,}ê±´")
            st.metric("ğŸ’° ì˜ˆì¹˜ê¸ˆ ë°ì´í„°", f"{deposit_count:,}ê±´")

        except Exception as e:
            st.error(f"ë°ì´í„° ì¡°íšŒ ì˜¤ë¥˜: {e}")

        st.markdown("---")

        # Azure ì„œë¹„ìŠ¤ ìƒíƒœ
        st.subheader("âš™ï¸ Azure ì„œë¹„ìŠ¤ ìƒíƒœ")
        azure_config = system_info["azure_config"]

        try:
            # Azure ì—°ê²° í…ŒìŠ¤íŠ¸
            test_results = azure_config.test_connection()

            st.write(
                "ğŸ¤– OpenAI:", "âœ… ì—°ê²°ë¨" if test_results["openai"] else "âŒ ì—°ê²° ì‹¤íŒ¨"
            )
            st.write(
                "ğŸ—„ï¸ Database:",
                "âœ… ì—°ê²°ë¨" if test_results["database"] else "âŒ ì—°ê²° ì‹¤íŒ¨",
            )

            st.subheader("âš™ï¸ Azure ì„œë¹„ìŠ¤ ìƒíƒœ")
            if azure_config and azure_config.is_production_ready():
                st.success("â˜ï¸ Azure ì„œë¹„ìŠ¤ ì‚¬ìš© ê°€ëŠ¥")
            else:
                st.warning("ğŸ’» ë¡œì»¬ ëª¨ë“œ ì‚¬ìš©")

        except Exception as e:
            st.error(f"Azure ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {e}")

        st.markdown("---")

        # ë°ì´í„° ê´€ë¦¬
        st.subheader("ğŸ—‚ï¸ ë°ì´í„° ê´€ë¦¬")

        if is_azure:
            # Azure ëª¨ë“œì—ì„œ ìƒ˜í”Œ ë°ì´í„° ê´€ë¦¬
            col1, col2 = st.columns(2)

            with col1:
                if st.button("ğŸ”„ ë°ì´í„° ìƒˆë¡œê³ ì¹¨"):
                    st.cache_data.clear()
                    st.rerun()

            with col2:
                if st.button("ğŸ§¹ ìƒ˜í”Œ ë°ì´í„° ì •ë¦¬"):
                    try:
                        sample_manager = system_info["sample_manager"]
                        sample_manager.cleanup_sample_data(_conn)
                        st.success("ìƒ˜í”Œ ë°ì´í„° ì •ë¦¬ ì™„ë£Œ")
                        st.cache_data.clear()
                        st.rerun()
                    except Exception as e:
                        st.error(f"ì •ë¦¬ ì‹¤íŒ¨: {e}")

            # ê°•ì œ ë¡œì»¬ ëª¨ë“œ ì „í™˜
            if st.button("ğŸ’» ë¡œì»¬ ëª¨ë“œë¡œ ì „í™˜"):
                st.cache_resource.clear()
                st.session_state.clear()
                st.rerun()

        else:
            # ë¡œì»¬ ëª¨ë“œì—ì„œì˜ ë°ì´í„° ê´€ë¦¬
            if st.button("ğŸ”„ ë°ì´í„° ìƒˆë¡œê³ ì¹¨"):
                st.cache_data.clear()
                st.cache_resource.clear()
                st.rerun()

            # Azure ëª¨ë“œ ì‹œë„
            if st.button("â˜ï¸ Azure ëª¨ë“œ ì‹œë„"):
                st.cache_resource.clear()
                st.session_state.clear()
                st.rerun()

        st.markdown("---")

        # ì‚¬ìš©ë²• ì•ˆë‚´
        st.subheader("ğŸ’¡ ì‚¬ìš©ë²• ì•ˆë‚´")
        st.markdown(
            """
        **ì¿¼ë¦¬ ì˜ˆì‹œ:**
        - "ì›”ë³„ í¬íŠ¸ì¸ í˜„í™©"
        - "SKí…”ë ˆì½¤ ì •ì‚° ë‚´ì—­"
        - "010-1234-5678 ë²ˆí˜¸ ì¡°íšŒ"
        - "ì‚¬ì—…ìë³„ ë¹„êµ"
        - "ì˜ˆì¹˜ê¸ˆ í˜„í™©"
        
        **ë°ì´í„°ë² ì´ìŠ¤:**
        - â˜ï¸ Azure: ì‹¤ì‹œê°„ ìš´ì˜ ë°ì´í„°
        - ğŸ’» ë¡œì»¬: ìƒ˜í”Œ í…ŒìŠ¤íŠ¸ ë°ì´í„°
        """
        )

        st.markdown("---")


# ë©”ì¸ ì‹¤í–‰
if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        st.error(f"ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘ ì‹¤íŒ¨: {e}")
        st.info("ë¡œì»¬ ëª¨ë“œë¡œ ì „í™˜í•˜ì—¬ ë‹¤ì‹œ ì‹œë„í•´ë³´ì„¸ìš”.")

        # ê¸´ê¸‰ í´ë°± - ê¸°ë³¸ ë¡œì»¬ ëª¨ë“œ
        try:
            st.header("ğŸ”§ ë¡œì»¬ ëª¨ë“œ")
            st.warning("ì‹œìŠ¤í…œ ì˜¤ë¥˜ë¡œ ì¸í•´ ê¸°ë³¸ ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.")

            # ê¸°ë³¸ ìƒ˜í”Œ ë°ì´í„°ë² ì´ìŠ¤ ìƒì„±
            conn = create_sample_database()

            st.success("âœ… ê¸°ë³¸ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì„±ê³µ")

            # ê¸°ë³¸ í˜„í™© í‘œì‹œ
            try:
                basic_query = """
                SELECT 
                    'PORT_IN' as type,
                    COUNT(*) as count,
                    SUM(SETL_AMT) as amount
                FROM PY_NP_SBSC_RMNY_TXN
                UNION ALL
                SELECT 
                    'PORT_OUT' as type,
                    COUNT(*) as count,
                    SUM(PAY_AMT) as amount
                FROM PY_NP_TRMN_RMNY_TXN
                """

                basic_df = pd.read_sql_query(basic_query, conn)
                st.dataframe(basic_df)

            except Exception as basic_error:
                st.error(f"ê¸°ë³¸ ì¿¼ë¦¬ ì‹¤í–‰ ì‹¤íŒ¨: {basic_error}")

        except Exception as fallback_error:
            st.error(f"ê¸´ê¸‰ ë³µêµ¬ ëª¨ë“œ ì‹¤íŒ¨: {fallback_error}")
            st.info("ì‹œìŠ¤í…œ ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”.")
