# sample_data.py - Azure SQL Database ì—°ë™ ìƒ˜í”Œ ë°ì´í„° ê´€ë¦¬
import sqlite3
import pandas as pd
import numpy as np
import pyodbc
from datetime import datetime, timedelta
import random
import logging
from typing import Optional, Dict, Any, Tuple
from azure_config import AzureConfig


class SampleDataManager:
    """ìƒ˜í”Œ ë°ì´í„° ê´€ë¦¬ í´ë˜ìŠ¤ - SQLiteì™€ Azure SQL Database ì§€ì›"""

    def __init__(self, azure_config: AzureConfig, force_local: bool = False):
        """
        ìƒ˜í”Œ ë°ì´í„° ë§¤ë‹ˆì € ì´ˆê¸°í™”

        Args:
            azure_config: Azure ì„¤ì • ê°ì²´
            force_local: ê°•ì œë¡œ ë¡œì»¬ SQLite ì‚¬ìš©
        """
        self.azure_config = azure_config
        self.force_local = force_local
        self.logger = logging.getLogger(__name__)

        # Azure ì—°ê²° ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
        self.use_azure = not force_local and azure_config.is_production_ready()

        # ì—°ê²° ì •ë³´
        self.connection_string = None
        self.sqlite_conn = None

        if self.use_azure:
            self.connection_string = azure_config.get_database_connection_string()
            self.logger.info("Azure SQL Database ëª¨ë“œë¡œ ì´ˆê¸°í™”")
        else:
            self.logger.info("ë¡œì»¬ SQLite ëª¨ë“œë¡œ ì´ˆê¸°í™”")

    def get_connection(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ë°˜í™˜"""
        if self.use_azure:
            return pyodbc.connect(self.connection_string, timeout=30)
        else:
            if self.sqlite_conn is None:
                self.sqlite_conn = sqlite3.connect(":memory:", check_same_thread=False)
            return self.sqlite_conn

    def create_sample_database(self):
        """
        ìƒ˜í”Œ ë°ì´í„°ë² ì´ìŠ¤ ìƒì„± ë° ë°ì´í„° ì‚½ì…
        Azure SQL Database ì—°ê²°ì‹œì—ëŠ” ê¸°ì¡´ ë°ì´í„° í™•ì¸ í›„ ìƒì„±
        """
        try:
            if self.use_azure:
                return self._handle_azure_sample_data()
            else:
                return self._create_local_sample_data()

        except Exception as e:
            self.logger.error(f"ìƒ˜í”Œ ë°ì´í„°ë² ì´ìŠ¤ ìƒì„± ì‹¤íŒ¨: {e}")
            # Azure ì‹¤íŒ¨ì‹œ ë¡œì»¬ë¡œ í´ë°±
            if self.use_azure:
                self.logger.warning("Azure ì—°ê²° ì‹¤íŒ¨, ë¡œì»¬ SQLiteë¡œ ì „í™˜")
                self.use_azure = False
                return self._create_local_sample_data()
            raise e

    def _handle_azure_sample_data(self):
        """Azure SQL Database ìƒ˜í”Œ ë°ì´í„° ì²˜ë¦¬"""
        conn = self.get_connection()

        try:
            # 1. í…Œì´ë¸” ì¡´ì¬ ì—¬ë¶€ í™•ì¸
            if not self._check_tables_exist(conn):
                self.logger.info("Azure SQL Databaseì— í…Œì´ë¸” ìƒì„± ì¤‘...")
                self._create_azure_tables(conn)

            # 2. ê¸°ì¡´ ë°ì´í„° í™•ì¸
            data_stats = self._check_existing_data(conn)

            # 3. ë°ì´í„°ê°€ ì¶©ë¶„íˆ ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©
            if self._is_sufficient_data(data_stats):
                self.logger.info("ì¶©ë¶„í•œ ìƒ˜í”Œ ë°ì´í„°ê°€ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤")
                self._log_data_statistics(data_stats)
                return conn

            # 4. ë°ì´í„°ê°€ ë¶€ì¡±í•˜ë©´ ì¶”ê°€ ìƒì„±
            self.logger.info("ìƒ˜í”Œ ë°ì´í„° ì¶”ê°€ ìƒì„± ì¤‘...")
            self._generate_azure_sample_data(conn, data_stats)

            # 5. ìµœì¢… í†µê³„ ì¶œë ¥
            final_stats = self._check_existing_data(conn)
            self._log_data_statistics(final_stats)

            return conn

        except Exception as e:
            self.logger.error(f"Azure ìƒ˜í”Œ ë°ì´í„° ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            conn.close()
            raise e

    def _create_local_sample_data(self):
        """ë¡œì»¬ SQLite ìƒ˜í”Œ ë°ì´í„° ìƒì„±"""
        conn = self.get_connection()

        # í…Œì´ë¸” ìƒì„±
        self._create_sqlite_tables(conn)

        # ìƒ˜í”Œ ë°ì´í„° ìƒì„±
        self._generate_sample_data(conn)

        self.logger.info("âœ… ë¡œì»¬ ìƒ˜í”Œ ë°ì´í„°ë² ì´ìŠ¤ê°€ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!")
        return conn

    def _check_tables_exist(self, conn) -> bool:
        """Azure SQL Databaseì—ì„œ í…Œì´ë¸” ì¡´ì¬ ì—¬ë¶€ í™•ì¸"""
        try:
            cursor = conn.cursor()

            # ì‹œìŠ¤í…œ í…Œì´ë¸”ì—ì„œ í™•ì¸
            check_query = """
            SELECT COUNT(*) as table_count
            FROM INFORMATION_SCHEMA.TABLES 
            WHERE TABLE_NAME IN (
                'PY_NP_TRMN_RMNY_TXN', 
                'PY_NP_SBSC_RMNY_TXN', 
                'PY_DEPAZ_BAS'
            )
            """

            cursor.execute(check_query)
            result = cursor.fetchone()
            table_count = result[0] if result else 0

            self.logger.info(f"Azure SQL Databaseì—ì„œ {table_count}/3ê°œ í…Œì´ë¸” ë°œê²¬")
            return table_count == 3

        except Exception as e:
            self.logger.error(f"í…Œì´ë¸” ì¡´ì¬ í™•ì¸ ì‹¤íŒ¨: {e}")
            return False

    def _check_existing_data(self, conn) -> Dict[str, int]:
        """ê¸°ì¡´ ë°ì´í„° í˜„í™© í™•ì¸"""
        data_stats = {
            "PY_NP_TRMN_RMNY_TXN": 0,
            "PY_NP_SBSC_RMNY_TXN": 0,
            "PY_DEPAZ_BAS": 0,
        }

        try:
            cursor = conn.cursor()

            for table_name in data_stats.keys():
                try:
                    cursor.execute(f"SELECT COUNT(*) FROM {table_name}")
                    result = cursor.fetchone()
                    data_stats[table_name] = result[0] if result else 0
                except Exception as e:
                    self.logger.warning(f"í…Œì´ë¸” {table_name} ë°ì´í„° í™•ì¸ ì‹¤íŒ¨: {e}")
                    data_stats[table_name] = 0

            return data_stats

        except Exception as e:
            self.logger.error(f"ê¸°ì¡´ ë°ì´í„° í™•ì¸ ì‹¤íŒ¨: {e}")
            return data_stats

    def _is_sufficient_data(self, data_stats: Dict[str, int]) -> bool:
        """ì¶©ë¶„í•œ ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸"""
        min_requirements = {
            "PY_NP_TRMN_RMNY_TXN": 500,  # ìµœì†Œ 500ê±´
            "PY_NP_SBSC_RMNY_TXN": 600,  # ìµœì†Œ 600ê±´
            "PY_DEPAZ_BAS": 500,  # ìµœì†Œ 500ê±´
        }

        for table_name, min_count in min_requirements.items():
            if data_stats.get(table_name, 0) < min_count:
                self.logger.info(
                    f"{table_name}: {data_stats.get(table_name, 0)}ê±´ (ìµœì†Œ {min_count}ê±´ í•„ìš”)"
                )
                return False

        return True

    def _create_azure_tables(self, conn):
        """Azure SQL Database í…Œì´ë¸” ìƒì„±"""
        cursor = conn.cursor()

        # 1. í•´ì§€ë²ˆí˜¸ì´ë™ ì •ì‚° í…Œì´ë¸” (í¬íŠ¸ì•„ì›ƒ)
        cursor.execute(
            """
            IF NOT EXISTS (SELECT * FROM INFORMATION_SCHEMA.TABLES WHERE TABLE_NAME = 'PY_NP_TRMN_RMNY_TXN')
            CREATE TABLE PY_NP_TRMN_RMNY_TXN (
                NP_DIV_CD NVARCHAR(3),
                TRMN_NP_ADM_NO NVARCHAR(11) PRIMARY KEY,
                NP_TRMN_DATE DATE NOT NULL,
                CNCL_WTHD_DATE DATE,
                BCHNG_COMM_CMPN_ID NVARCHAR(11),
                ACHNG_COMM_CMPN_ID NVARCHAR(11),
                SVC_CONT_ID NVARCHAR(20),
                BILL_ACC_ID NVARCHAR(11),
                TEL_NO NVARCHAR(20),
                NP_TRMN_DTL_STTUS_VAL NVARCHAR(3),
                PAY_AMT DECIMAL(18,3),
                CREATED_AT DATETIME2 DEFAULT GETDATE(),
                IS_SAMPLE_DATA BIT DEFAULT 1
            )
        """
        )

        # 2. ê°€ì…ë²ˆí˜¸ì´ë™ ì •ì‚° í…Œì´ë¸” (í¬íŠ¸ì¸)
        cursor.execute(
            """
            IF NOT EXISTS (SELECT * FROM INFORMATION_SCHEMA.TABLES WHERE TABLE_NAME = 'PY_NP_SBSC_RMNY_TXN')
            CREATE TABLE PY_NP_SBSC_RMNY_TXN (
                NP_DIV_CD NVARCHAR(3),
                NP_SBSC_RMNY_SEQ INT IDENTITY(1,1) PRIMARY KEY,
                TRT_DATE DATE NOT NULL,
                CNCL_DATE DATE,
                BCHNG_COMM_CMPN_ID NVARCHAR(11),
                ACHNG_COMM_CMPN_ID NVARCHAR(11),
                SVC_CONT_ID NVARCHAR(20),
                BILL_ACC_ID NVARCHAR(11),
                TEL_NO NVARCHAR(20),
                NP_STTUS_CD NVARCHAR(3),
                SETL_AMT DECIMAL(15,2),
                CREATED_AT DATETIME2 DEFAULT GETDATE(),
                IS_SAMPLE_DATA BIT DEFAULT 1
            )
        """
        )

        # 3. ì˜ˆì¹˜ê¸ˆ ê¸°ë³¸ í…Œì´ë¸”
        cursor.execute(
            """
            IF NOT EXISTS (SELECT * FROM INFORMATION_SCHEMA.TABLES WHERE TABLE_NAME = 'PY_DEPAZ_BAS')
            CREATE TABLE PY_DEPAZ_BAS (
                DEPAZ_SEQ INT IDENTITY(1,1) PRIMARY KEY,
                SVC_CONT_ID NVARCHAR(20),
                BILL_ACC_ID NVARCHAR(11),
                DEPAZ_DIV_CD NVARCHAR(3),
                RMNY_DATE DATE,
                RMNY_METH_CD NVARCHAR(5),
                DEPAZ_AMT DECIMAL(15,2),
                CREATED_AT DATETIME2 DEFAULT GETDATE(),
                IS_SAMPLE_DATA BIT DEFAULT 1
            )
        """
        )

        # ì¸ë±ìŠ¤ ìƒì„±
        self._create_azure_indexes(cursor)

        conn.commit()
        self.logger.info("Azure SQL Database í…Œì´ë¸” ìƒì„± ì™„ë£Œ")

    def _create_azure_indexes(self, cursor):
        """Azure SQL Database ì¸ë±ìŠ¤ ìƒì„±"""
        indexes = [
            "CREATE NONCLUSTERED INDEX IX_PY_NP_TRMN_RMNY_TXN_DATE ON PY_NP_TRMN_RMNY_TXN(NP_TRMN_DATE)",
            "CREATE NONCLUSTERED INDEX IX_PY_NP_TRMN_RMNY_TXN_OPERATOR ON PY_NP_TRMN_RMNY_TXN(BCHNG_COMM_CMPN_ID)",
            "CREATE NONCLUSTERED INDEX IX_PY_NP_SBSC_RMNY_TXN_DATE ON PY_NP_SBSC_RMNY_TXN(TRT_DATE)",
            "CREATE NONCLUSTERED INDEX IX_PY_NP_SBSC_RMNY_TXN_OPERATOR ON PY_NP_SBSC_RMNY_TXN(BCHNG_COMM_CMPN_ID)",
            "CREATE NONCLUSTERED INDEX IX_PY_DEPAZ_BAS_DATE ON PY_DEPAZ_BAS(RMNY_DATE)",
        ]

        for index_sql in indexes:
            try:
                cursor.execute(
                    f"IF NOT EXISTS (SELECT * FROM sys.indexes WHERE name = '{index_sql.split()[-1].split('(')[0]}') {index_sql}"
                )
            except Exception as e:
                self.logger.warning(f"ì¸ë±ìŠ¤ ìƒì„± ì‹¤íŒ¨: {e}")

    def _create_sqlite_tables(self, conn):
        """SQLite í…Œì´ë¸” ìƒì„±"""
        # 1. í•´ì§€ë²ˆí˜¸ì´ë™ ì •ì‚° í…Œì´ë¸” (í¬íŠ¸ì•„ì›ƒ)
        conn.execute(
            """
            CREATE TABLE PY_NP_TRMN_RMNY_TXN (
                NP_DIV_CD VARCHAR(3),
                TRMN_NP_ADM_NO VARCHAR(11) PRIMARY KEY,
                NP_TRMN_DATE DATE NOT NULL,
                CNCL_WTHD_DATE DATE,
                BCHNG_COMM_CMPN_ID VARCHAR(11),
                ACHNG_COMM_CMPN_ID VARCHAR(11),
                SVC_CONT_ID VARCHAR(20),
                BILL_ACC_ID VARCHAR(11),
                TEL_NO VARCHAR(20),
                NP_TRMN_DTL_STTUS_VAL VARCHAR(3),
                PAY_AMT DECIMAL(18,3)
            )
        """
        )

        # 2. ê°€ì…ë²ˆí˜¸ì´ë™ ì •ì‚° í…Œì´ë¸” (í¬íŠ¸ì¸)
        conn.execute(
            """
            CREATE TABLE PY_NP_SBSC_RMNY_TXN (
                NP_DIV_CD VARCHAR(3),
                NP_SBSC_RMNY_SEQ INTEGER PRIMARY KEY,
                TRT_DATE DATE NOT NULL,
                CNCL_DATE DATE,
                BCHNG_COMM_CMPN_ID VARCHAR(11),
                ACHNG_COMM_CMPN_ID VARCHAR(11),
                SVC_CONT_ID VARCHAR(20),
                BILL_ACC_ID VARCHAR(11),
                TEL_NO VARCHAR(20),
                NP_STTUS_CD VARCHAR(3),
                SETL_AMT DECIMAL(15,2)
            )
        """
        )

        # 3. ì˜ˆì¹˜ê¸ˆ ê¸°ë³¸ í…Œì´ë¸”
        conn.execute(
            """
            CREATE TABLE PY_DEPAZ_BAS (
                DEPAZ_SEQ INTEGER PRIMARY KEY,
                SVC_CONT_ID VARCHAR(20),
                BILL_ACC_ID VARCHAR(11),
                DEPAZ_DIV_CD VARCHAR(3),
                RMNY_DATE DATE,
                RMNY_METH_CD VARCHAR(5),
                DEPAZ_AMT DECIMAL(15,2)
            )
        """
        )

        conn.commit()
        self.logger.info("SQLite í…Œì´ë¸” ìƒì„± ì™„ë£Œ")

    def _generate_azure_sample_data(self, conn, existing_stats: Dict[str, int]):
        """Azure SQL Databaseìš© ìƒ˜í”Œ ë°ì´í„° ìƒì„±"""
        cursor = conn.cursor()

        # í†µì‹ ì‚¬ ì •ë³´
        operators = {
            "C001": "KT",
            "C002": "SKT",
            "C003": "LGU+",
            "C004": "KT MVNO",
            "C005": "SKT MVNO",
            "C006": "LGU+ MVNO",
        }

        # ìµœê·¼ 4ê°œì›” ê¸°ê°„ ì„¤ì •
        end_date = datetime.now()
        start_date = end_date - timedelta(days=120)

        # í•„ìš”í•œ ë°ì´í„° ì–‘ ê³„ì‚°
        target_counts = {
            "PY_NP_TRMN_RMNY_TXN": 1000,
            "PY_NP_SBSC_RMNY_TXN": 1200,
            "PY_DEPAZ_BAS": 1000,
        }

        # 1. í¬íŠ¸ì•„ì›ƒ ë°ì´í„° ìƒì„±
        port_out_needed = max(
            0,
            target_counts["PY_NP_TRMN_RMNY_TXN"]
            - existing_stats["PY_NP_TRMN_RMNY_TXN"],
        )
        if port_out_needed > 0:
            self._generate_azure_port_out_data(
                cursor, operators, start_date, end_date, port_out_needed
            )

        # 2. í¬íŠ¸ì¸ ë°ì´í„° ìƒì„±
        port_in_needed = max(
            0,
            target_counts["PY_NP_SBSC_RMNY_TXN"]
            - existing_stats["PY_NP_SBSC_RMNY_TXN"],
        )
        if port_in_needed > 0:
            self._generate_azure_port_in_data(
                cursor, operators, start_date, end_date, port_in_needed
            )

        # 3. ì˜ˆì¹˜ê¸ˆ ë°ì´í„° ìƒì„±
        deposit_needed = max(
            0, target_counts["PY_DEPAZ_BAS"] - existing_stats["PY_DEPAZ_BAS"]
        )
        if deposit_needed > 0:
            self._generate_azure_deposit_data(
                cursor, start_date, end_date, deposit_needed
            )

        conn.commit()
        self.logger.info("Azure SQL Database ìƒ˜í”Œ ë°ì´í„° ìƒì„± ì™„ë£Œ")

    def _generate_azure_port_out_data(
        self, cursor, operators, start_date, end_date, count
    ):
        """Azure SQL Database í¬íŠ¸ì•„ì›ƒ ë°ì´í„° ìƒì„±"""
        batch_size = 100
        total_batches = (count + batch_size - 1) // batch_size

        for batch in range(total_batches):
            batch_data = []
            current_batch_size = min(batch_size, count - batch * batch_size)

            for i in range(current_batch_size):
                # ëœë¤ ë‚ ì§œ ìƒì„±
                random_days = random.randint(0, (end_date - start_date).days)
                transaction_date = start_date + timedelta(days=random_days)

                # í†µì‹ ì‚¬ ì„ íƒ
                from_operator = random.choice(list(operators.values()))
                to_operator = random.choice(
                    [k for k in operators.values() if k != from_operator]
                )

                # ìƒíƒœ ì½”ë“œ
                status_val = random.choice(["1", "2", "3"])
                trmn_date = transaction_date.strftime("%Y-%m-%d")

                if status_val == "1":
                    cncl_date = None
                elif status_val == "2":
                    cncl_date = trmn_date
                else:
                    random_days = random.randint(1, 15)
                    cncl_date = (
                        transaction_date + timedelta(days=random_days)
                    ).strftime("%Y-%m-%d")

                pay_amount = random.randint(10, 1000000)

                batch_data.append(
                    (
                        "OUT",
                        f"AT{batch:04d}{i:04d}",  # ê³ ìœ  ID
                        trmn_date,
                        cncl_date,
                        from_operator,
                        to_operator,
                        f"{(batch * batch_size + i + 1):020d}",
                        f"{(batch * batch_size + i + 1):011d}",
                        f"010{random.randint(1000,9999)}{random.randint(1000,9999)}",
                        status_val,
                        pay_amount,
                    )
                )

            # ë°°ì¹˜ ì‚½ì…
            cursor.executemany(
                """
                INSERT INTO PY_NP_TRMN_RMNY_TXN 
                (NP_DIV_CD, TRMN_NP_ADM_NO, NP_TRMN_DATE, CNCL_WTHD_DATE, 
                 BCHNG_COMM_CMPN_ID, ACHNG_COMM_CMPN_ID, SVC_CONT_ID, BILL_ACC_ID, 
                 TEL_NO, NP_TRMN_DTL_STTUS_VAL, PAY_AMT)
                VALUES (?,?,?,?,?,?,?,?,?,?,?)
            """,
                batch_data,
            )

        self.logger.info(f"í¬íŠ¸ì•„ì›ƒ ë°ì´í„° {count}ê±´ ìƒì„± ì™„ë£Œ")

    def _generate_azure_port_in_data(
        self, cursor, operators, start_date, end_date, count
    ):
        """Azure SQL Database í¬íŠ¸ì¸ ë°ì´í„° ìƒì„±"""
        batch_size = 100
        total_batches = (count + batch_size - 1) // batch_size

        for batch in range(total_batches):
            batch_data = []
            current_batch_size = min(batch_size, count - batch * batch_size)

            for i in range(current_batch_size):
                # ëœë¤ ë‚ ì§œ ìƒì„±
                random_days = random.randint(0, (end_date - start_date).days)
                transaction_date = start_date + timedelta(days=random_days)

                # í†µì‹ ì‚¬ ì„ íƒ
                from_operator = random.choice(list(operators.values()))
                to_operator = random.choice(
                    [k for k in operators.values() if k != from_operator]
                )

                # ìƒíƒœ ì½”ë“œ
                status_cd = random.choice(["OK", "CN", "WD"])
                trt_date = transaction_date.strftime("%Y-%m-%d")

                if status_cd == "OK":
                    cncl_date = None
                elif status_cd == "CN":
                    cncl_date = trt_date
                else:
                    random_days = random.randint(1, 15)
                    cncl_date = (
                        transaction_date + timedelta(days=random_days)
                    ).strftime("%Y-%m-%d")

                settlement_amount = random.randint(10, 1000000)

                batch_data.append(
                    (
                        "IN",
                        trt_date,
                        cncl_date,
                        from_operator,
                        to_operator,
                        f"{(batch * batch_size + i + 1):020d}",
                        f"{(batch * batch_size + i + 1):011d}",
                        f"010{random.randint(1000,9999)}{random.randint(1000,9999)}",
                        status_cd,
                        settlement_amount,
                    )
                )

            # ë°°ì¹˜ ì‚½ì…
            cursor.executemany(
                """
                INSERT INTO PY_NP_SBSC_RMNY_TXN 
                (NP_DIV_CD, TRT_DATE, CNCL_DATE, BCHNG_COMM_CMPN_ID, ACHNG_COMM_CMPN_ID, 
                 SVC_CONT_ID, BILL_ACC_ID, TEL_NO, NP_STTUS_CD, SETL_AMT)
                VALUES (?,?,?,?,?,?,?,?,?,?)
            """,
                batch_data,
            )

        self.logger.info(f"í¬íŠ¸ì¸ ë°ì´í„° {count}ê±´ ìƒì„± ì™„ë£Œ")

    def _generate_azure_deposit_data(self, cursor, start_date, end_date, count):
        """Azure SQL Database ì˜ˆì¹˜ê¸ˆ ë°ì´í„° ìƒì„±"""
        batch_size = 100
        total_batches = (count + batch_size - 1) // batch_size

        for batch in range(total_batches):
            batch_data = []
            current_batch_size = min(batch_size, count - batch * batch_size)

            for i in range(current_batch_size):
                random_days = random.randint(0, (end_date - start_date).days)
                transaction_date = start_date + timedelta(days=random_days)

                batch_data.append(
                    (
                        f"{(batch * batch_size + i + 1):020d}",
                        f"{(batch * batch_size + i + 1):011d}",
                        random.choice(["10", "90"]),
                        transaction_date.strftime("%Y-%m-%d"),
                        random.choice(["NA", "CA"]),
                        random.randint(10, 1000000),
                    )
                )

            # ë°°ì¹˜ ì‚½ì…
            cursor.executemany(
                """
                INSERT INTO PY_DEPAZ_BAS 
                (SVC_CONT_ID, BILL_ACC_ID, DEPAZ_DIV_CD, RMNY_DATE, RMNY_METH_CD, DEPAZ_AMT)
                VALUES (?,?,?,?,?,?)
            """,
                batch_data,
            )

        self.logger.info(f"ì˜ˆì¹˜ê¸ˆ ë°ì´í„° {count}ê±´ ìƒì„± ì™„ë£Œ")

    def _generate_sample_data(self, conn):
        """SQLiteìš© ìƒ˜í”Œ ë°ì´í„° ìƒì„± (ê¸°ì¡´ ë¡œì§)"""
        # í†µì‹ ì‚¬ ì •ë³´
        operators = {
            "C001": "KT",
            "C002": "SKT",
            "C003": "LGU+",
            "C004": "KT MVNO",
            "C005": "SKT MVNO",
            "C006": "LGU+ MVNO",
        }

        # ìµœê·¼ 4ê°œì›” ê¸°ê°„ ì„¤ì •
        end_date = datetime.now()
        start_date = end_date - timedelta(days=120)

        self.logger.info("ğŸ“Š SQLite ìƒ˜í”Œ ë°ì´í„°ë¥¼ ìƒì„± ì¤‘ì…ë‹ˆë‹¤...")

        # 1. í•´ì§€ë²ˆí˜¸ì´ë™ ë°ì´í„° (í¬íŠ¸ì•„ì›ƒ) ìƒì„±
        self._generate_sqlite_port_out_data(conn, operators, start_date, end_date)

        # 2. ê°€ì…ë²ˆí˜¸ì´ë™ ë°ì´í„° (í¬íŠ¸ì¸) ìƒì„±
        self._generate_sqlite_port_in_data(conn, operators, start_date, end_date)

        self.logger.info("âœ¨ SQLite ìƒ˜í”Œ ë°ì´í„° ìƒì„± ì™„ë£Œ!")

    def _generate_sqlite_port_out_data(self, conn, operators, start_date, end_date):
        """SQLite í¬íŠ¸ì•„ì›ƒ ë°ì´í„° ìƒì„±"""
        port_out_data = []
        deposit_data = []

        # 1000ê±´ì˜ í¬íŠ¸ì•„ì›ƒ ë°ì´í„° ìƒì„±
        for i in range(1000):
            # ëœë¤ ë‚ ì§œ ìƒì„±
            random_days = random.randint(0, (end_date - start_date).days)
            transaction_date = start_date + timedelta(days=random_days)

            # í†µì‹ ì‚¬ ì„ íƒ (ë³€ê²½ì „/ë³€ê²½í›„)
            from_operator_code = random.choice(list(operators.values()))
            to_operator_code = random.choice(
                [k for k in operators.values() if k != from_operator_code]
            )

            # ë²ˆí˜¸ì´ë™ ìƒíƒœ ì½”ë“œì— ë”°ë¥¸ cncl_wthd_date ì„¤ì •
            np_trmn_dtl_sttus_val = random.choice(["1", "2", "3"])
            np_trmn_date = transaction_date.strftime("%Y-%m-%d")

            if np_trmn_dtl_sttus_val == "1":
                cncl_wthd_date = None  # NULL
            elif np_trmn_dtl_sttus_val == "2":
                cncl_wthd_date = np_trmn_date  # NP_TRMN_DATE ë™ì¼
            else:  # WD
                # CNCL_WTHD_DATE ì´í›„ 1~15ì¼ ëœë¤ ë‚ ì§œ
                random_days = random.randint(1, 15)
                cncl_wthd_date = (
                    transaction_date + timedelta(days=random_days)
                ).strftime("%Y-%m-%d")

            svc_cont_id = f"{i+1:020d}"
            bill_acc_id = f"{i+1:011d}"
            tel_no = f"010{random.randint(1000,9999)}{random.randint(1000,9999)}"
            pay_amount = random.randint(10, 1000000)

            port_out_data.append(
                (
                    "OUT",  # NP_DIV_CD
                    f"T{i+1:07d}",  # TRMN_NP_ADM_NO
                    np_trmn_date,  # NP_TRMN_DATE
                    cncl_wthd_date,  # CNCL_WTHD_DATE
                    from_operator_code,  # BCHNG_COMM_CMPN_ID
                    to_operator_code,  # ACHNG_COMM_CMPN_ID
                    svc_cont_id,  # SVC_CONT_ID
                    bill_acc_id,  # BILL_ACC_ID
                    tel_no,  # TEL_NO
                    np_trmn_dtl_sttus_val,  # NP_TRMN_DTL_STTUS_VAL
                    pay_amount,  # PAY_AMT
                )
            )

            deposit_data.append(
                (
                    i + 1,  # DEPAZ_SEQ
                    svc_cont_id,  # SVC_CONT_ID
                    bill_acc_id,  # BILL_ACC_ID
                    random.choice(["10", "90"]),  # DEPAZ_DIV_CD
                    np_trmn_date,  # RMNY_DATE
                    random.choice(["NA", "CA"]),  # RMNY_METH_CD
                    pay_amount,  # DEPAZ_AMT
                )
            )

        # PY_NP_TRMN_RMNY_TXN í…Œì´ë¸”ì— í¬íŠ¸ì•„ì›ƒ ë°ì´í„° ì‚½ì…
        conn.executemany(
            """
            INSERT INTO PY_NP_TRMN_RMNY_TXN 
            VALUES (?,?,?,?,?,?,?,?,?,?,?)
        """,
            port_out_data,
        )

        # PY_DEPAZ_BAS í…Œì´ë¸”ì— ì˜ˆì¹˜ê¸ˆ ë°ì´í„° ì‚½ì…
        conn.executemany(
            """
            INSERT INTO PY_DEPAZ_BAS 
            VALUES (?,?,?,?,?,?,?)
        """,
            deposit_data,
        )

        conn.commit()
        self.logger.info(f"ğŸ“¤ í¬íŠ¸ì•„ì›ƒ ë°ì´í„° {len(port_out_data)}ê±´ ìƒì„± ì™„ë£Œ")
        self.logger.info(f"ğŸ’° ì˜ˆì¹˜ê¸ˆ ë°ì´í„° {len(deposit_data)}ê±´ ìƒì„± ì™„ë£Œ")

    def _generate_sqlite_port_in_data(self, conn, operators, start_date, end_date):
        """SQLite í¬íŠ¸ì¸ ë°ì´í„° ìƒì„±"""
        port_in_data = []

        # 1200ê±´ì˜ í¬íŠ¸ì¸ ë°ì´í„° ìƒì„±
        for i in range(1200):
            # ëœë¤ ë‚ ì§œ ìƒì„± (ìµœê·¼ìœ¼ë¡œ ê°ˆìˆ˜ë¡ ì¦ê°€ ì¶”ì„¸)
            random_days = random.randint(0, (end_date - start_date).days)
            transaction_date = start_date + timedelta(days=random_days)

            # í†µì‹ ì‚¬ ì„ íƒ
            from_operator_code = random.choice(list(operators.values()))
            to_operator_code = random.choice(
                [k for k in operators.values() if k != from_operator_code]
            )

            # ë²ˆí˜¸ì´ë™ ìƒíƒœ ì½”ë“œì— ë”°ë¥¸ cncl_date ì„¤ì •
            np_sttus_cd = random.choice(["OK", "CN", "WD"])
            trt_date = transaction_date.strftime("%Y-%m-%d")

            if np_sttus_cd == "OK":
                cncl_date = None  # NULL
            elif np_sttus_cd == "CN":
                cncl_date = trt_date  # TRT_DATE ë™ì¼
            else:  # WD
                # CNCL_DATE ì´í›„ 1~15ì¼ ëœë¤ ë‚ ì§œ
                random_days = random.randint(1, 15)
                cncl_date = (transaction_date + timedelta(days=random_days)).strftime(
                    "%Y-%m-%d"
                )

            settlement_amount = random.randint(10, 1000000)

            port_in_data.append(
                (
                    "IN",  # NP_DIV_CD,
                    i + 1,  # NP_SBSC_RMNY_SEQ
                    trt_date,  # TRT_DATE
                    cncl_date,  # CNCL_DATE
                    from_operator_code,  # BCHNG_COMM_CMPN_ID
                    to_operator_code,  # ACHNG_COMM_CMPN_ID
                    f"{i+1:020d}",  # SVC_CONT_ID
                    f"{i+1:011d}",  # BILL_ACC_ID
                    f"010{random.randint(1000,9999)}{random.randint(1000,9999)}",  # TEL_NO
                    np_sttus_cd,  # NP_STTUS_CD
                    settlement_amount,  # SETL_AMT
                )
            )

        # ë°ì´í„°ë² ì´ìŠ¤ì— ì‚½ì…
        conn.executemany(
            """
            INSERT INTO PY_NP_SBSC_RMNY_TXN 
            VALUES (?,?,?,?,?,?,?,?,?,?,?)
        """,
            port_in_data,
        )

        conn.commit()
        self.logger.info(f"ğŸ“¥ í¬íŠ¸ì¸ ë°ì´í„° {len(port_in_data)}ê±´ ìƒì„± ì™„ë£Œ")

    def _log_data_statistics(self, data_stats: Dict[str, int]):
        """ë°ì´í„° í†µê³„ ë¡œê¹…"""
        self.logger.info("\nğŸ“Š ìƒ˜í”Œ ë°ì´í„° í†µê³„:")
        self.logger.info("=" * 50)

        total_records = sum(data_stats.values())

        for table_name, count in data_stats.items():
            table_display = {
                "PY_NP_TRMN_RMNY_TXN": "ğŸ“¤ í¬íŠ¸ì•„ì›ƒ",
                "PY_NP_SBSC_RMNY_TXN": "ğŸ“¥ í¬íŠ¸ì¸",
                "PY_DEPAZ_BAS": "ğŸ’° ì˜ˆì¹˜ê¸ˆ",
            }.get(table_name, table_name)

            self.logger.info(f"   {table_display}: {count:,}ê±´")

        self.logger.info(f"   ğŸ“Š ì´ ë°ì´í„°: {total_records:,}ê±´")
        self.logger.info("=" * 50)

    def get_sample_statistics(self, conn):
        """ìƒì„±ëœ ìƒ˜í”Œ ë°ì´í„° í†µê³„ í™•ì¸"""
        try:
            if self.use_azure:
                return self._get_azure_statistics(conn)
            else:
                return self._get_sqlite_statistics(conn)
        except Exception as e:
            self.logger.error(f"í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {}

    def _get_azure_statistics(self, conn):
        """Azure SQL Database í†µê³„ ì¡°íšŒ"""
        stats = {}
        cursor = conn.cursor()

        try:
            # í¬íŠ¸ì•„ì›ƒ í†µê³„
            cursor.execute(
                """
                SELECT 
                    COUNT(*) as total_count,
                    SUM(PAY_AMT) as total_amount,
                    AVG(PAY_AMT) as avg_amount,
                    MIN(PAY_AMT) as min_amount,
                    MAX(PAY_AMT) as max_amount
                FROM PY_NP_TRMN_RMNY_TXN
                WHERE NP_TRMN_DTL_STTUS_VAL IN ('1', '3')
            """
            )
            port_out_result = cursor.fetchone()

            if port_out_result:
                stats["port_out"] = {
                    "total_count": port_out_result[0],
                    "total_amount": port_out_result[1] or 0,
                    "avg_amount": port_out_result[2] or 0,
                    "min_amount": port_out_result[3] or 0,
                    "max_amount": port_out_result[4] or 0,
                }

            # í¬íŠ¸ì¸ í†µê³„
            cursor.execute(
                """
                SELECT 
                    COUNT(*) as total_count,
                    SUM(SETL_AMT) as total_amount,
                    AVG(SETL_AMT) as avg_amount,
                    MIN(SETL_AMT) as min_amount,
                    MAX(SETL_AMT) as max_amount
                FROM PY_NP_SBSC_RMNY_TXN
                WHERE NP_STTUS_CD IN ('OK', 'WD')
            """
            )
            port_in_result = cursor.fetchone()

            if port_in_result:
                stats["port_in"] = {
                    "total_count": port_in_result[0],
                    "total_amount": port_in_result[1] or 0,
                    "avg_amount": port_in_result[2] or 0,
                    "min_amount": port_in_result[3] or 0,
                    "max_amount": port_in_result[4] or 0,
                }

            # ì˜ˆì¹˜ê¸ˆ í†µê³„
            cursor.execute(
                """
                SELECT 
                    COUNT(*) as total_count,
                    SUM(DEPAZ_AMT) as total_amount,
                    AVG(DEPAZ_AMT) as avg_amount
                FROM PY_DEPAZ_BAS
                WHERE RMNY_METH_CD = 'NA' AND DEPAZ_DIV_CD = '10'
            """
            )
            deposit_result = cursor.fetchone()

            if deposit_result:
                stats["deposit"] = {
                    "total_count": deposit_result[0],
                    "total_amount": deposit_result[1] or 0,
                    "avg_amount": deposit_result[2] or 0,
                }

            return stats

        except Exception as e:
            self.logger.error(f"Azure í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {}

    def _get_sqlite_statistics(self, conn):
        """SQLite í†µê³„ ì¡°íšŒ"""
        stats = {}

        try:
            # í¬íŠ¸ì•„ì›ƒ í†µê³„
            port_out_stats = pd.read_sql_query(
                """
                SELECT 
                    COUNT(*) as total_count,
                    SUM(PAY_AMT) as total_amount,
                    AVG(PAY_AMT) as avg_amount,
                    MIN(PAY_AMT) as min_amount,
                    MAX(PAY_AMT) as max_amount
                FROM PY_NP_TRMN_RMNY_TXN
                WHERE NP_TRMN_DTL_STTUS_VAL IN ('1', '3')
            """,
                conn,
            )

            if not port_out_stats.empty:
                stats["port_out"] = port_out_stats.iloc[0].to_dict()

            # í¬íŠ¸ì¸ í†µê³„
            port_in_stats = pd.read_sql_query(
                """
                SELECT 
                    COUNT(*) as total_count,
                    SUM(SETL_AMT) as total_amount,
                    AVG(SETL_AMT) as avg_amount,
                    MIN(SETL_AMT) as min_amount,
                    MAX(SETL_AMT) as max_amount
                FROM PY_NP_SBSC_RMNY_TXN
                WHERE NP_STTUS_CD IN ('OK', 'WD')
            """,
                conn,
            )

            if not port_in_stats.empty:
                stats["port_in"] = port_in_stats.iloc[0].to_dict()

            # ì˜ˆì¹˜ê¸ˆ í†µê³„
            deposit_stats = pd.read_sql_query(
                """
                SELECT 
                    COUNT(*) as total_count,
                    SUM(DEPAZ_AMT) as total_amount,
                    AVG(DEPAZ_AMT) as avg_amount
                FROM PY_DEPAZ_BAS
                WHERE RMNY_METH_CD = 'NA' AND DEPAZ_DIV_CD = '10'
            """,
                conn,
            )

            if not deposit_stats.empty:
                stats["deposit"] = deposit_stats.iloc[0].to_dict()

            return stats

        except Exception as e:
            self.logger.error(f"SQLite í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {}

    def cleanup_sample_data(self, conn):
        """ìƒ˜í”Œ ë°ì´í„° ì •ë¦¬ (Azureë§Œ í•´ë‹¹)"""
        if not self.use_azure:
            self.logger.info("SQLiteëŠ” ë©”ëª¨ë¦¬ ê¸°ë°˜ì´ë¯€ë¡œ ì •ë¦¬ê°€ ë¶ˆí•„ìš”í•©ë‹ˆë‹¤")
            return

        try:
            cursor = conn.cursor()

            # ìƒ˜í”Œ ë°ì´í„°ë§Œ ì‚­ì œ
            cursor.execute("DELETE FROM PY_NP_TRMN_RMNY_TXN WHERE IS_SAMPLE_DATA = 1")
            cursor.execute("DELETE FROM PY_NP_SBSC_RMNY_TXN WHERE IS_SAMPLE_DATA = 1")
            cursor.execute("DELETE FROM PY_DEPAZ_BAS WHERE IS_SAMPLE_DATA = 1")

            conn.commit()
            self.logger.info("Azure SQL Database ìƒ˜í”Œ ë°ì´í„° ì •ë¦¬ ì™„ë£Œ")

        except Exception as e:
            self.logger.error(f"ìƒ˜í”Œ ë°ì´í„° ì •ë¦¬ ì‹¤íŒ¨: {e}")

    def is_using_azure(self) -> bool:
        """Azure SQL Database ì‚¬ìš© ì—¬ë¶€ ë°˜í™˜"""
        return self.use_azure

    def get_connection_info(self) -> Dict[str, Any]:
        """ì—°ê²° ì •ë³´ ë°˜í™˜"""
        return {
            "type": "Azure SQL Database" if self.use_azure else "SQLite",
            "azure_ready": self.azure_config.is_production_ready(),
            "force_local": self.force_local,
        }


# ê¸°ì¡´ í•¨ìˆ˜ë“¤ê³¼ì˜ í˜¸í™˜ì„±ì„ ìœ„í•œ ë˜í¼ í•¨ìˆ˜ë“¤
def create_sample_database(
    azure_config: Optional[AzureConfig] = None, force_local: bool = False
):
    """
    ìƒ˜í”Œ ë°ì´í„°ë² ì´ìŠ¤ ìƒì„± (ê¸°ì¡´ í•¨ìˆ˜ì™€ í˜¸í™˜)

    Args:
        azure_config: Azure ì„¤ì • (Noneì´ë©´ ë¡œì»¬ ëª¨ë“œ)
        force_local: ê°•ì œë¡œ ë¡œì»¬ SQLite ì‚¬ìš©

    Returns:
        ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ê°ì²´
    """
    if azure_config is None:
        # Azure ì„¤ì •ì´ ì—†ìœ¼ë©´ ê¸°ì¡´ ë¡œì»¬ ëª¨ë“œë¡œ ë™ì‘
        conn = sqlite3.connect(":memory:", check_same_thread=False)
        manager = SampleDataManager(None, force_local=True)
        manager.sqlite_conn = conn
        manager._create_sqlite_tables(conn)
        manager._generate_sample_data(conn)
        print("âœ… ë¡œì»¬ ìƒ˜í”Œ ë°ì´í„°ë² ì´ìŠ¤ê°€ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!")
        return conn
    else:
        # Azure ì„¤ì •ì´ ìˆìœ¼ë©´ ìƒˆë¡œìš´ ë§¤ë‹ˆì € ì‚¬ìš©
        manager = SampleDataManager(azure_config, force_local)
        return manager.create_sample_database()


def get_sample_statistics(conn):
    """ìƒ˜í”Œ ë°ì´í„° í†µê³„ ì¡°íšŒ (ê¸°ì¡´ í•¨ìˆ˜ì™€ í˜¸í™˜)"""
    # ì—°ê²° íƒ€ì…ì— ë”°ë¼ ì ì ˆí•œ ì¿¼ë¦¬ ì‹¤í–‰
    try:
        # SQLiteì¸ì§€ í™•ì¸
        cursor = conn.cursor()
        cursor.execute("SELECT name FROM sqlite_master WHERE type='table';")
        # SQLiteë¼ë©´ ê¸°ì¡´ ë¡œì§ ì‚¬ìš©

        print("\nğŸ“Š ìƒ˜í”Œ ë°ì´í„° í†µê³„:")
        print("=" * 50)

        # í¬íŠ¸ì•„ì›ƒ í†µê³„
        port_out_stats = pd.read_sql_query(
            """
            SELECT 
                COUNT(*) as total_count,
                SUM(PAY_AMT) as total_amount,
                AVG(PAY_AMT) as avg_amount,
                MIN(PAY_AMT) as min_amount,
                MAX(PAY_AMT) as max_amount
            FROM PY_NP_TRMN_RMNY_TXN
            WHERE NP_TRMN_DTL_STTUS_VAL IN ('1', '3')
        """,
            conn,
        )

        print("ğŸ“¤ í¬íŠ¸ì•„ì›ƒ í˜„í™©:")
        print(f"   ì´ ê±´ìˆ˜: {port_out_stats.iloc[0]['total_count']:,}ê±´")
        print(f"   ì´ ì •ì‚°ì•¡: {port_out_stats.iloc[0]['total_amount']:,.0f}ì›")
        print(f"   í‰ê·  ì •ì‚°ì•¡: {port_out_stats.iloc[0]['avg_amount']:,.0f}ì›")

        # í¬íŠ¸ì¸ í†µê³„
        port_in_stats = pd.read_sql_query(
            """
            SELECT 
                COUNT(*) as total_count,
                SUM(SETL_AMT) as total_amount,
                AVG(SETL_AMT) as avg_amount,
                MIN(SETL_AMT) as min_amount,
                MAX(SETL_AMT) as max_amount
            FROM PY_NP_SBSC_RMNY_TXN
            WHERE NP_STTUS_CD IN ('OK', 'WD')
        """,
            conn,
        )

        print("\nğŸ“¥ í¬íŠ¸ì¸ í˜„í™©:")
        print(f"   ì´ ê±´ìˆ˜: {port_in_stats.iloc[0]['total_count']:,}ê±´")
        print(f"   ì´ ì •ì‚°ì•¡: {port_in_stats.iloc[0]['total_amount']:,.0f}ì›")
        print(f"   í‰ê·  ì •ì‚°ì•¡: {port_in_stats.iloc[0]['avg_amount']:,.0f}ì›")

        # ì˜ˆì¹˜ê¸ˆ í†µê³„
        deposit_stats = pd.read_sql_query(
            """
            SELECT 
                COUNT(*) as total_count,
                SUM(DEPAZ_AMT) as total_amount,
                AVG(DEPAZ_AMT) as avg_amount
            FROM PY_DEPAZ_BAS
            WHERE RMNY_METH_CD = 'NA' AND DEPAZ_DIV_CD = '10'
        """,
            conn,
        )

        print("\nğŸ’° ì˜ˆì¹˜ê¸ˆ í˜„í™©:")
        print(f"   ì´ ê±´ìˆ˜: {deposit_stats.iloc[0]['total_count']:,}ê±´")
        print(f"   ì´ ì˜ˆì¹˜ê¸ˆ: {deposit_stats.iloc[0]['total_amount']:,.0f}ì›")
        print(f"   í‰ê·  ì˜ˆì¹˜ê¸ˆ: {deposit_stats.iloc[0]['avg_amount']:,.0f}ì›")

        print("=" * 50)

    except Exception as e:
        print(f"í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")


# í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
def test_sample_data_manager():
    """ìƒ˜í”Œ ë°ì´í„° ë§¤ë‹ˆì € í…ŒìŠ¤íŠ¸"""
    print("ğŸ§ª ìƒ˜í”Œ ë°ì´í„° ë§¤ë‹ˆì € í…ŒìŠ¤íŠ¸ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")

    try:
        from azure_config import get_azure_config

        azure_config = get_azure_config()

        # 1. Azure ëª¨ë“œ í…ŒìŠ¤íŠ¸ (ê°€ëŠ¥í•œ ê²½ìš°)
        if azure_config.is_production_ready():
            print("\nğŸ”µ Azure SQL Database ëª¨ë“œ í…ŒìŠ¤íŠ¸:")
            azure_manager = SampleDataManager(azure_config, force_local=False)
            azure_conn = azure_manager.create_sample_database()

            connection_info = azure_manager.get_connection_info()
            print(f"   ì—°ê²° íƒ€ì…: {connection_info['type']}")
            print(f"   Azure ì¤€ë¹„ ìƒíƒœ: {connection_info['azure_ready']}")

            # í†µê³„ í™•ì¸
            stats = azure_manager.get_sample_statistics(azure_conn)
            if stats:
                print("   ğŸ“Š Azure ë°ì´í„° í†µê³„:")
                for data_type, stat in stats.items():
                    print(f"     {data_type}: {stat.get('total_count', 0):,}ê±´")

            azure_conn.close()

        # 2. ë¡œì»¬ ëª¨ë“œ í…ŒìŠ¤íŠ¸
        print("\nğŸŸ¡ ë¡œì»¬ SQLite ëª¨ë“œ í…ŒìŠ¤íŠ¸:")
        local_manager = SampleDataManager(azure_config, force_local=True)
        local_conn = local_manager.create_sample_database()

        connection_info = local_manager.get_connection_info()
        print(f"   ì—°ê²° íƒ€ì…: {connection_info['type']}")

        # í†µê³„ í™•ì¸
        stats = local_manager.get_sample_statistics(local_conn)
        if stats:
            print("   ğŸ“Š ë¡œì»¬ ë°ì´í„° í†µê³„:")
            for data_type, stat in stats.items():
                print(f"     {data_type}: {stat.get('total_count', 0):,}ê±´")

        # 3. í˜¸í™˜ì„± í…ŒìŠ¤íŠ¸
        print("\nğŸ”„ ê¸°ì¡´ í•¨ìˆ˜ í˜¸í™˜ì„± í…ŒìŠ¤íŠ¸:")
        compat_conn = create_sample_database(azure_config, force_local=True)
        get_sample_statistics(compat_conn)

        print("\nâœ… ëª¨ë“  í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")

    except Exception as e:
        print(f"\nâŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        import traceback

        traceback.print_exc()


if __name__ == "__main__":
    test_sample_data_manager()
